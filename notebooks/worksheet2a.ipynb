{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 2: Introduction to using Python and the Python Library IRIS for analysis and visualisation\n",
    "\n",
    "In this worksheet, sample PRECIS output over Southeast Asia driven by HadCM3Q0 and ECHAM5 is compared with observations for validation purposes. Validation of model results by comparison with observed data is an essential step - this is the measure by which we can assess the quality of the model and it informs appropriate uses of the data.\n",
    "\n",
    "\n",
    "Here, we use PRECIS output driven by two different GCMs. Using data from both experiments will give us two representations of present day climate and two possible climate scenarios. For more details on multimodel approaches see the PRECIS workshop lecture on climate model ensembles.\n",
    "\n",
    "\n",
    "The following are examples of types of analyses undertaken as part of a model validation. The methods shown are not necessarily the only way to proceed and are intended to demonstrate the use of Iris in model validation, and provide a starting point for your own analyses. For further help on validating your PRECIS simulations, refer to the PRECIS workshop lecture notes.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "**Note:** The data used here has been processed in the same way as Worksheet 1. The 8 point-rim has been removed and it has been converted from PP to NetCDF format.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code preamble - these libraries will be used in this worksheet.\n",
    "# This code block needs to be re-run every time you restart this worksheet!\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.dates as mdates\n",
    "import calendar\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "import iris.quickplot as qplt\n",
    "\n",
    "iris.FUTURE.netcdf_promote = True\n",
    "iris.FUTURE.netcdf_no_unlimited = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Inspecting the data\n",
    "\n",
    "The datasets used here are daily and monthly data from two PRECIS runs carried out over Southeast Asia, one driven by HadCM3Q0 and the other driven by ECHAM5. The observations used for comparison are from the [APHRODITE gridded observational data set](https://climatedataguide.ucar.edu/climate-data/aphrodite-asian-precipitation-highly-resolved-observational-data-integration-towards).\n",
    "\n",
    "As we saw in previous workshop in Iris, data are read into an object called a cube. A cube contains the data of interest (e.g., temperature, rainfall, wind speeds) and metadata about a phenomenon. A single cube describes only one type of data. It is not possible for a cube to contain both temperature and rainfall, for example. A cube always has a name, a unit and an n-dimensional data array to represents the cubeâ€™s data. Additionally, the cube contains collections of coordinates.  Coordinate types can include spatial information (latitude, longitude, altitude), times, or other information, e.g., an ensemble number.\n",
    "\n",
    "__a) Load the netCDF file for the HadCM3Q0 and ECHAM5 model data and the APHRODITE rainfall observation data and print the cube output__\n",
    "\n",
    "A cube has coordinates (for example time, longitude, latitude, model levels etc) and this information can be accessed with commands. In the following exercise we follow a similar example to that in the [Iris documentation](http://scitools.org.uk/iris/docs/latest/userguide/navigating_a_cube.html#accessing-coordinates-on-the-cube) and find the latitude and longitude of the corners of the locations for the APHRODITE data. You can do so by printing the latitude and longitude coordinates (.points) and note the first and last values in the array.\n",
    "\n",
    "Before running the code take a look at it line by line to understand what steps are being made. Add code where prompted and then click in the box and press <kbd>ctrl</kbd> + <kbd>enter</kbd> to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This command ensures we are in the correct directory. Edit it as necessary to the directory you are working from.\n",
    "%cd /media/sf_share/UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check you are using Iris version 1.10 or greater\n",
    "print('Using Iris version: {}'.format(iris.__version__))\n",
    "\n",
    "# the following is needed to be compliant with the Iris's latest NetCDF default saving behaviour\n",
    "iris.FUTURE.netcdf_promote = 'True'\n",
    "iris.FUTURE.netcdf_no_unlimited = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feed in the names of the directories where the netCDF model files are stored\n",
    "path_in_cahpa   = '/net/data/users/ssadri/data-local/PRECIS_WORK/practise_ppfiles/monthly/cahpa/05216/'\n",
    "path_in_cahpb   = '/net/data/users/ssadri/data-local/PRECIS_WORK/practise_ppfiles/monthly/cahpb/05216/'\n",
    "path_in_APHRODITE   = '/net/data/users/ssadri/data-local/PRECIS_WORK/practise_ppfiles/monthly/APHRODITE/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and print the HadCM3Q0 (cahpa) model cube data\n",
    "cahpa_data_cube = iris.load_cube(path_in_cahpa + 'cahpaa.pm.6190.05216.rr8.nc')\n",
    "print 'This is the HadCM3Q0 cube'\n",
    "print cahpa_data_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and print the ECHAM5 (cahpb) model cube data\n",
    "cahpb_data_cube = iris.load_cube(path_in_cahpb + 'cahpba.pm.6190.05216.rr8.nc')\n",
    "print 'This is the ECHAM5 cube'\n",
    "print cahpb_data_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and print the APHRODITE observation cube data\n",
    "aphrodite_data_cube = iris.load_cube(path_in_APHRODITE + 'aphro.mon.6190.nc')\n",
    "print 'This is the APHRODITE cube'\n",
    "print aphrodite_data_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The coord objects of the data cubes contain the co-ordinate points of the data\n",
    "print 'This is the APHRODITE cube latitude coordinate data'\n",
    "print  aphrodite_data_cube.coord('latitude').points\n",
    "\n",
    "print 'This is the APHRODITE cube longitude coordinate data'\n",
    "print  aphrodite_data_cube.coord('longitude').points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b) Extract a subset of the data within a cube__\n",
    "\n",
    "The ability to extractis an important function in Iris. The extraction of a subset of data is called slicing.  For example, it could be necessary to extract data over all latitude and longitude grid points on the first time step. For more information around subsetting cubes please read further [here](http://scitools.org.uk/iris/docs/latest/userguide/subsetting_a_cube.html#cube-indexing).\n",
    "\n",
    "__Using the HacCM3Q0 data, the example below shows how to subset a cube for the first time and last timesteps. This method will be used later for plotting data from a cube.__ \n",
    "\n",
    "Work through the example below line by line then click in the box and press <kbd>ctrl</kbd> + <kbd>enter</kbd> to run the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the NetCDF file into a cube\n",
    "cahpa_data_cube = iris.load_cube(path_in_cahpa + 'cahpaa.pm.6190.05216.rr8.nc')\n",
    "\n",
    "print 'This is the cube with all timesteps'\n",
    "print cahpa_data_cube\n",
    "\n",
    "print 'This is the first time step of the cube' \n",
    "print cahpa_data_cube[0]\n",
    "\n",
    "print 'This is the last time step of the cube'\n",
    "print cahpa_data_cube[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Converting units\n",
    "\n",
    "__a) Convert the OND (October, November, December) seasonal precipitation fields for both runs from kg/m2/s (equivalent to mm/s) to mm/day__\n",
    "\n",
    "We could just multiply the raw data in mm/s by 86400 seconds, but a clearer way is to use the __`convert_units`__ method with the name of the units we want to convert the data into.\n",
    "\n",
    "For clarity let's do this for the __cahpa__ historical data first and break down the steps as follow:\n",
    "\n",
    "* Read in the historic NetCDF file into an Iris cube and print the cube\n",
    "* Print the units and summary statistic about the data\n",
    "* Convert the unit and print the information again\n",
    "* Rename the nuits value in the cube and save it as a new netCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the name of the historical netCDF file to load\n",
    "cahpa_historic_file = 'cahpaa.pm.6190.05216.rr8.nc'\n",
    "\n",
    "# read in the file into an iris cube and print it\n",
    "cahpa_historic_cube = iris.load_cube(path_in_cahpa + cahpa_historic_file)\n",
    "print cahpa_historic_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print the unit\n",
    "print('The current unit for data is: {}'.format(cahpa_historic_cube.units))\n",
    "\n",
    "# print the summary statistic (maximum monthly precipitation)\n",
    "maxpr = np.amax(cahpa_historic_cube.data)\n",
    "print('This is an example rainfall rate (kg m-2 s-1) prior to conversion:'.format(maxpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert units to kg m-2 day-1 (same as multiplying by 86400 seconds)\n",
    "cahpa_historic_cube.convert_units('kg m-2 day-1')\n",
    "maxpr = np.amax(cahpa_historic_cube.data)\n",
    "\n",
    "# print the summary statistic (maximum monthly precipitation) after the unit conversion\n",
    "print('This is the same rainfall rate but in (kg m-2 day-1): {}'.format(maxpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename the units value in the cube and save it as a new netCDF file\n",
    "# change to the directory where you want the new file is saved\n",
    "%cd <path to directory here>\n",
    "\n",
    "# Rename the units to mm day-1. 1 kg m-2 is equivalent to 1 mm of rain\n",
    "cahpa_historic_cube.units = 'mm day-1'\n",
    "\n",
    "# Print cube.units to view new units for precipitation\n",
    "print('The new rainfall units are: {}'.format(cahpa_historic_cube.units))\n",
    "\n",
    "# Rename the output file name to reflect the changed units\n",
    "new_cahpa_historic_file = cahpa_historic_file.replace('.nc', '.mmday.nc')\n",
    "\n",
    "# save the cube into a new netCDF file\n",
    "iris.save(cahpa_historic_cube, new_cahpa_historic_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the same proceedure for __cahpb__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cahpb_historic_file = 'cahpba.pm.6190.05216.rr8.nc'\n",
    "\n",
    "# read in the file into an iris cube and print it\n",
    "cahpb_historic_cube = iris.load_cube(path_in_cahpb + cahpb_historic_file)\n",
    "print cahpb_historic_cube\n",
    "\n",
    "# convert units to kg m-2 day-1 (same as multiplying by 86400 seconds)\n",
    "cahpb_historic_cube.convert_units('kg m-2 day-1')\n",
    "\n",
    "# change to the directory where you want the new file is saved\n",
    "%cd <path to directory here>\n",
    "\n",
    "# Rename the units to mm day-1. 1 kg m-2 is equivalent to 1 mm of rain\n",
    "cahpb_historic_cube.units = 'mm day-1'\n",
    "\n",
    "# rename the output file name to reflect the changed units\n",
    "new_cahpb_historic_file = cahpb_historic_file.replace('.nc', '.mmday.nc')\n",
    "\n",
    "# save the cube into a new netCDF file\n",
    "iris.save(cahpb_historic_cube, new_cahpb_historic_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Climatological mean calculation\n",
    "\n",
    "__a) Calculate the 1961-1990 seasonal mean precipitation field for October-December (OND) from both the HadCM3Q0 (cahpa) and ECHAM5 (cahpb) driven PRECIS runs__\n",
    "\n",
    "Work through the example below line by line then click in the box and press <kbd>ctrl</kbd> + <kbd>enter</kbd> to run the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define output location\n",
    "path_out = \"monthly/climatology/\"\n",
    "if not os.path.isdir(path_out):\n",
    "    os.mkdir(path_out)\n",
    "\n",
    "# Loop through two model runs\n",
    "for jobid in ['cahpa', 'cahpb']:\n",
    "    path_in = os.path.join('monthly', jobid, '05216/')\n",
    "\n",
    "    # Load the data\n",
    "    data = iris.load_cube(path_in + jobid + 'a.pm.6190.05216.rr8.mmday.nc')\n",
    "\n",
    "    # In order to calculate OND mean, we use the command below to add season membership coordinate\n",
    "    # The seasons can be any sequence of months, identified by the first letters of the names of the months.\n",
    "    # Here, we define two seasons, jfmamjjas (the months we are not interested in) and ond (October, November and\n",
    "    # December), the months we do want.\n",
    "    iris.coord_categorisation.add_season(data, 'time', name='seasons', seasons=('jfmamjjas','ond'))\n",
    "\n",
    "    # This command extracts data for the OND season using a constraint\n",
    "    data_ond = data.extract(iris.Constraint(seasons='ond'))\n",
    "\n",
    "    # The cube data_ond contains data for October-December for all years. The command below\n",
    "    # calculates the mean over all years.\n",
    "    seasonal_mean = data_ond.aggregated_by(['seasons'], iris.analysis.MEAN)\n",
    "\n",
    "    # Save the OND seasonal mean as a netCDF\n",
    "    iris.save(seasonal_mean, path_out + jobid + 'a.OND.mean.baseline.05216.mmday.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b) Calculate the 1961-1990 seasonal mean for OND from the APHRODITE observation data__\n",
    "\n",
    "APHRODITE is a daily high resolution (0.25 degree) rain gauge-based precipitation data set over Asia for 1950-2007. See http://www.chikyu.ac.jp/precip/ for more information.\n",
    "\n",
    "Follow step a) and complete the code yourself.  The file name to load is: `aphro.mon.6190.nc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directory names where data is read from and stored to\n",
    "path_in_aphro   = 'monthly/APHRODITE/'\n",
    "path_out        = 'monthly/climatology/'\n",
    "\n",
    "# Load the aprhodite data\n",
    "<code here>\n",
    "\n",
    "# in order to calculate OND mean, need to a add season membership coordinate\n",
    "<code here>\n",
    "\n",
    "# Then constrain the cube just for the OND season\n",
    "<code here>\n",
    "\n",
    "# Now calculate the mean over this season\n",
    "<code here>\n",
    "\n",
    "# save the seasonal mean as a netCDF\n",
    "<code here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 IRIS quick plotting and visualising data\n",
    "\n",
    "Now we will plot the output to take a first look at what the precipitation 1961-1990 OND seasonal mean looks like for each dataset. This provides an initial introduction to visualising data quickly through iris, for further reading and instructions how please visit: http://scitools.org.uk/iris/docs/latest/userguide/plotting_a_cube.html\n",
    "\n",
    "What are the differences between the plots? Note the colour bars.  Where are the largest daily rainfall rates distributed? Why do you think this is happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directory name where data is read from\n",
    "path_in = 'monthly/climatology/'\n",
    "\n",
    "# load cahpa model data\n",
    "cahpa_cube = iris.load_cube(path_in + 'cahpaa.OND.mean.baseline.05216.mmday.nc')\n",
    "print cahpa_cube\n",
    "\n",
    "# load cahpb model data\n",
    "cahpb_cube = iris.load_cube(path_in + 'cahpba.OND.mean.baseline.05216.mmday.nc')\n",
    "print cahpb_cube\n",
    "\n",
    "# load APHRODITE data\n",
    "obs_cube   = iris.load_cube(path_in + 'aphro.OND.mean.baseline.05216.mmday.nc')\n",
    "\n",
    "# Do some plotting!\n",
    "# Create a figure of the size 12x10 inches\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)           # Create a new subplot for the model data 2 row, 2 columns, 1st plot\n",
    "levels = range(0, 22, 2)       # Define the contour levels for all plots\n",
    "\n",
    "# Note this is where cube slicing is needed as you can only plot 2-coordinate\n",
    "# dimensions with qplt.contourf, so here we have selected time[0] as there is only\n",
    "# one timestep (the baseline 1961-1990 mean)\n",
    "qplt.contourf(cahpa_cube[0], levels=levels, cmap=cm.RdBu)\n",
    "                               \n",
    "\n",
    "plt.title('Q0 model')          # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()                 # adds x and y grid lines to the plot\n",
    "\n",
    "plt.subplot(2, 2, 2)           # Create a new subplot for the model data 2 row, 2 columns, 2nd plot\n",
    "qplt.contourf(cahpb_cube[0], levels=levels, cmap=cm.RdBu)\n",
    "\n",
    "plt.title('ECHAM5 model')       # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()                 # adds x and y grid lines to the plot\n",
    "\n",
    "plt.subplot(2, 1, 2)           # Create a new subplot for the observed data 2 row, 1 columns, second plot\n",
    "                               # This plot will be centred and below the two model plots\n",
    "qplt.contourf(obs_cube[0], levels=levels, cmap=cm.RdBu)\n",
    "\n",
    "plt.title('APHRODITE obs')     # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()                 # adds x and y grid lines to the plot\n",
    "\n",
    "plt.tight_layout()             # automatically adjusts subplot(s) to fit in to the figure area\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Mean annual cycle calculation\n",
    "\n",
    "If you have an area or region you want to focus on you can extract data for the region of interest. This example works through how to constrain your cube.\n",
    "\n",
    "__a) Extract the area around Kuala Lumpur from the monthly precipitation data for both the HadCM3Q0 (cahpa) and ECHAM5 (cahpb) driven runs by specifiying latitude and longitude coordinates__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up an area constraint for Kuala Lumpur (KL).\n",
    "# PRECIS uses a rotated grid, so the co-ordinates required are different to real world coordinates.\n",
    "# All grid cells whose longitudes and latitudes lie within the limits shown will be selected.\n",
    "\n",
    "KL_constraint = iris.Constraint(grid_longitude = lambda cell: -8.17 <= cell <= -7.43,\n",
    "                                grid_latitude = lambda cell: -12.10 <= cell <= -11.38)\n",
    "\n",
    "for jobid in ['cahpa', 'cahpb']:\n",
    "    # Directory name where data are read from and stored to\n",
    "    path  = os.path.join('monthly', jobid, '05216/')\n",
    "    \n",
    "    # Load the baseline precipitation data using the KL_constraint - the command below\n",
    "    # loads the data into a cube constrained by the area chosen\n",
    "    model_KL = iris.load_cube(path + jobid + 'a.pm.6190.05216.rr8.mmday.nc', KL_constraint)\n",
    "    print model_KL\n",
    "\n",
    "    # save the constrained cube\n",
    "    iris.save(model_KL, path + jobid + 'a.pm.6190.05216.rr8.ext.mmday.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for APHRODITE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directory where data are read from and stored to\n",
    "path  = 'monthly/APHRODITE/'\n",
    "\n",
    "# Set up area constraint for Kuala Lumpur\n",
    "# Note that the Aphrodite data are on a regular grid (unlike the  model data) so real latitudes and longitudes are\n",
    "# used to define the region around KL (more on this in section 2.6)\n",
    "KL_constraint2 = iris.Constraint(longitude = lambda cell: 101.25 <= cell <= 102.15, \\\n",
    "                                latitude = lambda cell: 2.74 <= cell <= 3.48)\n",
    "\n",
    "# Load the Aphrodite data using the KL_constraint\n",
    "aphrod = iris.load_cube(path + 'aphro.mon.6190.nc', KL_constraint2)\n",
    "print aphrod\n",
    "\n",
    "# save the constrained cube to directory\n",
    "iris.save(aphrod, path + 'aphro.pm.6190.05216.rr8.ext.mmday.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b) We now calculate monthly mean fields for 1961-1990 for each of the twelve months for the KL area__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_out = 'monthly/climatology/'\n",
    "\n",
    "for jobid in ['cahpa', 'cahpb']:\n",
    "    # Set up the path to the data\n",
    "    path_in = os.path.join('monthly', jobid, '05216/')\n",
    "    \n",
    "    # Load the data extracted around Kuala Lumpur created in previous step\n",
    "    data = iris.load_cube(path_in + jobid + 'a.pm.6190.05216.rr8.ext.mmday.nc')\n",
    "\n",
    "    # Add monthly coord categorisation to the time dimension coordinate\n",
    "    iris.coord_categorisation.add_month_number(data, 'time', name='month_number')\n",
    "    print data\n",
    "\n",
    "    # Calculate monthly mean values\n",
    "    monthly_mean = data.aggregated_by(['month_number'], iris.analysis.MEAN)\n",
    "\n",
    "    # Calculate area averaged monthly mean rainfall \n",
    "    monthly_mean = monthly_mean.collapsed(['grid_longitude', 'grid_latitude'], iris.analysis.MEAN)\n",
    "\n",
    "    # Save the area averaged monthly mean data\n",
    "    iris.save(monthly_mean, path_out + jobid + 'a.monmean.baseline.05216.rr8.ext.mmday.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c) What is the KL area averaged monthly mean precipitation amount in mm/day for the HadCM3Q0 and ECHAM5 driven PRECIS runs?__ \n",
    "\n",
    "By plotting the data of the cubes note down the approximate values in mm day-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directory to read in data from\n",
    "datapath = 'monthly/climatology/'\n",
    "\n",
    "# Set up date format for plotting - here, months are shown using abbreviated month names (Jan, Feb, Mar, ... Dec).\n",
    "# The alternative '%m' uses two digit numbers.\n",
    "axFmt = mdates.DateFormatter('%b')\n",
    "\n",
    "for jobid in ['cahpa', 'cahpb']:\n",
    "    # Load the model cube\n",
    "    cube = iris.load_cube(datapath + jobid + 'a.monmean.baseline.05216.rr8.ext.mmday.nc')\n",
    "    \n",
    "    # Quick line plot for each cube \n",
    "    qplt.plot(cube.coord('month_number'), cube, label=jobid)\n",
    "    plt.title('KL area averaged ' + model + ' monthly\\n average of daily rainfall')\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_label_text('Month Number')\n",
    "    ax.set_xlim(0.5, 12.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__d) Now by following the same methodology as above for 1 b) for the KL area find the monthly means 1961-1990 for APHRODITE observations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dirctories to load and save to\n",
    "path_in = 'monthly/APHRODITE/' \n",
    "path_out = 'monthly/climatology/'\n",
    "\n",
    "# Load the KL extracted data created in previous step\n",
    "aphrod = iris.load_cube(path_in + 'aphro.pm.6190.05216.rr8.ext.mmday.nc')\n",
    "\n",
    "# Add monthly coord categorisation to the time dim coordinate\n",
    "iris.coord_categorisation.add_month_number(aphrod, 'time', name='month_number')\n",
    "\n",
    "# Now calculate monthly means\n",
    "aphro_monthly_mean = aphrod.aggregated_by(['month_number'], iris.analysis.MEAN)\n",
    "\n",
    "# create the area averaged monthly mean of daily rainfall \n",
    "aphro_monthly_mean = aphro_monthly_mean.collapsed(['longitude', 'latitude'], iris.analysis.MEAN)\n",
    "\n",
    "# Save output\n",
    "iris.save(aphro_monthly_mean, path_out + 'aphro.monmean.baseline.05216.rr8.ext.mmday.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__e) Plot the observations and the HadCM3Q0 and ECHAM5 driven PRECIS runs. What are the differences between the observations and models, what months are the differences greatest?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directory to read data from\n",
    "path = 'monthly/climatology/'\n",
    "\n",
    "for jobid in ['cahpaa', 'cahpba', 'aphro']:\n",
    "    # Load the cube\n",
    "    cube = iris.load_cube(path + jobid + '.monmean.baseline.05216.rr8.ext.mmday.nc')\n",
    "    \n",
    "    # quick line plot for each cube and holding onto the same plot \n",
    "    qplt.plot(cube.coord('month_number'), cube, label=jobid)\n",
    "    plt.title('KL area averaged ' + id + '\\n monthly average of daily rainfall')\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_label_text('Month Number')\n",
    "    ax.set_xlim(0.5, 12.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Comparing models and observations\n",
    "\n",
    "To compare spatial model and observation fields properly they must be on the same grid. We will regrid to the coarsest grid. For the data used here, the observations have the coarsest resolution so we will regrid the model data onto the observation grid.\n",
    "\n",
    "The PRECIS model data are on a grid known as a Rotated Grid. The idea is that the \"real\" north pole in the Arctic is shifted such that the equator relative to our rotated pole then runs through the centre of the regional model domain.\n",
    "\n",
    "First, we will compare the observations and model data before regridding.\n",
    "\n",
    "__a) Create figures to compare the modelled and observed seasonal mean rainfall totals__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Directory to read in data from\n",
    "datapath = 'monthly/climatology/'\n",
    "\n",
    "# load cahpaa model data\n",
    "model_cube_a = iris.load_cube(datapath + 'cahpaa.OND.mean.baseline.05216.mmday.nc')\n",
    "\n",
    "# load cahpaa model data\n",
    "model_cube_b = iris.load_cube(datapath + 'cahpba.OND.mean.baseline.05216.mmday.nc')\n",
    "\n",
    "# load APHRODITE into a cube \n",
    "obs_cube = iris.load_cube(datapath + 'aphro.OND.mean.baseline.05216.mmday.nc')\n",
    "\n",
    "# Create a figure of the size 6x12 inches\n",
    "plt.figure(figsize=(6, 12))\n",
    "plt.subplot(3, 1, 1)        # Create a new subplot for the model data 3 rows, 1 column, 1st plot\n",
    "qplt.pcolormesh(model_cube_a[0], vmax=10) # quickly plots a colormesh map plot of the model data\n",
    "plt.title('HadCM3Q0 precipitation\\n'\n",
    "          'on a rotated longitude latitude grid')  # plots a title for the plot\n",
    "ax = plt.gca()              # gca function that returns the current axes\n",
    "ax.coastlines()             # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()              # adds x and y grid lines to the plot\n",
    "\n",
    "plt.subplot(3, 1, 2)        # Create a new subplot for the model data, 2nd plot\n",
    "qplt.pcolormesh(model_cube_b[0], vmax=10)\n",
    "plt.title('ECHAM5 precipitation\\n'\n",
    "          'on a rotated longitude latitude grid')\n",
    "ax = plt.gca()\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "\n",
    "plt.subplot(3, 1, 3)        # Create a new subplot for the obs data, 3rd plot       \n",
    "qplt.pcolormesh(obs_cube[0], vmax=10)   # quickly plots a colormesh map plot of the obs data\n",
    "plt.title('Observational APHRODITE precipitation\\n'\n",
    "          'on a coarser global longitude latitude grid') # plots a title for the plot\n",
    "ax = plt.gca()              # gca function that returns the current axes\n",
    "ax.coastlines()             # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()              # adds x and y grid lines to the plot\n",
    "\n",
    "plt.tight_layout()          # automatically adjusts subplot(s) to fit in to the figure area\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b) Regrid the multiannual OND mean model fields onto the observations grid__\n",
    "\n",
    "Here we use the `regrid` method to regrid the target cube. Here we will use linear interpolation. First, load in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory where data is stored\n",
    "data_path = 'monthly/climatology/'\n",
    "\n",
    "# load cahpaa\n",
    "cahpa_model_cube = iris.load_cube(data_path + 'cahpaa.OND.mean.baseline.05216.mmday.nc')\n",
    "# load cahpba\n",
    "cahpb_model_cube = iris.load_cube(data_path + 'cahpba.OND.mean.baseline.05216.mmday.nc')\n",
    "# load APHRODITE into a cube\n",
    "obs_cube = iris.load_cube(data_path + 'aphro.OND.mean.baseline.05216.mmday.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can regrid the model data to the grid used by the observations, the coordinate system used for the observations must be supplied - it is missing from the original NetCDF file.  The observations are on a regular longitude-latitude grid so the correct coordinate system is WGS84.\n",
    "\n",
    "We define the WGS84 coordinate system and then apply it to the x- and y-axes (i.e. longitudes and latitudes) of the observations.  The coordinate system used by the model (the rotated grid) is already defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define WGS84 projection for obs data\n",
    "wgs84 = iris.coord_systems.GeogCS(semi_major_axis=6378137.0, inverse_flattening=298.257223563)\n",
    "\n",
    "# Apply WGS84 to obs cube\n",
    "obs_cube.coord(axis='x').coord_system = wgs84\n",
    "obs_cube.coord(axis='y').coord_system = wgs84\n",
    "\n",
    "# Print out and compare the two coordinate systems\n",
    "print obs_cube.coord_system()\n",
    "print cahpa_model_cube.coord_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few lines regrid the model data to the regular grid used by the observations.  From the figures above, the area over which APHRODITE data are available is larger than the PRECIS model domain. Hence, the extrapolation mode is set to 'mask' so that any grid cells on the APHRODITE grid which do not overlap with model grid cells are masked off; otherwise, the model data would be interpolated which would produce misleading results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Regrid the climate model data onto APHRODITE grid\n",
    "cahpa_regrid = cahpa_model_cube.regrid(obs_cube, iris.analysis.Nearest(extrapolation_mode='mask'))\n",
    "cahpb_regrid = cahpb_model_cube.regrid(obs_cube, iris.analysis.Nearest(extrapolation_mode='mask'))\n",
    "\n",
    "# Save output\n",
    "iris.save(cahpa_regrid, data_path + 'cahpaa.OND.mean.baseline.05216.mmday.rg.nc')\n",
    "iris.save(cahpb_regrid, data_path + 'cahpba.OND.mean.baseline.05216.mmday.rg.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c) Now that the model grids have been regridded to the observation cube: (i) load the netCDF files, and (ii) then plot the APHRODITE and model data again (as above in 15.) to compare them visually once again. What do you note?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# directory where data are stored\n",
    "data_path = 'monthly/climatology/'\n",
    "\n",
    "# Load the data\n",
    "cahpa_regrid = iris.load_cube(data_path + 'cahpaa.OND.mean.baseline.05216.mmday.rg.nc')\n",
    "cahpb_regrid = iris.load_cube(data_path + 'cahpba.OND.mean.baseline.05216.mmday.rg.nc')\n",
    "obs_cube = iris.load_cube(data_path + 'aphro.OND.mean.baseline.05216.mmday.nc')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(6, 12))\n",
    "plt.subplot(3, 1, 1)        # Create a new subplot for the model data 3 rows, 1 column, 1st plot\n",
    "qplt.pcolormesh(cahpa_regrid[0], vmax=10) # quickly plots a colormesh map plot of the model data\n",
    "plt.title('HadCM3Q0 precipitation\\n'\n",
    "          'on a global longitude latitude grid')  # plots a title for the plot\n",
    "ax = plt.gca()              # gca function that returns the current axes\n",
    "ax.coastlines()             # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()              # adds x and y grid lines to the plot\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "qplt.pcolormesh(cahpb_regrid[0], vmax=10)\n",
    "plt.title('ECHAM5 precipitation\\n'\n",
    "          'on a global longitude latitude grid')\n",
    "ax = plt.gca()\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "\n",
    "plt.subplot(3, 1, 3)        # Create a new subplot for the obs data\n",
    "qplt.pcolormesh(obs_cube[0], vmax=10)\n",
    "plt.title('Observational APHRODITE precipitation\\n'\n",
    "          'on a coarser global longitude latitude grid')\n",
    "ax = plt.gca()\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "\n",
    "plt.tight_layout()          # automatically adjusts subplot(s) to fit in to the figure area\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__d) Find the difference between the model and the observation OND multiannual mean fields and plot maps to view the differences__\n",
    "\n",
    "We can simply subtract the model data from the observations.  There is a subtract function within Iris but it cannot be used here.  The model cubes contain extra coordinates which are not present in the obs cube; Iris requires all coordinates within the cubes to match exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load cubes, note this must be the regridded model cubes to compare as they must have the same lat/lon\n",
    "# and time dimensions\n",
    "\n",
    "data_path = 'monthly/climatology/'\n",
    "\n",
    "cahpa_cube = iris.load_cube(data_path + 'cahpaa.OND.mean.baseline.05216.mmday.rg.nc')\n",
    "cahpb_cube = iris.load_cube(data_path + 'cahpba.OND.mean.baseline.05216.mmday.rg.nc')\n",
    "obs_cube   = iris.load_cube(data_path + 'aphro.OND.mean.baseline.05216.mmday.nc')\n",
    "\n",
    "# Make sure units are the same\n",
    "obs_cube.units = cahpb_cube.units\n",
    "\n",
    "# Make recieving cube\n",
    "cahpa_obs_diff = obs_cube.copy()\n",
    "cahpb_obs_diff = obs_cube.copy()\n",
    "\n",
    "# Replace data with the differences\n",
    "cahpa_obs_diff.data = cahpa_cube.data - obs_cube.data\n",
    "\n",
    "# cahpb - aphrodite differences\n",
    "cahpb_obs_diff.data = cahpb_cube.data - obs_cube.data\n",
    "\n",
    "# Save the differences\n",
    "iris.save(cahpa_obs_diff, data_path + 'diff.cahpa_aphro.OND.baseline.nc')\n",
    "iris.save(cahpb_obs_diff, data_path + 'diff.cahpb_aphro.OND.baseline.nc')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot(1, 2, 1)           # Create a new subplot for the first differences, 2 rows, 1 column, 1st plot\n",
    "\n",
    "# Cut-out region with data. We use the intersection method to plot the region with data\n",
    "qplt.pcolormesh(cahpa_obs_diff[0].intersection(longitude=(90, 135), latitude=(-20, 32)), \n",
    "                vmax=10, vmin=-10, \n",
    "                cmap=plt.get_cmap('RdYlBu'))   # Note this is where cube slicing is needed as you can only plot 2-coordinate\n",
    "                               # dimensions with qplt.contourf, so here we have selected time[0] as there is only\n",
    "                               # one timestep (the baseline 1961-1990 mean)\n",
    "\n",
    "plt.title('Cahpa model and obs diff')       # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()                 # adds x and y grid lines to the plot\n",
    "\n",
    "plt.subplot(1, 2, 2)           # Create a new subplot for the model data 2 row, 2 columns, 2nd plot\n",
    "qplt.pcolormesh(cahpb_obs_diff[0].intersection(longitude=(90, 135), latitude=(-20, 32)),\n",
    "             vmax=10, vmin=-10,\n",
    "             cmap=plt.get_cmap('RdYlBu'))\n",
    "\n",
    "plt.title('Cahpb model and obs diff')       # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()                 # adds x and y grid lines to the plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Climatological mean and annual cycle for an ensemble\n",
    "\n",
    "So far data from two models downscaled with PRECIS have been analysed. In this section an ensemble of six models will be used, five from the HadCM3 QUMP ensemble (discussed in the model ensemble lecture) and one ECHAM5 model. The five members of the QUMP ensemble are HadCM3Q0 (cahpa), HadCM3Q3 (cahpc), HadCM3Q10 (cahpd), HadCM3Q11 (cahpe) and HadCM3Q13 (cahpf).\n",
    "\n",
    "Taking an ensemble approach allows us to account for a range of uncertainty in the model projections. Typing the python and IRIS commands into the command line for all six ensemble members would be very time consuming, so we use a script instead.\n",
    "\n",
    "The script has been written below to generate cubes of ensemble members which can then be saved as one netCDF file. Each ensemble member is identified by its model runid and is listed under a realization dimension coordinate that has been added to the cube. \n",
    "\n",
    "_(More robust coding practise would to write a series of functions, but we leave this as a future exercise for the reader)_\n",
    "\n",
    "__a) Calculate the OND seasonal mean and annual cycle (for the KL area) for 1.5m temperature and precipitation for CRU and APHRODITE observations__\n",
    "\n",
    "The CRU data are a monthly global land-only dataset (1901-present) at 0.5 degree resolution. Nine variables are available, including mean, min, max temperature and precipitation. For further details please see: http://www.cru.uea.ac.uk/~timm/grid/CRU_TS_2_1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The purpose of this script is to load the CRU temperature data and APHRODITE rainfall data, and then create (a) the OND\n",
    "seasonal mean and (b) monthly means averaged over Kuala Lumpur\n",
    "'''\n",
    "# Data directory paths in for loading and out for saving\n",
    "data_path_in  = 'monthly/'\n",
    "data_path_out = 'monthly/climatology/'\n",
    "\n",
    "# Constraint for area of CRU data covered by PRECIS domain\n",
    "# Values from script 'worksheet2.sh'\n",
    "model_constraint = iris.Constraint(longitude = lambda cell: 90.0 <= cell <= 137.0,\n",
    "                                latitude = lambda cell: -14.0 <= cell <= 31.0)\n",
    "\n",
    "scodes = ['03236', '05216']\n",
    "\n",
    "for scode in scodes:\n",
    "    # Load the CRU or APHRODITE data for the PRECIS model domain using the area constraint\n",
    "    if scode == '03236':\n",
    "        filename = 'CRU/cru.pm.6190.03236.nc'\n",
    "    else:\n",
    "        filename = 'APHRODITE/aphro.mon.6190.nc'\n",
    "    obs_cube = iris.load_cube(data_path_in + filename, model_constraint)\n",
    "\n",
    "    # In order to calculate OND mean, add a season membership coordinate\n",
    "    iris.coord_categorisation.add_season(obs_cube, 'time', name='seasons', seasons=('jfmamjjas','ond'))\n",
    "\n",
    "    # Extract data for OND only\n",
    "    obs_cube_ond = obs_cube.extract(iris.Constraint(seasons='ond'))\n",
    "\n",
    "    # Now calculate the mean over this season\n",
    "    obs_ond_mean = obs_cube_ond.aggregated_by(['seasons'], iris.analysis.MEAN)\n",
    "\n",
    "    # Add units description to temperature cube\n",
    "    # Save output\n",
    "    if scode == '03236':\n",
    "        obs_ond_mean.units = 'celsius'\n",
    "        file_head = 'cru.OND.mean.baseline.'\n",
    "    else:\n",
    "        obs_ond_mean.units = 'mm day-1'\n",
    "        file_head = 'aphro.OND.mean.baseline.'\n",
    "\n",
    "    print \"Saving file \" + file_head + scode + '.nc'\n",
    "    iris.save(obs_ond_mean, data_path_out + file_head + scode + '.nc')\n",
    "\n",
    "    # Select area around KL from the original data # MIGHT NEED TO REVISE LIMITS?\n",
    "    obs_cube_KL = obs_cube.intersection(longitude=(101.25,102.15), latitude=(2.74,3.48))\n",
    "    \n",
    "    # Add monthly categorisation to the time dimension coordinate\n",
    "    iris.coord_categorisation.add_month_number(obs_cube_KL, 'time', name='month_number')\n",
    "\n",
    "    # Calculate monthly mean values\n",
    "    obs_monthly_mean = obs_cube_KL.aggregated_by(['month_number'], iris.analysis.MEAN)\n",
    "\n",
    "    # Calculate area averaged monthly means for KL\n",
    "    obs_monthly_mean = obs_monthly_mean.collapsed(['longitude', 'latitude'], iris.analysis.MEAN)\n",
    "\n",
    "    # Save the observed monthly mean values\n",
    "    print \"Saving monthly mean file ...\"\n",
    "    if scode == '03236':\n",
    "        iris.save(obs_monthly_mean, data_path_out + 'cru.monmean.baseline.' + scode + '.ext.KL.nc')\n",
    "    else:\n",
    "        iris.save(obs_monthly_mean, data_path_out + 'aphro.monmean.baseline.' + scode + '.ext.KL.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b) Next, we repeat the operations on the six sets of model data - i.e., we create OND mean values and monthly means for the KL region__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Model runs:\n",
    "(1) Load each model run id extracted for KL and create OND seasonal mean, regrid to observation grid\n",
    "(2) Load each model runid for the KL region and then create the OND seasonal mean, regrid to the coaser\n",
    "observation model grid and merge all cubes into one cube of ensemble members\n",
    "(3) calculate the difference between models and observations\n",
    "'''\n",
    "# Data directory paths in for loading and out for saving\n",
    "data_path_in  = 'monthly/'\n",
    "data_path_out = 'monthly/climatology/'\n",
    "\n",
    "# These coordinates are for a regular grid as used by the CRU data\n",
    "KL_constraint = iris.Constraint(longitude = lambda cell: 101.25 <= cell <= 102.15,\n",
    "                                latitude = lambda cell: 2.74 <= cell <= 3.48)\n",
    "\n",
    "# These coordinates are for the rotated grid used by PRECIS\n",
    "KL_constraint_rotg = iris.Constraint(grid_longitude = lambda cell: -8.17 <= cell <= -7.43,\n",
    "                                grid_latitude = lambda cell: -12.10 <= cell <= -11.38)\n",
    "\n",
    "scodes = ['03236', '05216']\n",
    "\n",
    "# Define WGS84 projection for obs data. Required to regrid the model data to the obs grid\n",
    "wgs84 = iris.coord_systems.GeogCS(semi_major_axis=6378137.0, inverse_flattening=298.257223563)\n",
    "\n",
    "for scode in scodes:\n",
    "    # Load the observed OND mean\n",
    "    if scode == '03236':\n",
    "        units = 'degC'\n",
    "        obs_ond_mean = iris.load_cube(data_path_out + 'cru.OND.mean.baseline.' + scode + '.nc')\n",
    "    else:\n",
    "        obs_ond_mean = iris.load_cube(data_path_out + 'aphro.OND.mean.baseline.' + scode + '.nc')\n",
    "        units = 'mmday'\n",
    "    # Apply WGS84 to obs cube\n",
    "    obs_ond_mean.coord(axis='x').coord_system = wgs84\n",
    "    obs_ond_mean.coord(axis='y').coord_system = wgs84\n",
    "\n",
    "    # Loop over each  model runid. We use enumerate, so the variable 'member' runs from 0 to the number of models (6) minus 1\n",
    "    for i, model in enumerate('abcdef'):\n",
    "        runid = 'cahp' + model\n",
    "          \n",
    "        # Load the model data\n",
    "        subdir = '{}/{}/'.format(runid, scode)\n",
    "        file_in = '{}a.pm.6190.{}.rr8.nc'.format(runid, scode)\n",
    "        model_cube = iris.load_cube(data_path_in + subdir + file_in)\n",
    "          \n",
    "        # In order to calculate OND mean, need to add a season membership coordinate\n",
    "        iris.coord_categorisation.add_season(model_cube, 'time', name='seasons', seasons=('jfmamjjas','ond'))\n",
    "\n",
    "        # Then extract the part of the cube containing the OND season\n",
    "        model_cube_ond = model_cube.extract(iris.Constraint(seasons='ond'))\n",
    "\n",
    "        # Calculate the mean for the OND season\n",
    "        model_ond_mean = model_cube_ond.aggregated_by(['seasons'], iris.analysis.MEAN)\n",
    "\n",
    "        # Change the temperature units from Kelvin to degC, or mm s-1 to mm day-1\n",
    "        if scode == '03236':\n",
    "            model_ond_mean.convert_units('celsius')\n",
    "        else:\n",
    "            model_ond_mean.convert_units('kg m-2 day-1')\n",
    "    \n",
    "        # Save the model OND mean\n",
    "        file_out = '{}a.OND.mean.baseline.{}.{}.nc'.format(runid, scode, units)\n",
    "        iris.save(model_ond_mean, data_path_out + file_out)\n",
    "        print \"saved \" + file_out\n",
    "\n",
    "        # Regrid to observation grid\n",
    "        model_ond_mean_rg = model_ond_mean.regrid(obs_ond_mean, iris.analysis.Linear())\n",
    "        file_out = '{}a.OND.mean.baseline.{}.{}.rg.nc'.format(runid, scode, units)\n",
    "        iris.save(model_ond_mean_rg, data_path_out + file_out)\n",
    "\n",
    "        # Subtract the obs OND mean from the model OND mean and save the difference\n",
    "        model_ond_diff = obs_ond_mean.copy()\n",
    "        model_ond_diff.data = model_ond_mean_rg.data - obs_ond_mean.data\n",
    "\n",
    "        if scode == '03236':\n",
    "            model_ond_diff.units = 'celsius'\n",
    "            iris.save(model_ond_diff, data_path_out + 'diff.' + runid + '_cru.OND.baseline.nc')\n",
    "        else:\n",
    "            model_ond_diff.units = 'mm day-1'\n",
    "            iris.save(model_ond_diff, data_path_out + 'diff.' + runid + '_aphro.OND.baseline.nc')\n",
    "\n",
    "        # Remove the seasons coordinate as it is no longer needed\n",
    "        model_cube.remove_coord('seasons')\n",
    "\n",
    "        # Calculate monthly mean values for each model in the KL domain\n",
    "        # Add monthly coord categorisation to the time dimension coordinate of the KL data\n",
    "        iris.coord_categorisation.add_month_number(model_cube, 'time', name='month_number')\n",
    "\n",
    "        # Calculate monthly mean values\n",
    "        model_monthly_mean = model_cube.aggregated_by(['month_number'], iris.analysis.MEAN)\n",
    "\n",
    "        # Change the temperature units from Kelvin to degC, or mm s-1 to mm day-1\n",
    "        if scode == '03236':\n",
    "            model_monthly_mean.convert_units('celsius')\n",
    "        else:\n",
    "            model_monthly_mean.convert_units('kg m-2 day-1')\n",
    "\n",
    "        # Regrid to observation grid\n",
    "        model_monthly_mean_rg = model_monthly_mean.regrid(obs_ond_mean, iris.analysis.Linear())\n",
    "\n",
    "        # Extract the region around Kuala Lumpur\n",
    "        model_mm_KL = model_monthly_mean_rg.extract(KL_constraint)\n",
    "\n",
    "        # Calculate area averaged monthly mean temperatures / rainfall for KL\n",
    "        model_KL = model_mm_KL.collapsed(['longitude', 'latitude'], iris.analysis.MEAN)\n",
    "    \n",
    "        # Define and add an ensemble realization coordinate. The cube will now contain a new scalar coordinate named\n",
    "        # 'realization' which will have the value 'member+1' (so the members are numbered 1, 2, ...)\n",
    "        coord = iris.coords.AuxCoord(i+1, 'realization')\n",
    "        model_KL.add_aux_coord(coord)    \n",
    "\n",
    "        # Save the model monthly mean values for the KL area\n",
    "        file_out = '{}a.monthly.mean.baseline.{}.{}.ext.KL.rg.nc'.format(runid, scode, units)\n",
    "        iris.save(model_KL, data_path_out + file_out)\n",
    "        print \"saved \" + file_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__c) Calculate the differences between the models and observations for each ensemble member__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data directory path in for loading and out for saving\n",
    "data_path = 'monthly/climatology/'\n",
    "scodes = ['03236', '05216']\n",
    "\n",
    "for scode in scodes:\n",
    "    # Load the observed OND mean\n",
    "    if scode == '03236':\n",
    "        units = 'degC'\n",
    "        obs_monthly_mean = iris.load_cube(data_path + 'cru.monmean.baseline.' + scode + '.ext.KL.nc')\n",
    "    else:\n",
    "        units = 'mmday'\n",
    "        obs_monthly_mean = iris.load_cube(data_path + 'aphro.monmean.baseline.' + scode + '.ext.KL.nc')\n",
    "\n",
    "    # Load in the modelled monthly mean values and subtract the observations\n",
    "    for model in 'abcdef':\n",
    "        runid = 'cahp' + model\n",
    "        filename = '{}a.monthly.mean.baseline.{}.{}.ext.KL.rg.nc'.format(runid, scode, units)\n",
    "        model_monthly_mean = iris.load_cube(data_path + filename)\n",
    "        diff = obs_monthly_mean.copy()\n",
    "        diff.data = model_monthly_mean.data - obs_monthly_mean.data\n",
    "        file_out = '{}a.monthly.mean.diff.{}.ext.KL.nc'.format(runid, scode)\n",
    "        iris.save(diff, data_path + file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__d) Create four figures: the monthly cycles of temperature and rainfall from the 6 models and the observations, and the monthly differences between the models and observations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data directory path in for loading and out for saving\n",
    "data_path = 'monthly/climatology/'\n",
    "\n",
    "month_names = calendar.month_abbr\n",
    "scodes = ['03236', '05216']\n",
    "\n",
    "plotnum = 0\n",
    "\n",
    "# Plot the monthly mean cycles\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "for scode in scodes:\n",
    "    if scode == '03236':\n",
    "        units = 'degC'\n",
    "        ylabel = 'Temperature / $\\degree$C'\n",
    "        varname = 'temperature'\n",
    "    else:\n",
    "        units = 'mmday'\n",
    "        ylabel = 'Rainfall / mm day-1'\n",
    "        varname = 'rainfall'\n",
    "\n",
    "    plotnum = plotnum + 1\n",
    "    plt.subplot(4, 1, plotnum)\n",
    "\n",
    "    for model in 'abcdef':\n",
    "        runid = 'cahp' + model\n",
    "        # Load the model cube\n",
    "        filename = '{}a.monthly.mean.baseline.{}.{}.ext.KL.rg.nc'.format(runid, scode, units)\n",
    "        model_monthly_mean = iris.load_cube(data_path + filename)\n",
    "\n",
    "        # Use the month numbers from the cube, will be used as x-axis values\n",
    "        qplt.plot(model_monthly_mean.coord('month_number'), model_monthly_mean, linewidth=2)\n",
    "\n",
    "    # Load and plot the observed monthly cycle\n",
    "    if scode == '03236':\n",
    "        obs_monthly_mean = iris.load_cube(data_path + 'cru.monmean.baseline.' + scode + '.ext.KL.nc')\n",
    "    else:\n",
    "        obs_monthly_mean = iris.load_cube(data_path + 'aphro.monmean.baseline.' + scode + '.ext.KL.nc')\n",
    "\n",
    "    qplt.plot(obs_monthly_mean.coord('month_number'), obs_monthly_mean, color='black', linewidth=3)\n",
    "\n",
    "    # Set the axis limits, use month names on the x-axis\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim(0.5, 12.5)\n",
    "    ax.set_xticks(range(1,13))\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_xticklabels(month_names[1:])\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title('KL area averaged ' + varname + ' / ' + units)\n",
    "\n",
    "    # Now plot the monthly cycles of the differences between the models and observations\n",
    "    plotnum = plotnum + 1\n",
    "    plt.subplot(4, 1, plotnum)\n",
    "\n",
    "    for id in range(ord('a'), ord('f')+1):\n",
    "        runid = 'cahp' + chr(id)\n",
    "        # Load the differences between the model and observations\n",
    "        filename = '{}a.monthly.mean.diff.{}.ext.KL.nc'.format(runid, scode)\n",
    "        model_diff = iris.load_cube(data_path + filename)\n",
    "        qplt.plot(model_diff.coord('month_number'), model_diff, linewidth=2)\n",
    "\n",
    "    bx = plt.gca()\n",
    "    bx.set_xlim(0.5, 12.5)\n",
    "    bx.set_xticks(range(1,13))\n",
    "    bx.set_xticklabels(month_names[1:])\n",
    "    bx.set_xlabel('')\n",
    "    bx.set_ylabel(ylabel)\n",
    "    bx.set_title('KL area averaged ' + varname + ' differences')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

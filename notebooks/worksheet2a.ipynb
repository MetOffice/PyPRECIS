{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <style type=\"text/css\">\n",
    "  body     {background      : white;\n",
    "            font-family     : \"arial\";\n",
    "            font-size       : 10pt;\n",
    "            font-weight     : normal;\n",
    "\t    color           : black;}\n",
    "  h1       {text-align      : left;\n",
    "            color           : black;\n",
    "            font-size       : 16pt; \n",
    "\t    font-weight\t    : bold;\n",
    "            background      : rgb(186,240,10);\n",
    "            padding         : 5px;\n",
    "          -moz-border-radius: 10px 10px 10px 10px;}\n",
    "  h2       {text-align      : left;\n",
    "            color           : black;\n",
    "            font-size       : 12pt; \n",
    "\t    font-weight\t    : bold;\n",
    "            background      : rgb(186,240,10);\n",
    "            padding         : 5px;\n",
    "          -moz-border-radius: 10px 10px 10px 10px;}\n",
    "  h3\t   {text-align      : left;\n",
    "            color           : black;\n",
    "            font-size       : 10pt; \n",
    "            font-weight     : normal;\n",
    "            background      : rgb(196,202,193);\n",
    "            padding         : 5px;\n",
    "          -moz-border-radius: 10px 10px 10px 10px;}\n",
    "  h4\t   {text-align      : left;\n",
    "            color           : white;\n",
    "            font-size       : 24pt; \n",
    "            font-weight     : bold;\n",
    "            background      : black;\n",
    "            padding         : 5px;}\n",
    "  h5\t   {text-align      : left;\n",
    "            color           : black;\n",
    "            font-size       : 10pt; \n",
    "            font-weight     : normal;\n",
    "            border          : 1px rgb(0,173,208) solid;\n",
    "            padding         : 5px;\n",
    "          -moz-border-radius: 10px 10px 10px 10px;}\n",
    "  p        {text-align      : center;}\n",
    "  \n",
    "  a        {text-decoration : none;\n",
    "            color           : rgb(3,31,115);}\n",
    "  a:hover  {background      : rgb(135,136,0); \n",
    "            color           : white;}\n",
    "  a:active {background      : white; \n",
    "            color           : rgb(135,136,0);}\n",
    "  ul       {list-style-type : square;\n",
    "            list-style-image: url(Images/Arrow.gif);\n",
    "            font-size       : 10pt;}\n",
    "  table    {text-align      : left;\n",
    "            font-family     : \"times new roman\";\n",
    "            font-weight     : normal;\n",
    "            font-size       : 10pt;\n",
    "            color           : black;\n",
    "            background-color: rgb(245,255,240);\n",
    "            border          : 1px rgb(186,240,10) solid;\n",
    "            border-collapse : seperate;\n",
    "            border-spacing  : 5px;\n",
    "            padding         : 0px;\n",
    "          -moz-border-radius: 10px 10px 10px 10px;}\n",
    "  table.header {valign      : center;\n",
    "            font-family     : \"times new roman\";\n",
    "            font-weight     : normal;\n",
    "            font-size       : 10pt;\n",
    "            color           : white;\n",
    "            background-color: black;\n",
    "            border          : 1px rgb(186,240,10) solid;\n",
    "            border-collapse : seperate;\n",
    "            border-spacing  : 5px;\n",
    "            padding         : 0px;\n",
    "          -moz-border-radius: 10px 10px 10px 10px;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 2: Introduction to using Python and the Python Library IRIS for analysis and visualisation\n",
    "\n",
    "In this worksheet sample PRECIS output over Southeast Asia driven by HadCM3Q0 and ECHAM5 is compared with observations for validation purposes. Validation of model results by comparison with observed data is an essential step. It is the measure by which we can assess the quality of the model and it informs appropriate uses of the data.\n",
    "\n",
    "\n",
    "Here, we use PRECIS output driven by two different GCMs. Using data from both experiments will give us two representations of present day climate and two possible climate scenarios. For more details on multimodel approaches see the PRECIS workshop lecture on climate model ensembles.\n",
    "\n",
    "\n",
    "The following are examples of types of analyses undertaken as part of a model validation. The methods shown are not necessarily the only way to proceed and are intended to demonstrate the use of Iris in model validation, and provide a starting point for your own analyses. For further help on validating your PRECIS simulations, refer to the PRECIS workshop lecture notes.\n",
    "\n",
    "__Note:__ <span style=\"color:red\">The data used here has been processed in the same way as Worksheet 1. The 8 point-rim has been removed and it has been converted from PP to netCDF format.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Inspecting the data\n",
    "\n",
    "The datasets used here are daily and monthly data from two PRECIS runs carried out over Southeast Asia, one driven by HadCM3Q0 and the other driven by ECHAM5. The observations used for comparison are from the [APHRODITE gridded observational data set](https://climatedataguide.ucar.edu/climate-data/aphrodite-asian-precipitation-highly-resolved-observational-data-integration-towards).\n",
    "\n",
    "As we saw in previous workshop in Iris, data are read into an object called a cube. A cube contains the data of interest (e.g., temperature, rainfall, wind speeds) and metadata about a phenomenon. A single cube describes only one type of data. It is not possible for a cube to contain both temperature and rainfall, for example. A cube always has a name, a unit and an n-dimensional data array to represents the cubeâ€™s data. Additionally, the cube contains collections of coordinates.  Coordinate types can include spatial information (latitude, longitude, altitude), times, or other information, e.g., an ensemble number.\n",
    "\n",
    "__1 a.) Load the data netCDF file for the HadCM3Q0 and ECHAM5 model data and the APHRODITE rainfall observation data and print the cube output.__\n",
    "\n",
    "A cube has coordinates (for example time, longitude, latitude, model levels etc) and this information can be accessed with commands. In the following exercise we follow a similar example to that in the [Iris documentation](http://scitools.org.uk/iris/docs/latest/userguide/navigating_a_cube.html#accessing-coordinates-on-the-cube) and find the latitude and longitude of the corners of the locations for the APHRODITE data. You can do so by printing the latitude and longitude coordinates (.points) and note the first and last values in the array.\n",
    "\n",
    "Before running the code take a look at it line by line to understand what steps are being made. Add code where prompted and then click in the box and press 'ctrl' + 'enter' to run the code. The output will be printed below. If you have an error try again or ask for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This command ensures we are in the correct directory. Edit it as necessary to the directory you are working from.\n",
    "%cd /media/sf_share/UK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enusre you are using Iris version 1.10 or greater\n",
    "import iris\n",
    "print \"Using Iris version: \", iris.__version__\n",
    "\n",
    "# the following is needed to be compliant with the Iris's latest NetCDF default saving behaviour\n",
    "iris.FUTURE.netcdf_promote = 'True'\n",
    "iris.FUTURE.netcdf_no_unlimited = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feed in the names of the directories where the netCDF model files are stored\n",
    "path_in_cahpa   = '/net/data/users/ssadri/data-local/PRECIS_WORK/practise_ppfiles/monthly/cahpa/05216/'\n",
    "path_in_cahpb   = '/net/data/users/ssadri/data-local/PRECIS_WORK/practise_ppfiles/monthly/cahpb/05216/'\n",
    "path_in_APHRODITE   = '/net/data/users/ssadri/data-local/PRECIS_WORK/practise_ppfiles/monthly/APHRODITE/'\n",
    "print 'Date paths were set.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and print the HadCM3Q0 (cahpa) model cube data\n",
    "cahpa_data_cube = iris.load_cube(path_in_cahpa + 'cahpaa.pm.6190.05216.rr8.nc')\n",
    "print 'This is the HadCM3Q0 cube'\n",
    "print cahpa_data_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and print the ECHAM5 (cahpb) model cube data\n",
    "cahpb_data_cube = iris.load_cube(path_in_cahpb + 'cahpba.pm.6190.05216.rr8.nc')\n",
    "print 'This is the ECHAM5 cube'\n",
    "print cahpb_data_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load and print the APHRODITE observation cube data\n",
    "aphrodite_data_cube = iris.load_cube(path_in_APHRODITE + 'aphro.mon.6190.nc')\n",
    "print 'This is the APHRODITE cube'\n",
    "print aphrodite_data_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The coord objects of the data cubes contain the co-ordinate points of the data\n",
    "print 'This is the APHRODITE cube latitude coordinate data'\n",
    "print  aphrodite_data_cube.coord('latitude').points\n",
    "\n",
    "print 'This is the APHRODITE cube longitude coordinate data'\n",
    "print  aphrodite_data_cube.coord('longitude').points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1 b.) Extract a subset of the data within a cube__\n",
    "\n",
    "The ability to extractis an important function in Iris. The extraction of a subset of data is called slicing.  For example, it could be necessary to extract data over all latitude and longitude grid points on the first time step. For more information around subsetting cubes please read further here: (http://scitools.org.uk/iris/docs/latest/userguide/subsetting_a_cube.html#cube-indexing)\n",
    "\n",
    "__Using the HacCM3Q0 data, the example below shows how to subset a cube for the first time and last timesteps. Note: this method will be used later for plotting data from a cube.__ \n",
    "\n",
    "Work through the example below line by line then click in the box and press 'ctrl' + 'enter' to run the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the netCDF file into a cube\n",
    "cahpa_data_cube = iris.load_cube(path_in_cahpa + 'cahpaa.pm.6190.05216.rr8.nc')\n",
    "\n",
    "print 'This is the cube with all timesteps'\n",
    "print cahpa_data_cube\n",
    "print\n",
    "\n",
    "print 'This is the first time step of the cube' \n",
    "print cahpa_data_cube[0]\n",
    "print\n",
    "\n",
    "print 'This is the last time step of the cube'\n",
    "print cahpa_data_cube[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Converting units\n",
    "\n",
    "* Convert the OND (October, November, December) seasonal precipitation fields for both runs from kg/m2/s (equivalent to mm/s) to mm/day.\n",
    "\n",
    "We could just multiply the raw data in mm/s by 86400 seconds, but a clearer way is to use the ___convert_units___ method/function with the name of the units we want to convert the data into.\n",
    "\n",
    "For clarity let's do this for the ___cahpa___ historical data first and break down the steps as follow:\n",
    "\n",
    "* Read in the historic netCDF file into an Iris cube and print the cube\n",
    "* Print the units and summary statistic about the data\n",
    "* Convert the unit and print the information again\n",
    "* Rename the nuits value in the cube and save it as a new netCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the name of the historical netCDF file to load\n",
    "cahpa_historic_file = 'cahpaa.pm.6190.05216.rr8.nc'\n",
    "\n",
    "# read in the file into an iris cube and print it\n",
    "cahpa_historic_cube = iris.load_cube(path_in_cahpa + cahpa_historic_file)\n",
    "\n",
    "print cahpa_historic_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the units and summary statistic about the data #\n",
    "import numpy as np\n",
    "\n",
    "# print the unit\n",
    "print 'The current unit for data is : '\n",
    "print cahpa_historic_cube.units\n",
    "\n",
    "# print the summary statistic (maximum monthly precipitation)\n",
    "print 'This is an example rainfall rate (kg m-2 s-1) prior to conversion:'\n",
    "print np.amax(cahpa_historic_cube.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the unit and print the information again #\n",
    "                                \n",
    "# convert units to kg m-2 day-1 (same as multiplying by 86400 seconds)\n",
    "cahpa_historic_cube.convert_units('kg m-2 day-1')\n",
    "\n",
    "# print the summary statistic (maximum monthly precipitation) after the unit conversion\n",
    "print 'This is the same rainfall rate but in (kg m-2 day-1)'\n",
    "print 'I.e. converted to rainfall per day rather than per second.'\n",
    "print 'This is equivalent to multiplying by 86400 seconds:'\n",
    "print np.amax(cahpa_historic_cube.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename the nuits value in the cube and save it as a new netCDF file #\n",
    "\n",
    "# change to the directory where you want the new file is saved\n",
    "%cd $path_in_cahpa\n",
    "\n",
    "# Rename the units to mm day-1. 1 kg m-2 is equivalent to 1 mm of rain\n",
    "cahpa_historic_cube.units = 'mm day-1'\n",
    "\n",
    "# Print cube.units to view new units for precipitation\n",
    "print 'The new rainfall units are:'\n",
    "print cahpa_historic_cube.units\n",
    "print\n",
    "\n",
    "# rename the output file name to reflect the changed units\n",
    "new_cahpa_historic_file = cahpa_historic_file.replace('.nc', '.mmday.nc')\n",
    "\n",
    "# save the cube into a new netCDF file\n",
    "iris.save(cahpa_historic_cube, new_cahpa_historic_file)\n",
    "print 'The cube has been saved as a new netCDF file:: ' + new_cahpa_historic_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Below we follow the same proceedure for ___cahpb___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print '======================================='\n",
    "print 'First load the data into an Iris cube and print the cube'\n",
    "print '======================================='\n",
    "\n",
    "cahpb_historic_file = 'cahpba.pm.6190.05216.rr8.nc'\n",
    "\n",
    "# read in the file into an iris cube and print it\n",
    "cahpb_historic_cube = iris.load_cube(path_in_cahpb + cahpb_historic_file)\n",
    "\n",
    "print cahpb_historic_cube\n",
    "print '======================================='\n",
    "print 'Next print the units and summary statistic about the data'\n",
    "print '======================================='\n",
    "\n",
    "# print the unit\n",
    "print 'The current unit for data is : '\n",
    "print cahpb_historic_cube.units\n",
    "\n",
    "# print the summary statistic (maximum monthly precipitation)\n",
    "print 'This is an example rainfall rate (kg m-2 s-1) prior to conversion:'\n",
    "print np.amax(cahpb_historic_cube.data)\n",
    "print '======================================='\n",
    "print 'Then convert the unit and print the information again'\n",
    "print '======================================='\n",
    "\n",
    "# convert units to kg m-2 day-1 (same as multiplying by 86400 seconds)\n",
    "cahpb_historic_cube.convert_units('kg m-2 day-1')\n",
    "\n",
    "# print the summary statistic (maximum monthly precipitation) after the unit conversion\n",
    "print 'This is the same rainfall rate but in (kg m-2 day-1)'\n",
    "print 'I.e. converted to rainfall per day rather than per second.'\n",
    "print 'This is equivalent to multiplying by 86400 seconds:'\n",
    "print np.amax(cahpb_historic_cube.data)\n",
    "print '======================================='\n",
    "print 'Finally rename the nuits value in the cube and save it as a new netCDF file'\n",
    "print '======================================='\n",
    "print 'Changing to the directory:'\n",
    "\n",
    "# change to the directory where you want the new file is saved\n",
    "%cd $path_in_cahpb\n",
    "\n",
    "# Rename the units to mm day-1. 1 kg m-2 is equivalent to 1 mm of rain\n",
    "cahpb_historic_cube.units = 'mm day-1'\n",
    "print\n",
    "# Print cube.units to view new units for precipitation\n",
    "print 'The new rainfall units are:'\n",
    "print cahpb_historic_cube.units\n",
    "print\n",
    "\n",
    "# rename the output file name to reflect the changed units\n",
    "new_cahpb_historic_file = cahpb_historic_file.replace('.nc', '.mmday.nc')\n",
    "\n",
    "# save the cube into a new netCDF file\n",
    "iris.save(cahpb_historic_cube, new_cahpb_historic_file)\n",
    "print 'The cube has been saved as a new netCDF file: ' + new_cahpb_historic_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Climatological mean calculation\n",
    "\n",
    "__1 a. ) Calculate the 1961-1990 seasonal mean precipitation field for October-December (OND) from both the HadCM3Q0 (cahpa) and ECHAM5 (cahpb) driven PRECIS runs.__\n",
    "\n",
    "Work through the example below line by line then click in the box and press 'ctrl' + 'enter' to run the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import iris\n",
    "import iris.coord_categorisation\n",
    "import os\n",
    "\n",
    "try:\n",
    "    os.mkdir('monthly/climatology')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "path_out = \"monthly/climatology/\"\n",
    "\n",
    "for jobid in ['cahpa', 'cahpb']:\n",
    "\n",
    "    path_in = \"monthly/\" + jobid + \"/05216/\"\n",
    "\n",
    "# Load the data\n",
    "    data = iris.load_cube(path_in + jobid + 'a.pm.6190.05216.rr8.mmday.nc')\n",
    "\n",
    "# In order to calculate OND mean, we use the command below to add season membership coordinate\n",
    "# The seasons can be any sequence of months, identified by the first letters of the names of the months.\n",
    "# Here, we define two seasons, jfmamjjas (the months we are not interested in) and ond (October, November and\n",
    "# December), the months we do want.\n",
    "    iris.coord_categorisation.add_season(data, 'time', name='seasons', seasons=('jfmamjjas','ond'))\n",
    "\n",
    "# This command extracts data for the OND season using a constraint\n",
    "    data_ond = data.extract(iris.Constraint(seasons='ond'))\n",
    "    print 'This is the seasonal OND constrained cube'\n",
    "    print data_ond\n",
    "    print \n",
    "\n",
    "# The cube data_ond contains data for October-December for all years. The command below\n",
    "# calculates the mean over all years.\n",
    "    seasonal_mean = data_ond.aggregated_by(['seasons'], iris.analysis.MEAN)\n",
    "    print 'This is the seasonal OND mean cube for the baseline period 1961-1990'\n",
    "    print seasonal_mean\n",
    "    print\n",
    "\n",
    "# Save the OND seasonal mean as a netCDF\n",
    "    iris.save(seasonal_mean, path_out + jobid + 'a.OND.mean.baseline.05216.mmday.nc')\n",
    "    print 'The cube has been saved to the monthly/climatology/ directory'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1 b.) Calculate the 1961-1990 seasonal mean for OND from the APHRODITE observation data.__\n",
    "\n",
    "__Note:__ APHRODITE is a daily high resolution (0.25 degree) rain gauge-based precipitation data set over Asia for 1950-2007. See http://www.chikyu.ac.jp/precip/ for more information.\n",
    "\n",
    "__HINT__ Follow step 1. a), the file name to load is: 'aphro.mon.6190.nc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import iris\n",
    "import iris.coord_categorisation\n",
    "\n",
    "# Directory names where data is read from and stored to\n",
    "path_in_aphro   = 'monthly/APHRODITE/'\n",
    "path_out        = 'monthly/climatology/'\n",
    "\n",
    "# Load the aprhodite data\n",
    "aphroData = iris.load_cube(path_in_aphro + 'aphro.mon.6190.nc')\n",
    "\n",
    "print 'This is the aphrodite data'\n",
    "print aphroData\n",
    "print\n",
    "\n",
    "# in order to calculate OND mean, need to a add season membership coordinate\n",
    "iris.coord_categorisation.add_season(aphroData, 'time', name='seasons', seasons=('jfmamjjas','ond'))\n",
    "\n",
    "# Then constrain the cube just for the OND season\n",
    "aphroData = aphroData.extract(iris.Constraint(seasons='ond'))\n",
    "print 'This is the seasonal OND constrained cube'\n",
    "print aphroData\n",
    "print \n",
    "\n",
    "# Now calculate the mean over this season\n",
    "aphro_seasonal_mean = aphroData.aggregated_by(['seasons'], iris.analysis.MEAN)\n",
    "print 'This is the seasonal OND mean cube for the baseline period 1961-1990'\n",
    "print aphro_seasonal_mean\n",
    "print\n",
    "\n",
    "# save the seasonal mean as a netCDF\n",
    "iris.save(aphro_seasonal_mean, path_out + 'aphro.OND.mean.baseline.05216.mmday.nc')\n",
    "print 'The cube has been saved to the monthly/climatology/ directory'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 IRIS quick plotting and visualising data\n",
    "\n",
    "__Now we will plot the output to take a first look at what the precipitation 1961-1990 OND seasonal mean looks like for each dataset. This provides an initial introduction to visualising data quickly through iris, for further reading and instructions how please visit: http://scitools.org.uk/iris/docs/latest/userguide/plotting_a_cube.html __ \n",
    "\n",
    "Work through the example below line by line to try to understand what each step is doing, then press 'ctrl' + 'enter' to run the code and view the output below.\n",
    "\n",
    "What are the differences between the plots? Note the colour bars, where are the largest daily rainfall rates distributed? Why do you think this is happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# do not delete - needed ipython function\n",
    "\n",
    "# import the iris, matplotlib and iris quickplot libraries\n",
    "import iris\n",
    "import matplotlib.pyplot as plt\n",
    "import iris.quickplot as qplt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Directory name where data is read from\n",
    "path_in = 'monthly/climatology/'\n",
    "\n",
    "# load cahpa model data\n",
    "cahpa_cube = iris.load_cube(path_in + 'cahpaa.OND.mean.baseline.05216.mmday.nc')\n",
    "print cahpa_cube\n",
    "\n",
    "# load cahpb model data\n",
    "cahpb_cube = iris.load_cube(path_in + 'cahpba.OND.mean.baseline.05216.mmday.nc')\n",
    "print cahpb_cube\n",
    "\n",
    "# load APHRODITE data\n",
    "obs_cube   = iris.load_cube(path_in + 'aphro.OND.mean.baseline.05216.mmday.nc')\n",
    "#print obs_cube\n",
    "\n",
    "# Define the contour levels for all plots\n",
    "levels = range(0, 22, 2)\n",
    "\n",
    "# Create a figure of the size 12x10 inches\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)           # Create a new subplot for the model data 2 row, 2 columns, 1st plot\n",
    "qplt.contourf(cahpa_cube[0], levels=levels, cmap=cm.RdBu)   # Note this is where cube slicing is needed as you can only plot 2-coordinate\n",
    "                               # dimensions with qplt.contourf, so here we have selected time[0] as there is only\n",
    "                               # one timestep (the baseline 1961-1990 mean)\n",
    "\n",
    "plt.title('Q0 model')          # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()                 # adds x and y grid lines to the plot\n",
    "\n",
    "plt.subplot(2, 2, 2)           # Create a new subplot for the model data 2 row, 2 columns, 2nd plot\n",
    "qplt.contourf(cahpb_cube[0], levels=levels, cmap=cm.RdBu)\n",
    "\n",
    "plt.title('ECHAM5 model')       # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()                 # adds x and y grid lines to the plot\n",
    "\n",
    "plt.subplot(2, 1, 2)           # Create a new subplot for the observed data 2 row, 1 columns, second plot\n",
    "                               # This plot will be centred and below the two model plots\n",
    "qplt.contourf(obs_cube[0], levels=levels, cmap=cm.RdBu)\n",
    "\n",
    "plt.title('APHRODITE obs')     # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()                 # adds x and y grid lines to the plot\n",
    "\n",
    "plt.tight_layout()             # automatically adjusts subplot(s) to fit in to the figure area\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Mean annual cycle calculation\n",
    "\n",
    "If you have an area or region you want to focus on you can extract data for the region of interest. This example works through how to constrain your cube.\n",
    "\n",
    "__1 a. ) Extract the area around Kuala Lumpur from the monthly precipitation data for both the HadCM3Q0 (cahpa) and ECHAM5 (cahpb) driven runs by specifiying latitude and longitude coordinates.__\n",
    "\n",
    "Work through the example below and remove the double ## comments and review the code line by line to understand what is being done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import iris\n",
    "\n",
    "# Set up an area constraint for Kuala Lumpur (KL).\n",
    "# PRECIS uses a rotated grid, so the co-ordinates required are different to\n",
    "# real world coordinates.\n",
    "# All grid cells whose longitudes and latitudes lie within the limits shown will be selected.\n",
    "\n",
    "KL_constraint = iris.Constraint(grid_longitude = lambda cell: -8.17 <= cell <= -7.43, \\\n",
    "                                grid_latitude = lambda cell: -12.10 <= cell <= -11.38)\n",
    "\n",
    "for jobid in ['cahpa', 'cahpb']:\n",
    "\n",
    "# Directory name where data are read from and stored to\n",
    "    path  = 'monthly/' + jobid + '/05216/'\n",
    "    \n",
    "# Load the baseline precipitation data using the KL_constraint - the command below\n",
    "# loads the data into a cube constrained by the area chosen\n",
    "    model_KL = iris.load_cube(path + jobid + 'a.pm.6190.05216.rr8.mmday.nc', KL_constraint)\n",
    "\n",
    "    print 'The data from ' + jobid + ' around Kuala Lumpur. There are only 4 lat points and 5 long points.'\n",
    "    print model_KL\n",
    "\n",
    "# save the constrained cube\n",
    "    iris.save(model_KL, path + jobid + 'a.pm.6190.05216.rr8.ext.mmday.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now do the same for APHRODITE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import iris\n",
    "\n",
    "# Directory where data are read from and stored to\n",
    "path  = 'monthly/APHRODITE/'\n",
    "\n",
    "# Set up area constraint for Kuala Lumpur\n",
    "# Note that the Aphrodite data are on a regular grid (unlike the  model data) so real latitudes and longitudes are\n",
    "# used to define the region around KL (more on this in section 2.6)\n",
    "KL_constraint2 = iris.Constraint(longitude = lambda cell: 101.25 <= cell <= 102.15, \\\n",
    "                                latitude = lambda cell: 2.74 <= cell <= 3.48)\n",
    "\n",
    "# Load the Aphrodite data using the KL_constraint\n",
    "aphrod = iris.load_cube(path + 'aphro.mon.6190.nc', KL_constraint2)\n",
    "print aphrod\n",
    "\n",
    "# save the constrained cube to directory\n",
    "iris.save(aphrod, path + 'aphro.pm.6190.05216.rr8.ext.mmday.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1 b. ) We now calculate monthly mean fields for 1961-1990 for each of the twelve months for the KL area.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import iris\n",
    "import iris.coord_categorisation\n",
    "\n",
    "path_out = 'monthly/climatology/'\n",
    "\n",
    "for jobid in ['cahpa', 'cahpb']:\n",
    "\n",
    "# Set up the path to the data\n",
    "    path_in = 'monthly/' + jobid + '/05216/'\n",
    "    \n",
    "# Load the data extracted around Kuala Lumpur created in previous step\n",
    "    data = iris.load_cube(path_in + jobid + 'a.pm.6190.05216.rr8.ext.mmday.nc')\n",
    "\n",
    "# Add monthly coord categorisation to the time dimension coordinate\n",
    "    iris.coord_categorisation.add_month_number(data, 'time', name='month_number')\n",
    "    print data\n",
    "\n",
    "# Calculate monthly mean values\n",
    "    monthly_mean = data.aggregated_by(['month_number'], iris.analysis.MEAN)\n",
    "\n",
    "    print 'This is the monthly mean cube'\n",
    "    print monthly_mean\n",
    "\n",
    "# Calculate area averaged monthly mean rainfall \n",
    "    monthly_mean = monthly_mean.collapsed(['grid_longitude', 'grid_latitude'], iris.analysis.MEAN)\n",
    "    print 'This is the monthly mean averaged over the area'\n",
    "    print monthly_mean\n",
    "\n",
    "# Save the area averaged monthly mean data\n",
    "    iris.save(monthly_mean, path_out + jobid + 'a.monmean.baseline.05216.rr8.ext.mmday.nc')\n",
    "    print 'The cube has been saved to ' + path_out + jobid + 'a.monmean.baseline.05216.rr8.ext.mmday.nc'\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1 c. ) What is the KL area averaged monthly mean precipitation amount in mm/day for the HadCM3Q0 and ECHAM5 driven PRECIS runs?__ \n",
    "\n",
    "__By plotting the data of the cubes note down the approximate values in mm day-1.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#do not delete - needed ipython function\n",
    "%matplotlib inline\n",
    "\n",
    "import iris\n",
    "import matplotlib.pyplot as plt\n",
    "import iris.quickplot as qplt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Directory to read in data from\n",
    "datapath = 'monthly/climatology/'\n",
    "\n",
    "# Model names to loop over\n",
    "model_name = ['cahpa', 'cahpb']\n",
    "\n",
    "# Set up date format for plotting - here, months are shown using abbreviated month names (Jan, Feb, Mar, ... Dec).\n",
    "# The alternative (%m) uses two digit numbers.\n",
    "#axFmt = mdates.DateFormatter('%m')\n",
    "axFmt = mdates.DateFormatter('%b')\n",
    "\n",
    "for model in model_name:\n",
    "    # Load the model cube\n",
    "    cube = iris.load_cube(datapath + model + 'a.monmean.baseline.05216.rr8.ext.mmday.nc')\n",
    "    \n",
    "    # Quick line plot for each cube \n",
    "    qplt.plot(cube.coord('month_number'), cube, label=model)\n",
    "    plt.title('KL area averaged ' + model + ' monthly\\n average of daily rainfall')\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_label_text('Month Number')\n",
    "    ax.set_xlim(0.5, 12.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1 d. ) Now by following the same methodology as above for 1 b) for the KL area find the monthly means 1961-1990 for APHRODITE observations.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Type code here\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "\n",
    "# Dirctories to load and save to\n",
    "path_in        = 'monthly/APHRODITE/' \n",
    "path_out       = 'monthly/climatology/'\n",
    "\n",
    "# Load the KL extracted data created in previous step\n",
    "aphrod = iris.load_cube(path_in + 'aphro.pm.6190.05216.rr8.ext.mmday.nc')\n",
    "\n",
    "# Add monthly coord categorisation to the time dim coordinate\n",
    "iris.coord_categorisation.add_month_number(aphrod, 'time', name='month_number')\n",
    "\n",
    "# Now calculate monthly means\n",
    "aphro_monthly_mean = aphrod.aggregated_by(['month_number'], iris.analysis.MEAN)\n",
    "\n",
    "print 'This is the monthly mean cube'\n",
    "print aphro_monthly_mean\n",
    "# create the area averaged monthly mean of daily rainfall \n",
    "aphro_monthly_mean = aphro_monthly_mean.collapsed(['longitude', 'latitude'], iris.analysis.MEAN)\n",
    "print 'This is the monthly mean averaged over the area'\n",
    "print aphro_monthly_mean\n",
    "\n",
    "# Save output\n",
    "iris.save(aphro_monthly_mean, path_out + 'aphro.monmean.baseline.05216.rr8.ext.mmday.nc')\n",
    "print 'The cube has been saved to ' + path_out + 'aphro.monmean.baseline.05216.rr8.ext.mmday.nc'\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1 e. ) Plot the observations and the HadCM3Q0 and ECHAM5 driven PRECIS runs. What are the differences between the observations and models, what months are the differences greatest?__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do not delete - needed ipython function\n",
    "%matplotlib inline\n",
    "\n",
    "import iris\n",
    "import matplotlib.pyplot as plt\n",
    "import iris.quickplot as qplt\n",
    "\n",
    "# Directory to read data from\n",
    "path = 'monthly/climatology/'\n",
    "\n",
    "# Model job ids and name of observed data to loop over.\n",
    "names = ['cahpaa', 'cahpba', 'aphro']\n",
    "\n",
    "for id in names:\n",
    "    # Load the cube\n",
    "    cube = iris.load_cube(path + id + '.monmean.baseline.05216.rr8.ext.mmday.nc')\n",
    "    \n",
    "    # quick line plot for each cube and holding onto the same plot \n",
    "    qplt.plot(cube.coord('month_number'), cube, label=id)\n",
    "    plt.title('KL area averaged ' + id + '\\n monthly average of daily rainfall')\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_label_text('Month Number')\n",
    "    ax.set_xlim(0.5, 12.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Comparing models and observations\n",
    "\n",
    "To compare spatial model and observation fields properly they must be on the same grid. We will regrid to the coarsest grid. For the data used here, the observations have the coarsest resolution so we will regrid the model data onto the observation grid.\n",
    "\n",
    "The PRECIS model data are on a grid known as a Rotated Grid. The idea is that the \"real\" north pole in the Arctic is shifted such that the equator then runs through the centre of the regional model domain.\n",
    "\n",
    "First, we will compare the observations and model data before regridding.\n",
    "\n",
    "__1 a. ) Create figures to compare the modelled and observed seasonal mean rainfall totals.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "# do not delete - needed ipython function\n",
    "\n",
    "# import the iris, matplotlib and iris quickplot libraries\n",
    "import iris\n",
    "import matplotlib.pyplot as plt\n",
    "import iris.quickplot as qplt\n",
    "\n",
    "# Directory to read in data from\n",
    "datapath = 'monthly/climatology/'\n",
    "\n",
    "# load cahpaa model data\n",
    "model_cube_a = iris.load_cube(datapath + 'cahpaa.OND.mean.baseline.05216.mmday.nc')\n",
    "\n",
    "# load cahpaa model data\n",
    "model_cube_b = iris.load_cube(datapath + 'cahpba.OND.mean.baseline.05216.mmday.nc')\n",
    "\n",
    "# load APHRODITE into a cube \n",
    "obs_cube = iris.load_cube(datapath + 'aphro.OND.mean.baseline.05216.mmday.nc')\n",
    "\n",
    "# Create a figure of the size 6x12 inches\n",
    "plt.figure(figsize=(6, 12))\n",
    "plt.subplot(3, 1, 1)        # Create a new subplot for the model data 3 rows, 1 column, 1st plot\n",
    "qplt.pcolormesh(model_cube_a[0], vmax=10) # quickly plots a colormesh map plot of the model data\n",
    "plt.title('HadCM3Q0 precipitation\\n'\n",
    "          'on a rotated longitude latitude grid')  # plots a title for the plot\n",
    "ax = plt.gca()              # gca function that returns the current axes\n",
    "ax.coastlines()             # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()              # adds x and y grid lines to the plot\n",
    "\n",
    "plt.subplot(3, 1, 2)        # Create a new subplot for the model data, 2nd plot\n",
    "qplt.pcolormesh(model_cube_b[0], vmax=10)\n",
    "plt.title('ECHAM5 precipitation\\n'\n",
    "          'on a rotated longitude latitude grid')\n",
    "ax = plt.gca()\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "\n",
    "plt.subplot(3, 1, 3)        # Create a new subplot for the obs data, 3rd plot       \n",
    "qplt.pcolormesh(obs_cube[0], vmax=10)   # quickly plots a colormesh map plot of the obs data\n",
    "plt.title('Observational APHRODITE precipitation\\n'\n",
    "          'on a coarser global longitude latitude grid') # plots a title for the plot\n",
    "ax = plt.gca()              # gca function that returns the current axes\n",
    "ax.coastlines()             # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()              # adds x and y grid lines to the plot\n",
    "\n",
    "plt.tight_layout()          # automatically adjusts subplot(s) to fit in to the figure area\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1 b. ) Regrid the multiannual OND mean model fields onto the observations grid.__\n",
    "\n",
    "Note: regrid is used to regrid the target cube. Here we will use linear interpolation. First, load in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%cd /media/sf_share/UK\n",
    "import iris\n",
    "iris.FUTURE.netcdf_promote = True\n",
    "\n",
    "# directory where data is stored\n",
    "data_path = 'monthly/climatology/'\n",
    "\n",
    "# load cahpaa\n",
    "cahpa_model_cube = iris.load_cube(data_path + 'cahpaa.OND.mean.baseline.05216.mmday.nc')\n",
    "# load cahpba\n",
    "cahpb_model_cube = iris.load_cube(data_path + 'cahpba.OND.mean.baseline.05216.mmday.nc')\n",
    "# load APHRODITE into a cube\n",
    "obs_cube = iris.load_cube(data_path + 'aphro.OND.mean.baseline.05216.mmday.nc')\n",
    "print cahpa_model_cube\n",
    "print cahpb_model_cube\n",
    "print obs_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can regrid the model data to the grid used by the observations, the coordinate system used for the observations must be supplied - it is missing from the original NetCDF file.  The observations are on a regular longitude-latitude grid so the correct coordinate system is WGS84.\n",
    "\n",
    "We define the WGS84 coordinate system and then apply it to the x- and y-axes (i.e. longitudes and latitudes) of the observations.  The coordinate system used by the model (the rotated grid) is already defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define WGS84 projection for obs data\n",
    "wgs84 = iris.coord_systems.GeogCS(semi_major_axis=6378137.0, inverse_flattening=298.257223563)\n",
    "\n",
    "# Apply WGS84 to obs cube\n",
    "obs_cube.coord(axis='x').coord_system = wgs84\n",
    "obs_cube.coord(axis='y').coord_system = wgs84\n",
    "\n",
    "# Print out the two coordinate systems\n",
    "print obs_cube.coord_system()\n",
    "print cahpa_model_cube.coord_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few lines regrid the model data to the regular grid used by the observations.  From the figures above, the area over which APHRODITE data are available is larger than the PRECIS model domain. Hence, the extrapolation mode is set to 'mask' so that any grid cells on the APHRODITE grid which do not overlap with model grid cells are masked off; otherwise, the model data would be interpolated which would produce misleading results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Regrid the climate model data onto APHRODITE grid\n",
    "cahpa_regrid = cahpa_model_cube.regrid(obs_cube, iris.analysis.Nearest(extrapolation_mode='mask'))\n",
    "cahpb_regrid = cahpb_model_cube.regrid(obs_cube, iris.analysis.Nearest(extrapolation_mode='mask'))\n",
    "\n",
    "# Save output\n",
    "iris.save(cahpa_regrid, data_path + 'cahpaa.OND.mean.baseline.05216.mmday.rg.nc')\n",
    "iris.save(cahpb_regrid, data_path + 'cahpba.OND.mean.baseline.05216.mmday.rg.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1 c. ) Now that the model grids have been regridded to the observation cube: (i) load the netCDF files, and (ii) then plot the APHRODITE and model data again (as above in 15.) to compare them visually once again. What do you note?__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Insert code here - note you must start with importing the iris, matplotlib and iris quickplot libraries\n",
    "# Create a figure of the size 6x12 inches\n",
    "\n",
    "# do not delete - needed ipython function\n",
    "%matplotlib inline\n",
    "\n",
    "# import the iris, matplotlib and iris quickplot libraries\n",
    "import iris\n",
    "import matplotlib.pyplot as plt\n",
    "import iris.quickplot as qplt\n",
    "\n",
    "# directory where data are stored\n",
    "data_path = 'monthly/climatology/'\n",
    "\n",
    "cahpa_regrid = iris.load_cube(data_path + 'cahpaa.OND.mean.baseline.05216.mmday.rg.nc')\n",
    "cahpb_regrid = iris.load_cube(data_path + 'cahpba.OND.mean.baseline.05216.mmday.rg.nc')\n",
    "obs_cube = iris.load_cube(data_path + 'aphro.OND.mean.baseline.05216.mmday.nc')\n",
    "\n",
    "plt.figure(figsize=(6, 12))\n",
    "plt.subplot(3, 1, 1)        # Create a new subplot for the model data 3 rows, 1 column, 1st plot\n",
    "qplt.pcolormesh(cahpa_regrid[0], vmax=10) # quickly plots a colormesh map plot of the model data\n",
    "plt.title('HadCM3Q0 precipitation\\n'\n",
    "          'on a global longitude latitude grid')  # plots a title for the plot\n",
    "ax = plt.gca()              # gca function that returns the current axes\n",
    "ax.coastlines()             # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()              # adds x and y grid lines to the plot\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "qplt.pcolormesh(cahpb_regrid[0], vmax=10)\n",
    "plt.title('ECHAM5 precipitation\\n'\n",
    "          'on a global longitude latitude grid')\n",
    "ax = plt.gca()\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "\n",
    "plt.subplot(3, 1, 3)        # Create a new subplot for the obs data\n",
    "qplt.pcolormesh(obs_cube[0], vmax=10)\n",
    "plt.title('Observational APHRODITE precipitation\\n'\n",
    "          'on a coarser global longitude latitude grid')\n",
    "ax = plt.gca()\n",
    "ax.coastlines()\n",
    "ax.gridlines()\n",
    "\n",
    "plt.tight_layout()          # automatically adjusts subplot(s) to fit in to the figure area\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1 d. ) Find the difference between the model and the observation OND multiannual mean fields and plot maps to view the differences.__\n",
    "\n",
    "We can simply subtract the model data from the observations.  There is a subtract function within Iris but it cannot be used here.  The model cubes contain extra coordinates which are not present in the obs cube; Iris requires all coordinates within the cubes to match exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do not delete - needed ipython function\n",
    "%matplotlib inline\n",
    "\n",
    "# import the iris, matplotlib and iris quickplot libraries\n",
    "import iris\n",
    "import matplotlib.pyplot as plt\n",
    "import iris.quickplot as qplt\n",
    "\n",
    "# load cubes, note this must be the regridded model cubes to compare as they must have the same lat/lon\n",
    "# and time dimensions\n",
    "\n",
    "data_path = 'monthly/climatology/'\n",
    "\n",
    "cahpa_cube = iris.load_cube(data_path + 'cahpaa.OND.mean.baseline.05216.mmday.rg.nc')\n",
    "cahpb_cube = iris.load_cube(data_path + 'cahpba.OND.mean.baseline.05216.mmday.rg.nc')\n",
    "obs_cube   = iris.load_cube(data_path + 'aphro.OND.mean.baseline.05216.mmday.nc')\n",
    "\n",
    "# Make sure units are the same\n",
    "obs_cube.units = cahpb_cube.units\n",
    "\n",
    "# Make recieving cube\n",
    "cahpa_obs_diff = obs_cube.copy()\n",
    "cahpb_obs_diff = obs_cube.copy()\n",
    "\n",
    "# Replace data with the differences\n",
    "cahpa_obs_diff.data = cahpa_cube.data - obs_cube.data\n",
    "\n",
    "# cahpb - aphrodite differences\n",
    "cahpb_obs_diff.data = cahpb_cube.data - obs_cube.data\n",
    "\n",
    "# Save the differences\n",
    "iris.save(cahpa_obs_diff, data_path + 'diff.cahpa_aphro.OND.baseline.nc')\n",
    "iris.save(cahpb_obs_diff, data_path + 'diff.cahpb_aphro.OND.baseline.nc')\n",
    "\n",
    "# Plot the differences as map plots\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(1, 2, 1)           # Create a new subplot for the first differences, 2 rows, 1 column, 1st plot\n",
    "\n",
    "# Cut-out region with data. We use the intersection method to plot the region with data\n",
    "\n",
    "qplt.pcolormesh(cahpa_obs_diff[0].intersection(longitude=(90, 135), latitude=(-20, 32)), \n",
    "                vmax=10, vmin=-10, \n",
    "                cmap=plt.get_cmap('RdYlBu'))   # Note this is where cube slicing is needed as you can only plot 2-coordinate\n",
    "                               # dimensions with qplt.contourf, so here we have selected time[0] as there is only\n",
    "                               # one timestep (the baseline 1961-1990 mean)\n",
    "\n",
    "plt.title('Cahpa model and obs diff')       # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()                 # adds x and y grid lines to the plot\n",
    "\n",
    "plt.subplot(1, 2, 2)           # Create a new subplot for the model data 2 row, 2 columns, 2nd plot\n",
    "qplt.pcolormesh(cahpb_obs_diff[0].intersection(longitude=(90, 135), latitude=(-20, 32)),\n",
    "             vmax=10, vmin=-10,\n",
    "             cmap=plt.get_cmap('RdYlBu'))\n",
    "\n",
    "plt.title('Cahpb model and obs diff')       # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "ax.gridlines()                 # adds x and y grid lines to the plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Climatological mean and annual cycle for an ensemble\n",
    "\n",
    "So far data from two models downscaled with PRECIS have been analysed. In this section an ensemble of six models will be used, five from the HadCM3 QUMP ensemble (discussed in the model ensemble lecture) and one ECHAM5 model. The five members of the QUMP ensemble are HadCM3Q0 (cahpa), HadCM3Q3 (cahpc), HadCM3Q10 (cahpd), HadCM3Q11 (cahpe) and HadCM3Q13 (cahpf).\n",
    "\n",
    "Taking an ensemble approach allows us to account for a range of uncertainty in the model projections. Typing the python and IRIS commands into the command line for all six ensemble members would be very time consuming, so we use a script instead.\n",
    "\n",
    "The script has been written below to generate cubes of ensemble members which can then be saved as one netCDF file. Each ensemble member is identified by its model runid and is listed under a realization dimension coordinate that has been added to the cube. \n",
    "\n",
    "Note a more pythonic way would be to write functions, but for the ease of this tutorial it has not this time.\n",
    "\n",
    "__1 . ) Calculate the OND seasonal mean and annual cycle (for the KL area) for 1.5m temperature and precipitation for CRU and APHRODITE observations.__\n",
    "\n",
    "Note: The CRU data are a monthly global land-only dataset (1901-present) at 0.5 degree resolution. Nine variables are available, including mean, min, max temperature and precipitation. For further details please see: http://www.cru.uea.ac.uk/~timm/grid/CRU_TS_2_1.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The purpose of this script is to load the CRU temperature data and APHRODITE rainfall data, and then create (a) the OND\n",
    "seasonal mean and (b) monthly means averaged over Kuala Lumpur\n",
    "'''\n",
    "\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "iris.FUTURE.netcdf_no_unlimited = True\n",
    "iris.FUTURE.netcdf_promote = True\n",
    "\n",
    "# Data directory paths in for loading and out for saving\n",
    "data_path_in  = 'monthly/'\n",
    "data_path_out = 'monthly/climatology/'\n",
    "\n",
    "# Constraint for area of CRU data covered by PRECIS domain\n",
    "# Values from script 'worksheet2.sh'\n",
    "model_constraint = iris.Constraint(longitude = lambda cell: 90.0 <= cell <= 137.0, \\\n",
    "                                latitude = lambda cell: -14.0 <= cell <= 31.0)\n",
    "\n",
    "scodes = ['03236', '05216']\n",
    "\n",
    "for scode in scodes:\n",
    "# Load the CRU or APHRODITE data for the PRECIS model domain using the area constraint\n",
    "    if scode == '03236':\n",
    "        filename = 'CRU/cru.pm.6190.03236.nc'\n",
    "    else:\n",
    "        filename = 'APHRODITE/aphro.mon.6190.nc'\n",
    "    obs_cube = iris.load_cube(data_path_in + filename, model_constraint)\n",
    "\n",
    "# In order to calculate OND mean, add a season membership coordinate\n",
    "    iris.coord_categorisation.add_season(obs_cube, 'time', name='seasons', seasons=('jfmamjjas','ond'))\n",
    "\n",
    "# Extract data for OND only\n",
    "    obs_cube_ond = obs_cube.extract(iris.Constraint(seasons='ond'))\n",
    "\n",
    "# Now calculate the mean over this season\n",
    "    obs_ond_mean = obs_cube_ond.aggregated_by(['seasons'], iris.analysis.MEAN)\n",
    "\n",
    "# Add units description to temperature cube\n",
    "# Save output\n",
    "    if scode == '03236':\n",
    "        obs_ond_mean.units = 'celsius'\n",
    "        file_head = 'cru.OND.mean.baseline.'\n",
    "    else:\n",
    "        obs_ond_mean.units = 'mm day-1'\n",
    "        file_head = 'aphro.OND.mean.baseline.'\n",
    "\n",
    "    print \"Saving file \" + file_head + scode + '.nc'\n",
    "    iris.save(obs_ond_mean, data_path_out + file_head + scode + '.nc')\n",
    "\n",
    "# Select area around KL from the original data # MIGHT NEED TO REVISE LIMITS?\n",
    "    obs_cube_KL = obs_cube.intersection(longitude=(101.25,102.15), latitude=(2.74,3.48))\n",
    "    \n",
    "# Add monthly categorisation to the time dimension coordinate\n",
    "    iris.coord_categorisation.add_month_number(obs_cube_KL, 'time', name='month_number')\n",
    "\n",
    "# Calculate monthly mean values\n",
    "    obs_monthly_mean = obs_cube_KL.aggregated_by(['month_number'], iris.analysis.MEAN)\n",
    "\n",
    "# Calculate area averaged monthly means for KL\n",
    "    obs_monthly_mean = obs_monthly_mean.collapsed(['longitude', 'latitude'], iris.analysis.MEAN)\n",
    "\n",
    "# Save the observed monthly mean values\n",
    "    print \"Saving monthly mean file ...\"\n",
    "    if scode == '03236':\n",
    "        iris.save(obs_monthly_mean, data_path_out + 'cru.monmean.baseline.' + scode + '.ext.KL.nc')\n",
    "    else:\n",
    "        iris.save(obs_monthly_mean, data_path_out + 'aphro.monmean.baseline.' + scode + '.ext.KL.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2 . ) Next, we repeat the operations on the six sets of model data - i.e., we create OND mean values and monthly means for the KL region.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Model runs:\n",
    "(1) Load each model run id extracted for KL and create OND seasonal mean, regrid to observation grid\n",
    "(2) Load each model runid for the KL region and then create the OND seasonal mean, regrid to the coaser\n",
    "observation model grid and merge all cubes into one cube of ensemble members\n",
    "(3) calculate the difference between models and observations\n",
    "'''\n",
    "\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "iris.FUTURE.netcdf_no_unlimited = True\n",
    "iris.FUTURE.netcdf_promote = True\n",
    "\n",
    "# Data directory paths in for loading and out for saving\n",
    "data_path_in  = 'monthly/'\n",
    "data_path_out = 'monthly/climatology/'\n",
    "\n",
    "# These coordinates are for a regular grid as used by the CRU data\n",
    "KL_constraint = iris.Constraint(longitude = lambda cell: 101.25 <= cell <= 102.15, \\\n",
    "                                latitude = lambda cell: 2.74 <= cell <= 3.48)\n",
    "\n",
    "# These coordinates are for the rotated grid used by PRECIS\n",
    "KL_constraint_rotg = iris.Constraint(grid_longitude = lambda cell: -8.17 <= cell <= -7.43, \\\n",
    "                                grid_latitude = lambda cell: -12.10 <= cell <= -11.38)\n",
    "\n",
    "scodes = ['03236', '05216']\n",
    "\n",
    "# Define WGS84 projection for obs data. Required to regrid the model data to the obs grid\n",
    "wgs84 = iris.coord_systems.GeogCS(semi_major_axis=6378137.0, inverse_flattening=298.257223563)\n",
    "\n",
    "for scode in scodes:\n",
    "# Load the observed OND mean\n",
    "    if scode == '03236':\n",
    "        units = 'degC'\n",
    "        obs_ond_mean = iris.load_cube(data_path_out + 'cru.OND.mean.baseline.' + scode + '.nc')\n",
    "    else:\n",
    "        obs_ond_mean = iris.load_cube(data_path_out + 'aphro.OND.mean.baseline.' + scode + '.nc')\n",
    "        units = 'mmday'\n",
    "# Apply WGS84 to obs cube\n",
    "    obs_ond_mean.coord(axis='x').coord_system = wgs84\n",
    "    obs_ond_mean.coord(axis='y').coord_system = wgs84\n",
    "\n",
    "# Loop over each  model runid. We use enumerate, so the variable 'member' runs from 0 to the number of models (6) minus 1\n",
    "    for member, id in enumerate(range(ord('a'), ord('f')+1)):\n",
    "        runid = 'cahp' + chr(id)\n",
    "          \n",
    "# Load the model data\n",
    "        subdir = '{}/{}/'.format(runid, scode)\n",
    "        file_in = '{}a.pm.6190.{}.rr8.nc'.format(runid, scode)\n",
    "        model_cube = iris.load_cube(data_path_in + subdir + file_in)\n",
    "          \n",
    "# In order to calculate OND mean, need to add a season membership coordinate\n",
    "        iris.coord_categorisation.add_season(model_cube, 'time', name='seasons', seasons=('jfmamjjas','ond'))\n",
    "\n",
    "# Then extract the part of the cube containing the OND season\n",
    "        model_cube_ond = model_cube.extract(iris.Constraint(seasons='ond'))\n",
    "\n",
    "# Calculate the mean for the OND season\n",
    "        model_ond_mean = model_cube_ond.aggregated_by(['seasons'], iris.analysis.MEAN)\n",
    "\n",
    "# Change the temperature units from Kelvin to degC, or mm s-1 to mm day-1\n",
    "        if scode == '03236':\n",
    "            model_ond_mean.convert_units('celsius')\n",
    "        else:\n",
    "            model_ond_mean.convert_units('kg m-2 day-1')\n",
    "    \n",
    "# Save the model OND mean\n",
    "        file_out = '{}a.OND.mean.baseline.{}.{}.nc'.format(runid, scode, units)\n",
    "        iris.save(model_ond_mean, data_path_out + file_out)\n",
    "        print \"saved \" + file_out\n",
    "\n",
    "# Regrid to observation grid\n",
    "        model_ond_mean_rg = model_ond_mean.regrid(obs_ond_mean, iris.analysis.Linear())\n",
    "        file_out = '{}a.OND.mean.baseline.{}.{}.rg.nc'.format(runid, scode, units)\n",
    "        iris.save(model_ond_mean_rg, data_path_out + file_out)\n",
    "\n",
    "# Subtract the obs OND mean from the model OND mean and save the difference\n",
    "        model_ond_diff = obs_ond_mean.copy()\n",
    "        model_ond_diff.data = model_ond_mean_rg.data - obs_ond_mean.data\n",
    "\n",
    "        if scode == '03236':\n",
    "            model_ond_diff.units = 'celsius'\n",
    "            iris.save(model_ond_diff, data_path_out + 'diff.' + runid + '_cru.OND.baseline.nc')\n",
    "        else:\n",
    "            model_ond_diff.units = 'mm day-1'\n",
    "            iris.save(model_ond_diff, data_path_out + 'diff.' + runid + '_aphro.OND.baseline.nc')\n",
    "\n",
    "# Remove the seasons coordinate as it is no longer needed\n",
    "        model_cube.remove_coord('seasons')\n",
    "\n",
    "# Calculate monthly mean values for each model in the KL domain\n",
    "# Add monthly coord categorisation to the time dimension coordinate of the KL data\n",
    "        iris.coord_categorisation.add_month_number(model_cube, 'time', name='month_number')\n",
    "\n",
    "# Calculate monthly mean values\n",
    "        model_monthly_mean = model_cube.aggregated_by(['month_number'], iris.analysis.MEAN)\n",
    "\n",
    "# Change the temperature units from Kelvin to degC, or mm s-1 to mm day-1\n",
    "        if scode == '03236':\n",
    "            model_monthly_mean.convert_units('celsius')\n",
    "        else:\n",
    "            model_monthly_mean.convert_units('kg m-2 day-1')\n",
    "\n",
    "# Regrid to observation grid\n",
    "        model_monthly_mean_rg = model_monthly_mean.regrid(obs_ond_mean, iris.analysis.Linear())\n",
    "\n",
    "# Extract the region around Kuala Lumpur\n",
    "        model_mm_KL = model_monthly_mean_rg.extract(KL_constraint)\n",
    "\n",
    "# Calculate area averaged monthly mean temperatures / rainfall for KL\n",
    "        model_KL = model_mm_KL.collapsed(['longitude', 'latitude'], iris.analysis.MEAN)\n",
    "    \n",
    "# Define and add an ensemble realization coordinate. The cube will now contain a new scalar coordinate named\n",
    "# 'realization' which will have the value 'member+1' (so the members are numbered 1, 2, ...)\n",
    "        coord = iris.coords.AuxCoord(member+1, 'realization')\n",
    "        model_KL.add_aux_coord(coord)    \n",
    "\n",
    "# Save the model monthly mean values for the KL area\n",
    "        file_out = '{}a.monthly.mean.baseline.{}.{}.ext.KL.rg.nc'.format(runid, scode, units)\n",
    "        iris.save(model_KL, data_path_out + file_out)\n",
    "        print \"saved \" + file_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__3. ) Calculate the differences between the models and observations for each ensemble member.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import iris\n",
    "iris.FUTURE.netcdf_no_unlimited = True\n",
    "iris.FUTURE.netcdf_promote = True\n",
    "\n",
    "# Data directory path in for loading and out for saving\n",
    "data_path = 'monthly/climatology/'\n",
    "scodes = ['03236', '05216']\n",
    "\n",
    "for scode in scodes:\n",
    "# Load the observed OND mean\n",
    "    if scode == '03236':\n",
    "        units = 'degC'\n",
    "        obs_monthly_mean = iris.load_cube(data_path + 'cru.monmean.baseline.' + scode + '.ext.KL.nc')\n",
    "    else:\n",
    "        units = 'mmday'\n",
    "        obs_monthly_mean = iris.load_cube(data_path + 'aphro.monmean.baseline.' + scode + '.ext.KL.nc')\n",
    "\n",
    "# Load in the modelled monthly mean values and subtract the observations\n",
    "    for id in range(ord('a'), ord('f')+1):\n",
    "        runid = 'cahp' + chr(id)\n",
    "        filename = '{}a.monthly.mean.baseline.{}.{}.ext.KL.rg.nc'.format(runid, scode, units)\n",
    "        model_monthly_mean = iris.load_cube(data_path + filename)\n",
    "        diff = obs_monthly_mean.copy()\n",
    "        diff.data = model_monthly_mean.data - obs_monthly_mean.data\n",
    "        file_out = '{}a.monthly.mean.diff.{}.ext.KL.nc'.format(runid, scode)\n",
    "        iris.save(diff, data_path + file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. ) Create four figures: the monthly cycles of temperature and rainfall from the 6 models and the observations, and the monthly differences between the models and observations.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do not delete - needed ipython function\n",
    "%matplotlib inline\n",
    "\n",
    "import iris\n",
    "import calendar\n",
    "import iris.quickplot as qplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data directory path in for loading and out for saving\n",
    "data_path = 'monthly/climatology/'\n",
    "\n",
    "month_names = calendar.month_abbr\n",
    "scodes = ['03236', '05216']\n",
    "\n",
    "plotnum = 0\n",
    "\n",
    "# Plot the monthly mean cycles\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "for scode in scodes:\n",
    "    if scode == '03236':\n",
    "        units = 'degC'\n",
    "        ylabel = 'Temperature / $\\degree$C'\n",
    "        varname = 'temperature'\n",
    "    else:\n",
    "        units = 'mmday'\n",
    "        ylabel = 'Rainfall / mm day-1'\n",
    "        varname = 'rainfall'\n",
    "\n",
    "    plotnum = plotnum + 1\n",
    "    plt.subplot(4, 1, plotnum)\n",
    "\n",
    "    for id in range(ord('a'), ord('f')+1):\n",
    "        runid = 'cahp' + chr(id)\n",
    "# Load the model cube\n",
    "        filename = '{}a.monthly.mean.baseline.{}.{}.ext.KL.rg.nc'.format(runid, scode, units)\n",
    "        model_monthly_mean = iris.load_cube(data_path + filename)\n",
    "\n",
    "# Use the month numbers from the cube, will be used as x-axis values\n",
    "        qplt.plot(model_monthly_mean.coord('month_number'), model_monthly_mean, linewidth=2)\n",
    "\n",
    "# Load and plot the observed monthly cycle\n",
    "    if scode == '03236':\n",
    "        obs_monthly_mean = iris.load_cube(data_path + 'cru.monmean.baseline.' + scode + '.ext.KL.nc')\n",
    "    else:\n",
    "        obs_monthly_mean = iris.load_cube(data_path + 'aphro.monmean.baseline.' + scode + '.ext.KL.nc')\n",
    "\n",
    "    qplt.plot(obs_monthly_mean.coord('month_number'), obs_monthly_mean, color='black', linewidth=3)\n",
    "\n",
    "# Set the axis limits, use month names on the x-axis\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim(0.5, 12.5)\n",
    "    ax.set_xticks(range(1,13))\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_xticklabels(month_names[1:])\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title('KL area averaged ' + varname + ' / ' + units)\n",
    "\n",
    "# Now plot the monthly cycles of the differences between the models and observations\n",
    "    plotnum = plotnum + 1\n",
    "    plt.subplot(4, 1, plotnum)\n",
    "\n",
    "    for id in range(ord('a'), ord('f')+1):\n",
    "        runid = 'cahp' + chr(id)\n",
    "# Load the differences between the model and observations\n",
    "        filename = '{}a.monthly.mean.diff.{}.ext.KL.nc'.format(runid, scode)\n",
    "        model_diff = iris.load_cube(data_path + filename)\n",
    "        qplt.plot(model_diff.coord('month_number'), model_diff, linewidth=2)\n",
    "\n",
    "    bx = plt.gca()\n",
    "    bx.set_xlim(0.5, 12.5)\n",
    "    bx.set_xticks(range(1,13))\n",
    "    bx.set_xticklabels(month_names[1:])\n",
    "    bx.set_xlabel('')\n",
    "    bx.set_ylabel(ylabel)\n",
    "    bx.set_title('KL area averaged ' + varname + ' differences')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 2: Using the Python Iris library for analysis and visualisation\n",
    "\n",
    "In this worksheet, sample PRECIS output over Southeast Asia driven by HadCM3Q0 and ECHAM5 is compared with observations for validation purposes. Validation of model results by comparison with observed data is an essential step - this is the measure by which we can assess the quality of the model and it informs appropriate uses of the data.\n",
    "\n",
    "\n",
    "Here, we use PRECIS output driven by two different GCMs. Using data from both experiments will give us two representations of present day climate and two possible climate scenarios. For more details on multimodel approaches see the PRECIS workshop lecture on climate model ensembles.\n",
    "\n",
    "\n",
    "The following are examples of types of analyses undertaken as part of a model validation. The methods shown are not necessarily the only way to proceed and are intended to demonstrate the use of Iris in model validation, and provide a starting point for your own analyses. For further help on validating your PRECIS simulations, refer to the PRECIS workshop lecture notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>By the end of this worksheet you should be able to:</b><br> \n",
    "- Apply basic statistical operations to Iris cubes. <br>\n",
    "- Plot information from Iris cubes.<br>\n",
    "- Code a basic python workflow for undertaking basic temperature and rainfall analysis\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> The data used here has been processed in the same way as Worksheet 1. The 8 point-rim has been removed and it has been converted from PP to NetCDF format.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code preamble - these libraries will be used in this worksheet.\n",
    "# This code block needs to be re-run every time you restart this worksheet!\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.dates as mdates\n",
    "import calendar\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "import iris.quickplot as qplt\n",
    "import cartopy.crs as ccrs\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from cartopy.mpl.geoaxes import GeoAxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Inspecting the data\n",
    "\n",
    "The datasets used here are daily and monthly data from two PRECIS runs carried out over Southeast Asia, one driven by HadCM3Q0 and the other driven by ECHAM5. The observations used for comparison are from the APHRODITE gridded observational data set (insert URL).\n",
    "\n",
    "in Iris, data are read into an object called a cube. A cube contains the data of interest (e.g., temperature, rainfall, wind speeds) and metadata about a phenomenon. A single cube describes only one type of data. It is not possible for a cube to contain both temperature and rainfall, for example. A cube always has a name, a unit and an n-dimensional data array to represents the cubeâ€™s data. Additionally, the cube contains collections of coordinates.  Coordinate types can include spatial information (latitude, longitude, altitude), a time dimension, or other information, e.g., an ensemble number.\n",
    "\n",
    "<p><img src=\"img/multi_array_to_cube.png\" alt=\"Example Iris cube\" style=\"float: center; height: 300px;\"/></p>\n",
    "\n",
    "__a) Load the netCDF file for the HadCM3Q0 and ECHAM5 model data and the APHRODITE rainfall observation data and print the cube output__\n",
    "\n",
    "A cube has coordinates (for example time, longitude, latitude, model levels etc) and this information can be accessed with commands. In the following exercise we follow a similar example to that in the [Iris documentation](http://scitools.org.uk/iris/docs/latest/userguide/navigating_a_cube.html#accessing-coordinates-on-the-cube) and find the latitude and longitude of the corners of the locations for the APHRODITE data. You can do so by printing the latitude and longitude coordinates (.points) and note the first and last values in the array.\n",
    "\n",
    "Before running the code take a look at it line by line to understand what steps are being made. Add code where prompted and then click in the box and press <kbd>ctrl</kbd> + <kbd>enter</kbd> to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed in the names of the directories where the netCDF model files are stored\n",
    "DATADIR = '/project/precis/worksheets/data/'\n",
    "path_in_cahpa   = os.path.join(DATADIR, 'netcdf/cahpa/')\n",
    "path_in_cahpb   = os.path.join(DATADIR, 'netcdf/cahpb/')\n",
    "path_in_APHRODITE   = os.path.join(DATADIR, 'APHRODITE/')\n",
    "\n",
    "# Load and print the HadCM3Q0 (cahpa) model cube data\n",
    "cahpaData = iris.load_cube(path_in_cahpa + 'cahpa.pm.1981_1983.pr.norim.nc')\n",
    "\n",
    "# Load and print the ECHAM5 (cahpb) model cube data\n",
    "cahpbData = iris.load_cube(path_in_cahpb + 'cahpb.pm.1981_1983.pr.norim.nc')\n",
    "\n",
    "# Load and print the APHRODITE observation cube data\n",
    "aphroData = iris.load_cube(path_in_APHRODITE + 'aphro.mon.6190.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b) Extract a subset of the data within a cube__\n",
    "\n",
    "The ability to extractis an important function in Iris. The extraction of a subset of data is called slicing.  For example, it could be necessary to extract data over all latitude and longitude grid points on the first time step. For more information around subsetting cubes please read further [here](http://scitools.org.uk/iris/docs/latest/userguide/subsetting_a_cube.html#cube-indexing).\n",
    "\n",
    "__Using the HacCM3Q0 data, the example below shows how to subset a cube for the first time and last timesteps. This method will be used later for plotting data from a cube.__ \n",
    "\n",
    "Work through the example below line by line then click in the box and press <kbd>Ctrl</kbd> + <kbd>Enter</kbd> to run the code.\n",
    "\n",
    "This is the cube with all the time steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cahpaData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris cubes can be sliced in a similar way to arrays. \n",
    "\n",
    "This is the first time step of the cube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cahpaData[0, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is the last time step of the cube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cahpaData[-1, :, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question</b> What is the order of dimensions in a cube? <br>\n",
    "a) [longitude, latitude, time]<br>\n",
    "b) [time, latitude, longitude]<br>\n",
    "c) [latitude, longitude, time]\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Converting units\n",
    "\n",
    "__a) Convert the OND (October, November, December) seasonal precipitation fields for both runs from kg/m2/s (equivalent to mm/s) to mm/day__\n",
    "\n",
    "We could just multiply the raw data in mm/s by 86400 seconds, but a clearer way is to use the __`.convert_units()`__ method with the name of the units we want to convert the data into.\n",
    "\n",
    "For clarity let's do this for the __cahpa__ historical data first and break down the steps as follow:\n",
    "\n",
    "* Print the units and summary statistic about the data\n",
    "* Convert the unit and print the information again\n",
    "* Rename the units value in the cube and save it as a new netCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cahpaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the unit\n",
    "print('The current unit for data is: {}'.format(cahpaData.units))\n",
    "\n",
    "# print the summary statistic (maximum monthly precipitation)\n",
    "maxpr = np.max(cahpaData.data)\n",
    "print('This is an example rainfall rate (kg m-2 s-1) prior to conversion:{:f}'.format(maxpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert units to kg m-2 day-1 (same as multiplying by 86400 seconds)\n",
    "cahpaData.convert_units('kg m-2 day-1')\n",
    "# Print cube.units to view new units for precipitation\n",
    "print('The new rainfall units are: {}'.format(cahpaData.units))\n",
    "maxpr = np.max(cahpaData.data)\n",
    "\n",
    "# print the summary statistic (maximum monthly precipitation) after the unit conversion\n",
    "print('This is the same rainfall rate but in (kg m-2 day-1): {:f}'.format(maxpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the new cube units for consistnecy, then save the converted cube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename cube units\n",
    "cahpaData.units = 'mm day-1'\n",
    "# Remove extraneous cube metadata.  This helps make cube comparisons easier later.\n",
    "cahpaData.remove_coord('forecast_period')\n",
    "cahpaData.remove_coord('forecast_reference_time')\n",
    "# Save the new cube as a new netCDF file\n",
    "iris.save(cahpaData, path_in_cahpa + 'cahpa.pm.1981_1983.pr.norim.mmday-1.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the follow code blcok to repeat the same proceedure for __cahpb__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the current cahpb cube units\n",
    "print('The current unit for data is: {}'.format( ))\n",
    "\n",
    "# convert units to kg m-2 day-1\n",
    "\n",
    "\n",
    "# Rename the units to mm day-1. 1 kg m-2 is equivalent to 1 mm of rain\n",
    "\n",
    "\n",
    "# save the cube into a new netCDF file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cahpbData.convert_units('kg m-2 day-1')\n",
    "cahpbData.units = 'mm day-1'\n",
    "cahpbData.remove_coord('forecast_period')\n",
    "cahpbData.remove_coord('forecast_reference_time')\n",
    "iris.save(cahpbData, path_in_cahpb + 'cahpb.pm.1981_1983.pr.norim.mmday-1.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Climatological mean calculation\n",
    "\n",
    "__a) Calculate the 1961-1990 seasonal mean precipitation field for October-December (OND) from both the HadCM3Q0 (cahpa) and ECHAM5 (cahpb) driven PRECIS runs__\n",
    "\n",
    "Work through the example below line by line then click in the box and press <kbd>ctrl</kbd> + <kbd>enter</kbd> to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define output location\n",
    "outdir = os.path.join(DATADIR, 'climatology/')\n",
    "# Check to see if this directory exists, if not create it\n",
    "if not os.path.isdir(outdir):\n",
    "    # Make directory\n",
    "    os.mkdir(outdir)\n",
    "    # Set directory permissions \n",
    "    os.chmod(outdir, 0o776)\n",
    "\n",
    "# Loop through two model runs\n",
    "for jobid in ['cahpa', 'cahpb']:\n",
    "    infile = os.path.join(DATADIR, 'netcdf', jobid, jobid + '.pm.1981_1983.pr.norim.mmday-1.nc')\n",
    "\n",
    "    # Load the data\n",
    "    data = iris.load_cube(infile)\n",
    "\n",
    "    # In order to calculate OND mean, we use the command below to add season membership coordinate\n",
    "    # The seasons can be any sequence of months, identified by the first letters of the names of the months.\n",
    "    # Here, we define two seasons, jfmamjjas (the months we are not interested in) and ond (October, November and\n",
    "    # December), the months we do want.\n",
    "    iris.coord_categorisation.add_season(data, 'time', name='seasons', seasons=('jfmamjjas','ond'))\n",
    "\n",
    "    # This command extracts data for the OND season using a constraint\n",
    "    data_ond = data.extract(iris.Constraint(seasons='ond'))\n",
    "\n",
    "    # The cube data_ond contains data for October-December for all years. The command below\n",
    "    # calculates the mean over all years.\n",
    "    seasonal_mean = data_ond.aggregated_by(['seasons'], iris.analysis.MEAN)\n",
    "    \n",
    "    # Save the OND seasonal mean as a netCDF\n",
    "    outfile = os.path.join(outdir, jobid + '.a.OND.mean.baseline.pr.mmday-1.nc')\n",
    "    iris.save(seasonal_mean, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seasonal_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b) Calculate the 1961-1990 seasonal mean for OND from the APHRODITE observation data__\n",
    "\n",
    "APHRODITE is a daily high resolution (0.25 degree) rain gauge-based precipitation data set over Asia for 1950-2007. See http://www.chikyu.ac.jp/precip/ for more information.\n",
    "\n",
    "Follow step a) and complete the code yourself.  The file name to load is: `aphro.mon.6190.nc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory names where data is read from and stored to\n",
    "infile = os.path.join(DATADIR, 'APHRODITE', 'aphro.mon.6190.nc')\n",
    "\n",
    "# Load the aprhodite data\n",
    "\n",
    "\n",
    "# in order to calculate OND mean, need to a add season membership coordinate\n",
    "\n",
    "\n",
    "# Then constrain the cube just for the OND season\n",
    "\n",
    "\n",
    "# Now calculate the mean over this season\n",
    "\n",
    "\n",
    "# save the seasonal mean as a netCDF\n",
    "outfile = os.path.join(outdir, 'aphro.a.OND.mean.baseline.pr.mmday-1.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = os.path.join(DATADIR, 'APHRODITE', 'aphro.mon.6190.nc')\n",
    "aphro_cube = iris.load_cube(infile)\n",
    "iris.coord_categorisation.add_season(aphro_cube, 'time', name='seasons', seasons=('jfmamjjas','ond'))\n",
    "aphro_cube_ond = aphro_cube.extract(iris.Constraint(seasons='ond'))\n",
    "seasonal_mean = aphro_cube_ond.aggregated_by(['seasons'], iris.analysis.MEAN)\n",
    "outfile = os.path.join(outdir, 'aphro.a.OND.mean.baseline.pr.mmday-1.nc')\n",
    "iris.save(seasonal_mean, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question:</b> How would you calculate the standard deviation of mean rainfall?  How about annual maximum rainfall?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 IRIS quick plotting and visualising data\n",
    "\n",
    "Now we will plot the output to take a first look at what the precipitation 1961-1990 OND seasonal mean looks like for each dataset. This provides an initial introduction to visualising data quickly through iris, for further reading and instructions how please visit: http://scitools.org.uk/iris/docs/latest/userguide/plotting_a_cube.html\n",
    "\n",
    "What are the differences between the plots? Note the colour bars.  Where are the largest daily rainfall rates distributed? Why do you think this is happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory name where data is read from\n",
    "indir = os.path.join(DATADIR, 'climatology')\n",
    "\n",
    "# load cahpa model data\n",
    "cahpa_cube = iris.load_cube(indir + '/cahpa.a.OND.mean.baseline.pr.mmday-1.nc')\n",
    "\n",
    "# load cahpb model data\n",
    "cahpb_cube = iris.load_cube(indir + '/cahpb.a.OND.mean.baseline.pr.mmday-1.nc')\n",
    "\n",
    "# load APHRODITE data\n",
    "obs_cube   = iris.load_cube(indir + '/aphro.a.OND.mean.baseline.pr.mmday-1.nc')\n",
    "\n",
    "# Do some plotting!\n",
    "# Create a figure of the size 12x10 inches\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(1, 3, 1)           # Create a new subplot for the model data 2 row, 2 columns, 1st plot\n",
    "levels = range(0, 22, 2)       # Define the contour levels for all plots\n",
    "\n",
    "# Note this is where cube slicing is needed as you can only plot 2-coordinate\n",
    "# dimensions with qplt.contourf, so here we have selected time[0] as there is only\n",
    "# one timestep (the baseline 1961-1990 mean)\n",
    "qplt.contourf(cahpa_cube[0], levels=levels, cmap=cm.RdBu)\n",
    "                               \n",
    "\n",
    "plt.title('Q0 model')          # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "\n",
    "plt.subplot(1, 3, 2)           # Create a new subplot for the model data 2 row, 2 columns, 2nd plot\n",
    "qplt.contourf(cahpb_cube[0], levels=levels, cmap=cm.RdBu)\n",
    "\n",
    "plt.title('ECHAM5 model')       # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "\n",
    "plt.subplot(1, 3, 3)           # Create a new subplot for the observed data 2 row, 1 columns, second plot\n",
    "                               # This plot will be centred and below the two model plots\n",
    "qplt.contourf(obs_cube[0], levels=levels, cmap=cm.RdBu)\n",
    "\n",
    "plt.title('APHRODITE obs')     # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "\n",
    "plt.tight_layout()             # automatically adjusts subplot(s) to fit in to the figure area\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Mean annual cycle calculation\n",
    "\n",
    "If you have an area or region you want to focus on you can extract data for the region of interest. This example works through how to constrain your cube.\n",
    "\n",
    "__a) Extract the area around Kuala Lumpur from the monthly precipitation data for both the HadCM3Q0 (cahpa) and ECHAM5 (cahpb) driven runs by specifiying latitude and longitude coordinates__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrain the cube area over Kuala Lumpur (KL).\n",
    "# PRECIS uses a rotated grid, so the co-ordinates required are different to real world coordinates.\n",
    "\n",
    "for jobid in ['cahpa', 'cahpb']:\n",
    "    # Directory name where data are read from and stored to\n",
    "    infile = os.path.join(DATADIR, 'netcdf', jobid, jobid + '.pm.1981_1983.pr.norim.mmday-1.nc')\n",
    "    \n",
    "    # Load the baseline precipitation data using the KL_constraint - the command below\n",
    "    # loads the data into a cube constrained by the area chosen\n",
    "    data = iris.load_cube(infile)\n",
    "    # All grid cells whose longitudes and latitudes lie within the limits shown will be selected.\n",
    "    data_KL = data.intersection(grid_longitude=(-8.17, -7.43),\n",
    "                                grid_latitude=(-12.10, -11.38))\n",
    "\n",
    "    # save the constrained cube\n",
    "    outfile = os.path.join(DATADIR, 'netcdf', jobid, jobid + '.pm.1981_1983.pr.norim.mmday-1.KL.nc')\n",
    "    iris.save(data_KL, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for APHRODITE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the Aphrodite data are on a regular grid (unlike the  model data) so real latitudes and longitudes are\n",
    "# used to define the region around KL (more on this in section 2.6)\n",
    "obs_cube_KL = obs_cube.intersection(longitude=(101.25, 102.15),\n",
    "                                    latitude=(2.74, 3.48))\n",
    "\n",
    "# save the constrained cube to directory\n",
    "outfile = os.path.join(DATADIR, 'APHRODITE', 'aphro.pm.6190.KL.nc')\n",
    "iris.save(obs_cube_KL, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b) We now calculate monthly mean fields for 1961-1990 for each of the twelve months for the KL area__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jobid in ['cahpa', 'cahpb']:\n",
    "    # Set up the path to the data\n",
    "    infile = os.path.join(DATADIR, 'netcdf', jobid, jobid + '.pm.1981_1983.pr.norim.mmday-1.KL.nc')\n",
    "    \n",
    "    # Load the data extracted around Kuala Lumpur created in previous step\n",
    "    data = iris.load_cube(infile)\n",
    "\n",
    "    # Add monthly coord categorisation to the time dimension coordinate\n",
    "    iris.coord_categorisation.add_month_number(data, 'time', name='month_number')\n",
    "\n",
    "    # Calculate monthly mean values\n",
    "    monthly_mean = data.aggregated_by(['month_number'], iris.analysis.MEAN)\n",
    "\n",
    "    # Calculate area averaged monthly mean rainfall \n",
    "    monthly_mean = monthly_mean.collapsed(['grid_longitude', 'grid_latitude'], iris.analysis.MEAN)\n",
    "\n",
    "    # Save the area averaged monthly mean data\n",
    "    outfile = os.path.join(DATADIR, 'climatology', jobid + '.monmean.1981_1983.pr.norim.mmday-1.KL.nc')\n",
    "    iris.save(monthly_mean, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c) What is the KL area averaged monthly mean precipitation amount in mm/day for the HadCM3Q0 and ECHAM5 driven PRECIS runs?__ \n",
    "\n",
    "By plotting the data of the cubes note down the approximate values in mm day-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jobid in ['cahpa', 'cahpb']:\n",
    "    # Load the model cube\n",
    "    inpath = os.path.join(DATADIR, 'climatology', jobid + '.monmean.1981_1983.pr.norim.mmday-1.KL.nc')\n",
    "    cube = iris.load_cube(inpath)\n",
    "    \n",
    "    # Quick line plot for each cube \n",
    "    qplt.plot(cube.coord('month_number'), cube, label=jobid)\n",
    "    plt.title('KL area averaged ' + jobid + ' monthly\\n average of daily rainfall')\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_label_text('Month Number')\n",
    "    ax.set_xlim(0.5, 12.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__d) Now by following the same methodology as above for 1 b) for the KL area find the monthly means 1961-1990 for APHRODITE observations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dirctories to load and save to\n",
    "path_in = 'monthly/APHRODITE/' \n",
    "path_out = 'monthly/climatology/'\n",
    "\n",
    "# Load the KL extracted data created in previous step\n",
    "aphrod = iris.load_cube(path_in + 'aphro.pm.6190.05216.rr8.ext.mmday.nc')\n",
    "\n",
    "# Add monthly coord categorisation to the time dim coordinate\n",
    "iris.coord_categorisation.add_month_number(aphrod, 'time', name='month_number')\n",
    "\n",
    "# Now calculate monthly means\n",
    "aphro_monthly_mean = aphrod.aggregated_by(['month_number'], iris.analysis.MEAN)\n",
    "\n",
    "# create the area averaged monthly mean of daily rainfall \n",
    "aphro_monthly_mean = aphro_monthly_mean.collapsed(['longitude', 'latitude'], iris.analysis.MEAN)\n",
    "\n",
    "# Save output\n",
    "iris.save(aphro_monthly_mean, path_out + 'aphro.monmean.baseline.05216.rr8.ext.mmday.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question:</b> Plot the observations and the HadCM3Q0 and ECHAM5 driven PRECIS runs. What are the differences between the observations and models, what months are the differences greatest?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Comparing models and observations\n",
    "\n",
    "In 2.4 we saw how to plot individual model output on a map, but to compare spatial model and observation fields properly they must be on the same grid. We will regrid to the coarsest grid. For the data used here, the observations have the coarsest resolution so we will regrid the model data onto the observation grid.\n",
    "\n",
    "The PRECIS model data are on a grid known as a Rotated Grid. The idea is that the \"real\" north pole in the Arctic is shifted such that the equator relative to our rotated pole then runs through the centre of the regional model domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a) Regrid the multiannual OND mean model fields onto the observations grid__\n",
    "\n",
    "Here we use the `regrid` method to regrid the target cube. Here we will use linear interpolation. First, load in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory where data is stored\n",
    "data_path = os.path.join(DATADIR, 'climatology')\n",
    "\n",
    "# load cahpaa\n",
    "cahpa_model_cube = iris.load_cube(data_path + '/cahpa.a.OND.mean.baseline.pr.mmday-1.nc')\n",
    "# load cahpba\n",
    "cahpb_model_cube = iris.load_cube(data_path + '/cahpb.a.OND.mean.baseline.pr.mmday-1.nc')\n",
    "# load APHRODITE into a cube\n",
    "obs_cube = iris.load_cube(data_path + '/aphro.a.OND.mean.baseline.pr.mmday-1.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can regrid the model data to the grid used by the observations, the coordinate system used for the observations must be supplied.  In this case it is missing from the original NetCDF file, but the observations are on a regular longitude-latitude grid so the correct coordinate system is WGS84.\n",
    "\n",
    "We define the WGS84 coordinate system and then apply it to the x- and y-axes (i.e. longitudes and latitudes) of the observations.  The coordinate system used by the model (the rotated grid) is already defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define WGS84 projection for obs data\n",
    "wgs84 = iris.coord_systems.GeogCS(semi_major_axis=6378137.0, inverse_flattening=298.257223563)\n",
    "\n",
    "# Apply WGS84 to obs cube\n",
    "obs_cube.coord(axis='x').coord_system = wgs84\n",
    "obs_cube.coord(axis='y').coord_system = wgs84\n",
    "\n",
    "# Print out and compare the two coordinate systems\n",
    "print(obs_cube.coord_system())\n",
    "print(cahpa_model_cube.coord_system())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few lines regrid the model data to the regular grid used by the observations.  From the figures above, we know that the area over which APHRODITE data are available is larger than the PRECIS model domain. Hence, the extrapolation mode is set to 'mask' so that any grid cells on the APHRODITE grid which do not overlap with model grid cells are masked off; otherwise, the model data would be interpolated which would produce misleading results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regrid the climate model data onto APHRODITE grid\n",
    "cahpa_regrid = cahpa_model_cube.regrid(obs_cube, iris.analysis.Nearest(extrapolation_mode='mask'))\n",
    "cahpb_regrid = cahpb_model_cube.regrid(obs_cube, iris.analysis.Nearest(extrapolation_mode='mask'))\n",
    "\n",
    "# Save output\n",
    "iris.save(cahpa_regrid, data_path + '/cahpa.a.OND.mean.baseline.pr.mmday-1.rg.nc')\n",
    "iris.save(cahpb_regrid, data_path + '/cahpb.a.OND.mean.baseline.pr.mmday-1.rg.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model grids have been regridded to the observation cube: (i) load the netCDF files, and (ii) then plot the APHRODITE and model data again (as above in 15.) to compare them visually once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory name where data is read from\n",
    "indir = os.path.join(DATADIR, 'climatology')\n",
    "\n",
    "# load cahpa model data\n",
    "cahpa_cube = iris.load_cube(indir + '/cahpa.a.OND.mean.baseline.pr.mmday-1.rg.nc')\n",
    "\n",
    "# load cahpb model data\n",
    "cahpb_cube = iris.load_cube(indir + '/cahpb.a.OND.mean.baseline.pr.mmday-1.rg.nc')\n",
    "\n",
    "# load APHRODITE data\n",
    "obs_cube   = iris.load_cube(indir + '/aphro.a.OND.mean.baseline.pr.mmday-1.nc')\n",
    "\n",
    "# Do some plotting!\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "levels = range(0, 22, 2)\n",
    "\n",
    "\n",
    "qplt.contourf(cahpa_cube[0], levels=levels, cmap=cm.RdBu)\n",
    "plt.title('HadCM3Q0 precipitation \\n on a global longitude latitude grid')\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "\n",
    "plt.subplot(1, 3, 2) \n",
    "qplt.contourf(cahpb_cube[0], levels=levels, cmap=cm.RdBu)\n",
    "plt.title('ECHAM5 precipitation \\n on a global longitude latitude grid')\n",
    "ax = plt.gca()\n",
    "ax.coastlines()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "qplt.contourf(obs_cube[0], levels=levels, cmap=cm.RdBu)\n",
    "plt.title('Observational APHRODITE precipitation \\n on a coarser global longitude latitude grid')\n",
    "ax = plt.gca()\n",
    "ax.coastlines()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question:</b> What differences do you see?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__d) Find the difference between the model and the observation OND multiannual mean fields and plot maps to view the differences__\n",
    "\n",
    "We can simply subtract the model data from the observations.  There is a subtract function within Iris but it cannot be used here.  The model cubes contain extra coordinates which are not present in the obs cube; Iris requires all coordinates within the cubes to match exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure units are the same\n",
    "obs_cube.units = cahpb_cube.units\n",
    "\n",
    "# Make recieving cube\n",
    "cahpa_obs_diff = obs_cube.copy()\n",
    "cahpb_obs_diff = obs_cube.copy()\n",
    "\n",
    "# Replace data with the differences\n",
    "cahpa_obs_diff.data = cahpa_cube.data - obs_cube.data\n",
    "\n",
    "# cahpb - aphrodite differences\n",
    "cahpb_obs_diff.data = cahpb_cube.data - obs_cube.data\n",
    "\n",
    "# Save the differences\n",
    "# iris.save(cahpa_obs_diff, data_path + 'diff.cahpa_aphro.OND.baseline.nc')\n",
    "# iris.save(cahpb_obs_diff, data_path + 'diff.cahpb_aphro.OND.baseline.nc')\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.subplot(1, 2, 1)           # Create a new subplot for the first differences, 2 rows, 1 column, 1st plot\n",
    "\n",
    "# Cut-out region with data. We use the intersection method to plot the region with data\n",
    "qplt.pcolormesh(cahpa_obs_diff[0].intersection(longitude=(90, 135), latitude=(-20, 32)), \n",
    "                vmax=10, vmin=-10, \n",
    "                cmap=plt.get_cmap('RdBu'))   # Note this is where cube slicing is needed as you can only plot 2-coordinate\n",
    "                               # dimensions with qplt.contourf, so here we have selected time[0] as there is only\n",
    "                               # one timestep (the baseline 1961-1990 mean)\n",
    "\n",
    "plt.title('cahpa - obs')       # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "\n",
    "plt.subplot(1, 2, 2)           # Create a new subplot for the model data 2 row, 2 columns, 2nd plot\n",
    "qplt.pcolormesh(cahpb_obs_diff[0].intersection(longitude=(90, 135), latitude=(-20, 32)),\n",
    "             vmax=10, vmin=-10,\n",
    "             cmap=plt.get_cmap('RdBu'))\n",
    "\n",
    "plt.title('cahpb - obs')       # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Climatological mean and annual cycle for an ensemble\n",
    "\n",
    "So far data from two models downscaled with PRECIS have been analysed. In this section we will look at some addional HadCM3 ensemble memebers and the CRU data set. \n",
    "\n",
    "This gives us an ensemble of RCM data:\n",
    "\n",
    "* HadCM3Q0 (cahpa)\n",
    "* ECHAM5 (cahpb)\n",
    "* HadCM3Q3 (cahpc)\n",
    "* HadCM3Q10 (cahpd)\n",
    "* HadCM3Q11 (cahpe)\n",
    "* HadCM3Q13 (cahpf)\n",
    "\n",
    "And observational datasets:\n",
    "\n",
    "* APHRODITE\n",
    "* CRU\n",
    "\n",
    "The CRU data are a monthly global land-only dataset (1901-present) at 0.5 degree resolution. Nine variables are available, including mean, min, max temperature and precipitation. For further details please see: http://www.cru.uea.ac.uk/~timm/grid/CRU_TS_2_1.html\n",
    "\n",
    "Taking an ensemble approach allows us to account for a range of uncertainty in the model projections.\n",
    "\n",
    "Write a series of scripts to do the following:\n",
    "\n",
    "__a) Calculate the OND seasonal mean and annual cycle (for the KL area) for 1.5m temperature and precipitation for CRU and APHRODITE observations__\n",
    "\n",
    "__b) Calculate OND seasonal-mean and monthly-mean anomalies for the KL area for the 4 additional HadCM3Q ensemble members (cahpc, cahpd, cahpe & cahpf)__\n",
    "\n",
    "__c) Plot a series of figures that shows 1) the monthly cycles of temperature and rainfall comparing the 6 models and the observations; and 2) the monthly differences between the models and observations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here are some useful varibles  you might like to use in your scripts\n",
    "'''\n",
    "# Some helpful data locations\n",
    "DATADIR = '/project/precis/worksheets/data'\n",
    "APHRODIR = os.path.join(DATADIR, 'APHRODITE')\n",
    "CRUDIR = os.path.join(DATADIR, 'CRU')\n",
    "CLIMDIR = os.path.join(DATADIR, 'climatology')\n",
    "MODELDIR = os.path.join(DATADIR, 'netcdf')\n",
    "\n",
    "# Some helpful model variables\n",
    "JOBID = ['cahpa', 'cahpb', 'cahpc', 'cahpd', 'cahpe', 'cahpf']\n",
    "STASHCODES = ['03236', '05216']\n",
    "\n",
    "# Kuala Lumpur domains...\n",
    "# ... in roatated pole coordinates\n",
    "grid_longitude=(-8.17, -7.43)\n",
    "grid_latitude=(-12.10, -11.38)\n",
    "# ... in true lat-lon coordiates\n",
    "longitude=(101.25, 102.15)\n",
    "latitude=(2.74, 3.48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "a) Calculate the OND seasonal-mean and monthly-mean 1.5m temperature and precipitation \n",
    "for the KL area, for CRU and APHRODITE observations\n",
    "'''\n",
    "# Load APHRODITE data\n",
    "\n",
    "# Load CRU data\n",
    "\n",
    "# Extract KL area\n",
    "\n",
    "# Add OND season catagorisation\n",
    "\n",
    "# Add monthly catagorisation\n",
    "\n",
    "# Extract season\n",
    "\n",
    "# Aggregate cubes\n",
    "\n",
    "# Find KL area average\n",
    "\n",
    "# Check and add cube metadata\n",
    "\n",
    "# Save cubes to CLIMDIR\n",
    "# Remember to use the same naming convention we used earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "b) Calculate OND seasonal-mean and monthly-mean anomalies for the KL area \n",
    "for the 4 additional HadCM3Q ensemble members (cahpc, cahpd, cahpe & cahpf)\n",
    "'''\n",
    "# Load ensemble members\n",
    "# Remember you need to do this for both precipitation AND temperature\n",
    "\n",
    "# Regrid ensemble members onto observational grid\n",
    "# Remember you need to check your model and obs cubes have the appropriate coordinate systems defined\n",
    "\n",
    "# Extract the KL area. Remember you are now working in true lat-lon coordinates!\n",
    "\n",
    "# Find OND and monthly means\n",
    "\n",
    "# Calculate model anomalies\n",
    "# Remember temp anomaly   = model - CRU data\n",
    "#          precip anomaly = model - APHRO data\n",
    "\n",
    "# Check cube metadata consitency and save\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question:</b> What difference would it make if we first extracted the KL area and <em>then</em> regrid the models? <br> \n",
    "Which order is best for preserving data integrity?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c) Create four figures:__\n",
    "    \n",
    "    i) the monthly cycle of temperature (model and observations) \n",
    "    ii) the monthly cyce of rainfall (model and observations)\n",
    "    iii) the monthly temperature anomaly for each model\n",
    "    iv) the monthly precipitation anomaly for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot 1: The monthly cycle of temperature (model and observations)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot 2: The monthly cycle of precipitation (model and observations)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot 3: The monthly temperature anomaly for each model\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot 4: The monthly precipitation anomaly for each model\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question:</b> How could you summarise the ensemble variability amongst model members in a plot?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question:</b> How does the monthly temperature and precipitation anomaly compare to the OND average?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question:</b> What are the advantages and disadvantages of plotting spatial maps of temperature and rainfall variability over Kuala Lumpur?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â© Crown Copyright 2018, Met Office"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <b>Tutorial 4: Advanced data analysis</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives:\n",
    "\n",
    "In this session we will learn: \n",
    "1. to calculate frequency of wet days\n",
    "2. to calculate percentiles\n",
    "3. how to calculate some useful climate extremes statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Frequency of wet days](#freq)\n",
    "2. [Percentiles](#percent)\n",
    "3. [Investigating extremes](#extremes)\n",
    "4. [Exercises](#exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Prerequisites</b> <br> \n",
    "- Basic programming skills in python<br>\n",
    "- Familiarity with python libraries Iris, Numpy and Matplotlib<br>\n",
    "- Basic understanding of climate data<br>\n",
    "- Tutorial 1, 2 and 3\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Frequency of wet days<a id='freq'></a>\n",
    "### 1.1 Import libraries\n",
    "Import the necessary libraries. Current datasets are in zarr format, we need zarr and xarray libraries to access the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import zarr\n",
    "import iris\n",
    "import os\n",
    "from cssp_utils import zarr_reader\n",
    "from iris.analysis import Aggregator\n",
    "import dask\n",
    "dask.config.set(scheduler=dask.get)\n",
    "import dask.array as da\n",
    "import iris.quickplot as qplt\n",
    "import iris.plot as iplt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "from catnip.preparation import extract_rot_cube, add_bounds\n",
    "from xarray_iris_coord_system import XarrayIrisCoordSystem as xics\n",
    "xi = xics()\n",
    "xr.set_options(display_style='text') # Work around for AML bug that won't display HTML output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Prerequisites</b> <br> \n",
    "- Basic programming skills in python<br>\n",
    "- Familiarity with python libraries Iris, Numpy and Matplotlib<br>\n",
    "- Basic understanding of climate data<br>\n",
    "- Tutorials 1, 2 and 3\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set up authentication for the Azure blob store\n",
    "\n",
    "The data for this course is held online in an Azure Blob Storage Service. To access this we use a SAS (shared access signature).  You should have been given the credentials for this service before the course, but if not please ask your instructor. We use the getpass module here to avoid putting the token into the public domain. Run the cell below and in the box enter your SAS and press return. This will store the password in the variable SAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "# SAS WITHOUT leading '?'\n",
    "SAS = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the Zarr library to connect to this storage. This is a little like opening a file on a local file system but works without downloading the data. This makes use of the Azure Blob Storage service. The zarr.ABStore method returns a zarr.storage.ABSStore object which we can now use to access the Zarr data in the same way we would use a local file. If you have a Zarr file on a local file system you could skip this step and instead just use the path to the Zarr data below when opening the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = zarr.ABSStore(container='metoffice-20cr-ds', prefix='daily/', account_name=\"metdatasa\", blob_service_kwargs={\"sas_token\":SAS})\n",
    "type(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Read daily data\n",
    "A Dataset consists of coordinates and data variables. Let's use the xarray's **open_zarr()** method to read all our zarr data into a dataset object and display it's metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the open_zarr() method to read in the whole dataset metadata\n",
    "dataset = xr.open_zarr(store)\n",
    "# print out the metadata\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataset into an iris cubelist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xarray_iris_coord_system import XarrayIrisCoordSystem as xics\n",
    "xi = xics()\n",
    "# create an empty list to hold the iris cubes\n",
    "cubelist = iris.cube.CubeList([])\n",
    "\n",
    "# use the DataSet.apply() to convert the dataset to Iris Cublelist\n",
    "dataset.apply(lambda da: cubelist.append(xi.to_iris(da)))\n",
    "\n",
    "# print out the cubelist.\n",
    "cubelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> The following <b>sections</b> demonstrate analysis of moderate extremes. The basis of climate extremes analysis is a common set of standard extreme climate indices, defined by the World Climate Research Programme <a href=\"https://www.wcrp-climate.org/etccdi\">Expert Team on Climate Change Detection and Indices (ETCCDI)</a>\n",
    "    \n",
    "<br>There are 27 climate extremes indices, nicely summarised by the <a href=\"https://www.climdex.org/learn/indices/\">Climdex</a> website.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Calculate number of wet days ($\\mathrm{pr} \\geq 1 mm \\;day^{-1}$)\n",
    "\n",
    "In this section we'll be looking at wet days, a threshold measure giving the count of days when $\\mathrm{pr} \\geq 1 mm \\;day^{-1}$, and R95p, the 95th percentile of precipitation on wet days ($\\mathrm{pr} \\geq 1 mm \\;day^{-1}$) in the 1851-1900 period over the Shanghai region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'precipitation_flux' cube\n",
    "pflx = cubelist.extract_strict('precipitation_flux')\n",
    "# To avoid warnings when collapsing coordinates and also when plotting, add bounds to all coordinates\n",
    "pflx = add_bounds(pflx,['time', 'grid_latitude', 'grid_longitude'])\n",
    "# convert units to mm/day (equivalent to 'kg m-2 day-1')\n",
    "pflx.convert_units('kg m-2 day-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the time and region constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define time constraint and extract 1851-1900 period\n",
    "start_time = 1851\n",
    "end_time = 1900\n",
    "\n",
    "# define the time constraint\n",
    "time_constraint = iris.Constraint(time=lambda cell: start_time <= cell.point.year <= end_time)\n",
    "\n",
    "# laod the data into cubes applying the time constraint\n",
    "pflx = pflx.extract(time_constraint)\n",
    "\n",
    "# extract Shangai region and constain with time\n",
    "\n",
    "# defining Shangai region coords\n",
    "min_lat=29.0\n",
    "max_lat=32.0\n",
    "min_lon=118.0\n",
    "max_lon=123.0\n",
    "\n",
    "# extract data for the the Shanghai region using extract_rot_cube() function\n",
    "pflx = extract_rot_cube(pflx, min_lat, min_lon, max_lat, max_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use the iris COUNT aggregator to count the number of days with > 1mm precip\n",
    "wetdays = pflx.collapsed('time', iris.analysis.COUNT, function=lambda values: values > 1)\n",
    "wetdays.rename('number of wet days (>=1mm/day)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find wet days as a percentage of total days\n",
    "total_days = len(pflx.coord('time').points)\n",
    "pcent_wetdays = (wetdays / total_days) * 100\n",
    "\n",
    "# renaming the cube name and units\n",
    "pcent_wetdays.rename('percentage of wet days (>=1mm/day)')\n",
    "pcent_wetdays.units = '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can plot the number and percententage of wet days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.suptitle('Number of wet days (1851-1900)', fontsize=16)\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(wetdays)\n",
    "ax1.coastlines()\n",
    "ax1 = fig.add_subplot(1, 2, 2, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(pcent_wetdays)\n",
    "ax1.coastlines()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Task:</b><br><ul>\n",
    "        <li> Calculate and visualise the percentage difference of wet days from past (1851-1880) to recent (1981-2010) 30 years period.\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Percentiles<a id='percent'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Calculating 95th percentile of precipitation\n",
    "\n",
    "In this section we will calculate the extreme precipitation i.e. 95th percentile of rainfall on wet days over Shanghai region from 1981-2010. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'precipitation_flux' cube\n",
    "pflx = cubelist.extract_strict('precipitation_flux')\n",
    "\n",
    "# change the units to kg m-2 d-1\n",
    "pflx.convert_units('kg m-2 d-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define time constraint and extract 1851-1900 period\n",
    "start_time = 1981\n",
    "end_time = 2010\n",
    "\n",
    "# define the time constraint\n",
    "cons = iris.Constraint(time=lambda cell: start_time <= cell.point.year <= end_time)\n",
    "\n",
    "# laod the data into cubes applying the time constraint\n",
    "pflx = pflx.extract(cons)\n",
    "\n",
    "# extract Shangai region and constain with time\n",
    "\n",
    "# defining Shangai region coords\n",
    "min_lat=29.0\n",
    "max_lat=32.0\n",
    "min_lon=118.0\n",
    "max_lon=123.0\n",
    "\n",
    "# extract data for the the Shanghai region using extract_rot_cube() function\n",
    "pflx = extract_rot_cube(pflx, min_lat, min_lon, max_lat, max_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the cube, mask where daily rainfall < 1 so that only wet days\n",
    "# are included in the calculation\n",
    "pflx_wet = pflx.copy()\n",
    "pflx_wet.data = np.ma.masked_less(pflx_wet.data, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the *iris.analysis.PERCENTILE* method to calculate the percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pflx_pc95 = pflx_wet.collapsed('time', iris.analysis.PERCENTILE, percent=95.)\n",
    "pflx_pc95.rename('R95p of daily rainfall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.suptitle('Extreme rainfall', fontsize=16)\n",
    "qplt.pcolormesh(pflx_pc95)\n",
    "plt.gca().coastlines()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Investigate extremes<a id='extremes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Calculate the extreme index TX90P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the frequency of warm days in the present (extreme index TX90P), i.e. the number of days which exceed the 90th percentile temperatures in the baseline. Then calculate the numbers of days as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first extract the air_temperature at 1.5m cubes from the cubelist\n",
    "air_temp = cubelist.extract('air_temperature' & iris.AttributeConstraint(Height='1.5 m'))\n",
    "\n",
    "# constraint for the maximum temperature \n",
    "max_temp_cons = iris.Constraint(cube_func=lambda c: (len(c.cell_methods) > 0) and \n",
    "                                (c.cell_methods[0].method == 'maximum'))\n",
    "\n",
    "# define time constraint and extract 1851-1900 period (the baseline)\n",
    "start_time = 1851\n",
    "end_time = 1900\n",
    "\n",
    "# define the time constraint\n",
    "time_constraint = iris.Constraint(time=lambda cell: start_time <= cell.point.year <= end_time)\n",
    "\n",
    "# applying the pressure, maximum temperature and time constraints getting a single cube\n",
    "max_temp = air_temp.extract_strict(max_temp_cons & time_constraint)\n",
    "\n",
    "# defining Shangai region coords\n",
    "min_lat=29.0\n",
    "max_lat=32.0\n",
    "min_lon=118.0\n",
    "max_lon=123.0\n",
    "\n",
    "# extract data for the the Shanghai region using extract_rot_cube() function\n",
    "max_temp = extract_rot_cube(max_temp, min_lat, min_lon, max_lat, max_lon)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_temp_pc90 = max_temp.collapsed('time', iris.analysis.PERCENTILE, percent=90.)\n",
    "max_temp_pc90.rename('R90p of daily maximum temperature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extract present day\n",
    "# extract a single cube of maximum air_temperature at 1.5m cube from the cubelist\n",
    "max_temp = cubelist.extract_strict('air_temperature' & iris.AttributeConstraint(Height='1.5 m') &\n",
    "                           max_temp_cons)\n",
    "# extract data for the the Shanghai region using extract_rot_cube() function\n",
    "max_temp = extract_rot_cube(max_temp, min_lat, min_lon, max_lat, max_lon)\n",
    "\n",
    "\n",
    "start_time = 1981\n",
    "end_time = 2010\n",
    "\n",
    "time_constraint = iris.Constraint(time=lambda cell: start_time <= cell.point.year <= end_time)\n",
    "max_temp = max_temp.extract(time_constraint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to calculate the number of warm days, we do so by counting all the data points that are greater than 90th percentile of the baseline period within the last 30 years. We can use numpy method **np.where** which return 1 where max_temp is greater then max_temp_pc90 and returns 0 otherise. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new cube to hold the counts\n",
    "nwarmdays = max_temp_pc90.copy()\n",
    "\n",
    "# Use broadcasting to identify all cells where daily temperatures in the future exceed the 95th percentile\n",
    "temp_gt_pc90 = np.where(max_temp.data >= max_temp_pc90.data, 1, 0)\n",
    "\n",
    "# using np.ma.sum to sum the number of warm days above the 90th percentile\n",
    "nwarmdays.data = np.ma.sum(temp_gt_pc90, axis=0)\n",
    "\n",
    "# the sum above removes the mask - reinstate it with \n",
    "nwarmdays.data.mask = max_temp_pc90.data.mask\n",
    "nwarmdays.units = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qplt.pcolormesh(nwarmdays)\n",
    "plt.gca().coastlines() \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate percentage of warmest days by using **iris.analysis.maths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndays = max_temp.shape[0]\n",
    "# calculating percentage \n",
    "nwd_pcent = iris.analysis.maths.divide(iris.analysis.maths.multiply(nwarmdays, 100), ndays)\n",
    "nwd_pcent.units=\"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting the percentage of warm days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qplt.pcolormesh(nwd_pcent)\n",
    "plt.title('Percentage of warm days')\n",
    "plt.gca().coastlines() \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Task:</b><br><ul>\n",
    "        <li> Calculate and plot the past (1851-1880) and present (1981-2010) 90th percentile of maximum temperature and the difference between them.\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exercises<a id='exercise'></a>\n",
    "\n",
    "In this exercise we will calculate the percentage of total precipitation from 1981-2010 which falls on very wet days (where a very wet day is one on which daily rainfall exceeds the 95th percentile of the baseline) over Shanghai region.\n",
    "\n",
    "Further we also calculate the percentage of very wet days in the past (1851-1880) and see the difference by plotting the difference of heavy rainfall in the past and present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: calculate the percentage of total precipitation from 1981-2010 on very wet days (=> 95th Percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: calculate the percentage of total precipitation from 1951-1880 on very wet days (=> 95th Percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Calculate the difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Plot the percentages and difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Summary</b><br> \n",
    "    In this session we learned how:<br>\n",
    "    <ul>\n",
    "        <li>to calculate extreme values and percentages\n",
    "        <li>to calcuate basic extreme value indices  \n",
    "    </ul>\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cssp37",
   "language": "python",
   "name": "cssp37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

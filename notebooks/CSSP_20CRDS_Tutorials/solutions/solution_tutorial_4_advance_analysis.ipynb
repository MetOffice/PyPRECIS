{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <b>Tutorial 4: Advanced data analysis</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives:\n",
    "\n",
    "In this session we will learn: \n",
    "1. to calculate frequency of wet days\n",
    "2. to calculate percentiles\n",
    "3. how to calculate some useful climate extremes statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. [Frequency of wet days](#freq)\n",
    "2. [Percentiles](#percent)\n",
    "3. [Investigating extremes](#extremes)\n",
    "4. [Exercises](#exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Prerequisites</b> <br> \n",
    "- Basic programming skills in python<br>\n",
    "- Familiarity with python libraries Iris, Numpy and Matplotlib<br>\n",
    "- Basic understanding of climate data<br>\n",
    "- Tutorial 1, 2 and 3\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Frequency of wet days<a id='freq'></a>\n",
    "### 1.1 Import libraries\n",
    "Import the necessary libraries. Current datasets are in zarr format, we need zarr and xarray libraries to access the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import zarr\n",
    "import iris\n",
    "import os\n",
    "import sys\n",
    "from iris.analysis import Aggregator\n",
    "import dask\n",
    "\n",
    "dask.config.set(scheduler=dask.get)\n",
    "import dask.array as da\n",
    "import iris.quickplot as qplt\n",
    "import iris.plot as iplt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "from catnip.preparation import extract_rot_cube, add_bounds\n",
    "from scripts.xarray_iris_coord_system import XarrayIrisCoordSystem as xics\n",
    "\n",
    "xi = xics()\n",
    "xr.set_options(\n",
    "    display_style=\"text\"\n",
    ")  # Work around for AML bug that won't display HTML output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Prerequisites</b> <br> \n",
    "- Basic programming skills in python<br>\n",
    "- Familiarity with python libraries Iris, Numpy and Matplotlib<br>\n",
    "- Basic understanding of climate data<br>\n",
    "- Tutorials 1, 2 and 3\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set up authentication for the Azure blob store\n",
    "\n",
    "The data for this course is held online in an Azure Blob Storage Service. To access this we use a SAS (shared access signature).  You should have been given the credentials for this service before the course, but if not please ask your instructor. We use the getpass module here to avoid putting the token into the public domain. Run the cell below and in the box enter your SAS and press return. This will store the password in the variable SAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# SAS WITHOUT leading '?'\n",
    "SAS = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the Zarr library to connect to this storage. This is a little like opening a file on a local file system but works without downloading the data. This makes use of the Azure Blob Storage service. The zarr.ABStore method returns a zarr.storage.ABSStore object which we can now use to access the Zarr data in the same way we would use a local file. If you have a Zarr file on a local file system you could skip this step and instead just use the path to the Zarr data below when opening the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = zarr.ABSStore(\n",
    "    container=\"metoffice-20cr-ds\",\n",
    "    prefix=\"daily/\",\n",
    "    account_name=\"metdatasa\",\n",
    "    blob_service_kwargs={\"sas_token\": SAS},\n",
    ")\n",
    "type(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Read daily data\n",
    "A Dataset consists of coordinates and data variables. Let's use the xarray's **open_zarr()** method to read all our zarr data into a dataset object and display it's metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the open_zarr() method to read in the whole dataset metadata\n",
    "dataset = xr.open_zarr(store)\n",
    "# print out the metadata\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataset into an iris cubelist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xarray_iris_coord_system import XarrayIrisCoordSystem as xics\n",
    "\n",
    "xi = xics()\n",
    "# create an empty list to hold the iris cubes\n",
    "cubelist = iris.cube.CubeList([])\n",
    "\n",
    "# use the DataSet.apply() to convert the dataset to Iris Cublelist\n",
    "dataset.apply(lambda da: cubelist.append(xi.to_iris(da)))\n",
    "\n",
    "# print out the cubelist.\n",
    "cubelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Note:</b> The following <b>sections</b> demonstrate analysis of moderate extremes. The basis of climate extremes analysis is a common set of standard extreme climate indices, defined by the World Climate Research Programme <a href=\"https://www.wcrp-climate.org/etccdi\">Expert Team on Climate Change Detection and Indices (ETCCDI)</a>\n",
    "    \n",
    "<br>There are 27 climate extremes indices, nicely summarised by the <a href=\"https://www.climdex.org/learn/indices/\">Climdex</a> website.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Calculate number of wet days ($\\mathrm{pr} \\geq 1 mm \\;day^{-1}$)\n",
    "\n",
    "In this section we'll be looking at wet days, a threshold measure giving the count of days when $\\mathrm{pr} \\geq 1 mm \\;day^{-1}$, and R95p, the 95th percentile of precipitation on wet days ($\\mathrm{pr} \\geq 1 mm \\;day^{-1}$) in the 1851-1900 period over the Shanghai region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'precipitation_flux' cube\n",
    "pflx = cubelist.extract_strict(\"precipitation_flux\")\n",
    "# To avoid warnings when collapsing coordinates and also when plotting, add bounds to all coordinates\n",
    "pflx = add_bounds(pflx, [\"time\", \"grid_latitude\", \"grid_longitude\"])\n",
    "# convert units to mm/day (equivalent to 'kg m-2 day-1')\n",
    "pflx.convert_units(\"kg m-2 day-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the time and region constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define time constraint and extract 1851-1900 period\n",
    "start_time = 1851\n",
    "end_time = 1900\n",
    "\n",
    "# define the time constraint\n",
    "time_constraint = iris.Constraint(\n",
    "    time=lambda cell: start_time <= cell.point.year <= end_time\n",
    ")\n",
    "\n",
    "# laod the data into cubes applying the time constraint\n",
    "pflx = pflx.extract(time_constraint)\n",
    "\n",
    "# extract Shangai region and constain with time\n",
    "\n",
    "# defining Shangai region coords\n",
    "min_lat = 29.0\n",
    "max_lat = 32.0\n",
    "min_lon = 118.0\n",
    "max_lon = 123.0\n",
    "\n",
    "# extract data for the the Shanghai region using extract_rot_cube() function\n",
    "pflx = extract_rot_cube(pflx, min_lat, min_lon, max_lat, max_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use the iris COUNT aggregator to count the number of days with > 1mm precip\n",
    "wetdays = pflx.collapsed(\n",
    "    \"time\", iris.analysis.COUNT, function=lambda values: values > 1\n",
    ")\n",
    "wetdays.rename(\"number of wet days (>=1mm/day)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find wet days as a percentage of total days\n",
    "total_days = len(pflx.coord(\"time\").points)\n",
    "pcent_wetdays = (wetdays / total_days) * 100\n",
    "\n",
    "# renaming the cube name and units\n",
    "pcent_wetdays.rename(\"percentage of wet days (>=1mm/day)\")\n",
    "pcent_wetdays.units = \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can plot the number and percentage of wet days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.suptitle(\"Number of wet days (1851-1900)\", fontsize=16)\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(wetdays)\n",
    "ax1.coastlines()\n",
    "ax1 = fig.add_subplot(1, 2, 2, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(pcent_wetdays)\n",
    "ax1.coastlines()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Task:</b><br><ul>\n",
    "        <li> Calculate and visualise the percentage difference of wet days from past (1851-1880) to recent (1981-2010) 30 years period.\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'precipitation_flux' cube\n",
    "pflx = cubelist.extract_strict(\"precipitation_flux\")\n",
    "# To avoid warnings when collapsing coordinates and also when plotting, add bounds to all coordinates\n",
    "pflx = add_bounds(pflx, [\"time\", \"grid_latitude\", \"grid_longitude\"])\n",
    "# convert units to mm/day (equivalent to 'kg m-2 day-1')\n",
    "pflx.convert_units(\"kg m-2 day-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define historical time constraint and extract 1851-1880 period\n",
    "start_time = 1851\n",
    "end_time = 1880\n",
    "\n",
    "# define the historical time constraint\n",
    "past_time_constraint = iris.Constraint(\n",
    "    time=lambda cell: start_time <= cell.point.year <= end_time\n",
    ")\n",
    "\n",
    "# laod the data into cubes applying the time constraint\n",
    "past_pflx = pflx.extract(past_time_constraint)\n",
    "\n",
    "# define recent time constraint and extract 1981-2010 period\n",
    "start_time = 1981\n",
    "end_time = 2010\n",
    "\n",
    "# define the recent time constraint\n",
    "recent_time_constraint = iris.Constraint(\n",
    "    time=lambda cell: start_time <= cell.point.year <= end_time\n",
    ")\n",
    "\n",
    "# laod the data into cubes applying the time constraint\n",
    "recent_pflx = pflx.extract(recent_time_constraint)\n",
    "\n",
    "# defining Shangai region coords\n",
    "min_lat = 29.0\n",
    "max_lat = 32.0\n",
    "min_lon = 118.0\n",
    "max_lon = 123.0\n",
    "\n",
    "# extract data for the the Shanghai region using extract_rot_cube() function\n",
    "past_pflx = extract_rot_cube(past_pflx, min_lat, min_lon, max_lat, max_lon)\n",
    "recent_pflx = extract_rot_cube(recent_pflx, min_lat, min_lon, max_lat, max_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use the iris COUNT aggregator to count the number of days with > 1mm precip\n",
    "past_wetdays = past_pflx.collapsed(\n",
    "    \"time\", iris.analysis.COUNT, function=lambda values: values > 1\n",
    ")\n",
    "past_wetdays.rename(\"historical number of wet days (>=1mm/day)\")\n",
    "\n",
    "\n",
    "# Find wet days as a percentage of total days\n",
    "total_days = len(past_wetdays.coord(\"time\").points)\n",
    "pcent_past_wetdays = (past_wetdays / total_days) * 100\n",
    "\n",
    "# renaming the cube name and units\n",
    "pcent_past_wetdays.rename(\"historical percentage of wet days (>=1mm/day)\")\n",
    "pcent_past_wetdays.units = \"%\"\n",
    "\n",
    "# calculate for the recent data\n",
    "recent_wetdays = recent_pflx.collapsed(\n",
    "    \"time\", iris.analysis.COUNT, function=lambda values: values > 1\n",
    ")\n",
    "recent_wetdays.rename(\"recent number of wet days (>=1mm/day)\")\n",
    "\n",
    "# Find wet days as a percentage of total days\n",
    "total_days = len(recent_wetdays.coord(\"time\").points)\n",
    "pcent_recent_wetdays = (recent_wetdays / total_days) * 100\n",
    "\n",
    "# renaming the cube name and units\n",
    "pcent_recent_wetdays.rename(\"recent percentage of wet days (>=1mm/day)\")\n",
    "pcent_recent_wetdays.units = \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data as number of wet days\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.suptitle(\n",
    "    \"Number of wet days Historical (1851-1900) vs Recent (1981-2010)\", fontsize=16\n",
    ")\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(past_wetdays)\n",
    "ax1.coastlines()\n",
    "ax1 = fig.add_subplot(1, 2, 2, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(recent_wetdays)\n",
    "ax1.coastlines()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data as percentage of wet days\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.suptitle(\n",
    "    \"Percentage of wet days Historical (1851-1900) vs Recent (1981-2010)\", fontsize=16\n",
    ")\n",
    "ax1 = fig.add_subplot(1, 2, 1, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(pcent_past_wetdays)\n",
    "ax1.coastlines()\n",
    "ax1 = fig.add_subplot(1, 2, 2, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(pcent_recent_wetdays)\n",
    "ax1.coastlines()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Percentiles<a id='percent'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Calculating 95th percentile of precipitation\n",
    "\n",
    "In this section we will calculate the extreme precipitation i.e. 95th percentile. We have already extracted our cube *Pflx%* so we can use the *iris.analysis.PERCENTILE* method to calculate the percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'precipitation_flux' cube\n",
    "pflx = cubelist.extract_strict(\"precipitation_flux\")\n",
    "\n",
    "# change the units to kg m-2 d-1\n",
    "pflx.convert_units(\"kg m-2 d-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define time constraint and extract 1851-1900 period\n",
    "start_time = 1981\n",
    "end_time = 2010\n",
    "\n",
    "# define the time constraint\n",
    "cons = iris.Constraint(time=lambda cell: start_time <= cell.point.year <= end_time)\n",
    "\n",
    "# laod the data into cubes applying the time constraint\n",
    "pflx = pflx.extract(cons)\n",
    "\n",
    "# extract Shangai region and constain with time\n",
    "\n",
    "# defining Shangai region coords\n",
    "min_lat = 29.0\n",
    "max_lat = 32.0\n",
    "min_lon = 118.0\n",
    "max_lon = 123.0\n",
    "\n",
    "# extract data for the the Shanghai region using extract_rot_cube() function\n",
    "pflx = extract_rot_cube(pflx, min_lat, min_lon, max_lat, max_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the cube, mask where daily rainfall < 1 so that only wet days\n",
    "# are included in the calculation\n",
    "pflx_wet = pflx.copy()\n",
    "pflx_wet.data = np.ma.masked_less(pflx_wet.data, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the iris.analysis.PERCENTILE method to calculate the percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pflx_pc95 = pflx_wet.collapsed(\"time\", iris.analysis.PERCENTILE, percent=95.0)\n",
    "pflx_pc95.rename(\"R95p of daily rainfall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.suptitle(\"Extreme rainfall\", fontsize=16)\n",
    "qplt.pcolormesh(pflx_pc95)\n",
    "plt.gca().coastlines()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Investigate extremes<a id='extremes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Calculate the extreme index TX90P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the frequency of warm days in the present (extreme index TX90P), i.e. the number of days which exceed the 90th percentile temperatures in the baseline. Then calculate the numbers of days as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first extract the air_temperature at 1.5m cubes from the cubelist\n",
    "air_temp = cubelist.extract(\n",
    "    \"air_temperature\" & iris.AttributeConstraint(Height=\"1.5 m\")\n",
    ")\n",
    "\n",
    "# constraint for the maximum temperature\n",
    "max_temp_cons = iris.Constraint(\n",
    "    cube_func=lambda c: (len(c.cell_methods) > 0)\n",
    "    and (c.cell_methods[0].method == \"maximum\")\n",
    ")\n",
    "\n",
    "# define time constraint and extract 1851-1900 period (the baseline)\n",
    "start_time = 1851\n",
    "end_time = 1900\n",
    "\n",
    "# define the time constraint\n",
    "time_constraint = iris.Constraint(\n",
    "    time=lambda cell: start_time <= cell.point.year <= end_time\n",
    ")\n",
    "\n",
    "# applying the pressure, maximum temperature and time constraints getting a single cube\n",
    "max_temp = air_temp.extract_strict(max_temp_cons & time_constraint)\n",
    "\n",
    "# defining Shangai region coords\n",
    "min_lat = 29.0\n",
    "max_lat = 32.0\n",
    "min_lon = 118.0\n",
    "max_lon = 123.0\n",
    "\n",
    "# extract data for the the Shanghai region using extract_rot_cube() function\n",
    "max_temp = extract_rot_cube(max_temp, min_lat, min_lon, max_lat, max_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_temp_pc90 = max_temp.collapsed(\"time\", iris.analysis.PERCENTILE, percent=90.0)\n",
    "max_temp_pc90.rename(\"R90p of daily maximum temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extract present day\n",
    "# extract a single cube of maximum air_temperature at 1.5m cube from the cubelist\n",
    "max_temp = cubelist.extract_strict(\n",
    "    \"air_temperature\" & iris.AttributeConstraint(Height=\"1.5 m\") & max_temp_cons\n",
    ")\n",
    "# extract data for the the Shanghai region using extract_rot_cube() function\n",
    "max_temp = extract_rot_cube(max_temp, min_lat, min_lon, max_lat, max_lon)\n",
    "\n",
    "start_time = 1981\n",
    "end_time = 2010\n",
    "\n",
    "time_constraint = iris.Constraint(\n",
    "    time=lambda cell: start_time <= cell.point.year <= end_time\n",
    ")\n",
    "max_temp = max_temp.extract(time_constraint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to calculate the number of warm days, we do so by counting all the data points that are greater than 90th percentile of the baseline period within the last 30 years. We can use numpy method **np.where** which return 1 where max_temp is greater then max_temp_pc90 and returns 0 otherise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new cube to hold the counts\n",
    "nwarmdays = max_temp_pc90.copy()\n",
    "\n",
    "# Use broadcasting to identify all cells where daily temperatures in the future exceed the 95th percentile\n",
    "temp_gt_pc90 = np.where(max_temp.data >= max_temp_pc90.data, 1, 0)\n",
    "\n",
    "# using np.ma.sum to sum the number of warm days above the 90th percentile\n",
    "nwarmdays.data = np.ma.sum(temp_gt_pc90, axis=0)\n",
    "\n",
    "# the sum above removes the mask - reinstate it with\n",
    "nwarmdays.data.mask = max_temp_pc90.data.mask\n",
    "nwarmdays.units = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwarmdays = add_bounds(nwarmdays, [\"grid_latitude\", \"grid_longitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qplt.pcolormesh(nwarmdays)\n",
    "plt.gca().coastlines()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate percentage of warmest days by using **iris.analysis.maths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndays = max_temp.shape[0]\n",
    "# calculating percentage\n",
    "nwd_pcent = iris.analysis.maths.divide(\n",
    "    iris.analysis.maths.multiply(nwarmdays, 100), ndays\n",
    ")\n",
    "nwd_pcent.units = \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting the percentage of warm days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qplt.pcolormesh(nwd_pcent)\n",
    "plt.title(\"Percentage of warm days\")\n",
    "plt.gca().coastlines()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Task:</b><br><ul>\n",
    "        <li> Calculate and plot the past (1851-1880) and present (1981-2010) 90th percentile of maximum temperature and the difference between them.\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first extract the air_temperature at 1.5m cubes from the cubelist\n",
    "air_temp = cubelist.extract(\n",
    "    \"air_temperature\" & iris.AttributeConstraint(Height=\"1.5 m\")\n",
    ")\n",
    "\n",
    "# constraint for the maximum temperature\n",
    "max_temp_cons = iris.Constraint(\n",
    "    cube_func=lambda c: (len(c.cell_methods) > 0)\n",
    "    and (c.cell_methods[0].method == \"maximum\")\n",
    ")\n",
    "\n",
    "# define time constraint and extract 1851-1900 period (the baseline)\n",
    "start_time = 1851\n",
    "end_time = 1880\n",
    "\n",
    "# define the time constraint\n",
    "time_constraint = iris.Constraint(\n",
    "    time=lambda cell: start_time <= cell.point.year <= end_time\n",
    ")\n",
    "\n",
    "# applying the pressure, maximum temperature and time constraints getting a single cube\n",
    "past_max_temp = air_temp.extract_strict(max_temp_cons & time_constraint)\n",
    "\n",
    "# defining Shangai region coords\n",
    "min_lat = 29.0\n",
    "max_lat = 32.0\n",
    "min_lon = 118.0\n",
    "max_lon = 123.0\n",
    "\n",
    "# extract data for the the Shanghai region using extract_rot_cube() function\n",
    "past_max_temp_shanghai = extract_rot_cube(\n",
    "    past_max_temp, min_lat, min_lon, max_lat, max_lon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the 90 percentile\n",
    "past_max_temp_shanghai_pc90 = past_max_temp_shanghai.collapsed(\n",
    "    \"time\", iris.analysis.PERCENTILE, percent=90.0\n",
    ")\n",
    "past_max_temp_shanghai_pc90.rename(\"Historic R90p of daily maximum temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guessing bounds\n",
    "past_max_temp_shanghai_pc90 = add_bounds(\n",
    "    past_max_temp_shanghai_pc90, [\"grid_latitude\", \"grid_longitude\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the historic data\n",
    "qplt.pcolormesh(past_max_temp_shanghai_pc90)\n",
    "plt.title(\"R90p of daily maximum temperature (1880-1900)\")\n",
    "plt.gca().coastlines()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now extract present day\n",
    "# extract a single cube of maximum air_temperature at 1.5m cube from the cubelist\n",
    "max_temp = cubelist.extract_strict(\n",
    "    \"air_temperature\" & iris.AttributeConstraint(Height=\"1.5 m\") & max_temp_cons\n",
    ")\n",
    "# extract data for the the Shanghai region using extract_rot_cube() function\n",
    "max_temp_shanghai = extract_rot_cube(max_temp, min_lat, min_lon, max_lat, max_lon)\n",
    "\n",
    "start_time = 1981\n",
    "end_time = 2010\n",
    "\n",
    "time_constraint = iris.Constraint(\n",
    "    time=lambda cell: start_time <= cell.point.year <= end_time\n",
    ")\n",
    "recent_max_temp_shanghai = max_temp_shanghai.extract(time_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the 90 percentile\n",
    "recent_max_temp_shanghai_pc90 = recent_max_temp_shanghai.collapsed(\n",
    "    \"time\", iris.analysis.PERCENTILE, percent=90.0\n",
    ")\n",
    "recent_max_temp_shanghai_pc90.rename(\"Recent R90p of daily maximum temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guessing bounds\n",
    "recent_max_temp_shanghai_pc90 = add_bounds(\n",
    "    recent_max_temp_shanghai_pc90, [\"grid_latitude\", \"grid_longitude\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the recent data\n",
    "qplt.pcolormesh(recent_max_temp_shanghai_pc90)\n",
    "plt.title(\"R90p of daily maximum temperature (1981-2010)\")\n",
    "plt.gca().coastlines()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let calculate the difference plot\n",
    "diff_max_temp_shanghai_pc90 = (\n",
    "    recent_max_temp_shanghai_pc90 - past_max_temp_shanghai_pc90\n",
    ")\n",
    "diff_max_temp_shanghai_pc90.rename(\"Difference R90p of daily maximum temperature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guessing bounds\n",
    "past_max_temp_shanghai_pc90 = add_bounds(\n",
    "    past_max_temp_shanghai_pc90, [\"grid_latitude\", \"grid_longitude\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and finally plot the historic, recent and difference plots next to each other\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "fig.suptitle(\n",
    "    \"90th percentile of maximum temperature (1851-1880) vs Recent (1981-2010)\",\n",
    "    fontsize=16,\n",
    ")\n",
    "ax1 = fig.add_subplot(1, 3, 1, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(past_max_temp_shanghai_pc90)\n",
    "ax1.coastlines()\n",
    "ax1 = fig.add_subplot(1, 3, 2, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(recent_max_temp_shanghai_pc90)\n",
    "ax1.coastlines()\n",
    "ax1 = fig.add_subplot(1, 3, 3, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(diff_max_temp_shanghai_pc90)\n",
    "ax1.coastlines()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exercises<a id='exercise'></a>\n",
    "\n",
    "In this exercise we will calculate the percentage of total precipitation from 1981-2010 which falls on very wet days (where a very wet day is one on which daily rainfall exceeds the 95th percentile of the baseline) over Shanghai region.\n",
    "\n",
    "Further we also calculate the percentage of very wet days in the past (1851-1880) and see the difference by plotting the difference of heavy rainfall in the past and present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Calculate what percentage of all of the precipitation in period 1981-2010 fell on days when there was heavy rain i.e. => 95th Percentile.\n",
    "\n",
    "For this task, we need to calculate the percentage of all of the precipitation in this period which fell on days when there was heavy rain i.e. => 95th Percentile.\n",
    "\n",
    "We can break this down as follows:\n",
    "\n",
    "<li>load the daily data for the period 1981-2010 and extract Shanghai</li>\n",
    "<li>find the 95th percentile of daily rainfall on wet days for the period</li>\n",
    "<li>find the sum of the rainfall on days when the precip > 95th percentile</li>\n",
    "<li>find the total rainfall on all days</li>\n",
    "<li>find the percentage of all of the precipitation in this period which fell on days when there was heavy rain</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first extract the air_temperature at 1.5m cubes from the cubelist\n",
    "precip = cubelist.extract_strict(\"precipitation_flux\")\n",
    "# convert units to mm/day (equivalent to 'kg m-2 day-1')\n",
    "precip.convert_units(\"kg m-2 day-1\")\n",
    "# To avoid warnings when collapsing coordinates and also when plotting, add bounds to all coordinates\n",
    "precip = add_bounds(precip, [\"time\", \"grid_latitude\", \"grid_longitude\"])\n",
    "\n",
    "# define time constraint and extract 1851-1900 period (the baseline)\n",
    "start_time = 1981\n",
    "end_time = 2010\n",
    "\n",
    "# define the time constraint\n",
    "time_constraint = iris.Constraint(\n",
    "    time=lambda cell: start_time <= cell.point.year <= end_time\n",
    ")\n",
    "\n",
    "# applying the pressure, maximum temperature and time constraints getting a single cube\n",
    "present_precip = precip.extract(time_constraint)\n",
    "\n",
    "# defining Shangai region coords\n",
    "min_lat = 29.0\n",
    "max_lat = 32.0\n",
    "min_lon = 118.0\n",
    "max_lon = 123.0\n",
    "\n",
    "# extract data for the the Shanghai region using extract_rot_cube() function\n",
    "present_precip_shanghai = extract_rot_cube(\n",
    "    present_precip, min_lat, min_lon, max_lat, max_lon\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the cube, mask where daily rainfall < 1 so that only wet days\n",
    "# are included in the calculation of the 95th percentile\n",
    "present_precip_shanghai_wet = present_precip_shanghai.copy()\n",
    "present_precip_shanghai_wet.data = np.ma.masked_less(\n",
    "    present_precip_shanghai_wet.data, 1.0\n",
    ")\n",
    "\n",
    "# Calculating percentile\n",
    "present_precip_shanghai_pc95 = present_precip_shanghai_wet.collapsed(\n",
    "    \"time\", iris.analysis.PERCENTILE, percent=95.0\n",
    ")\n",
    "present_precip_shanghai_pc95.rename(\"Present R95p of daily precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of days of the rainfall on days when the precip > 95th percentile\n",
    "# mask the present_precip_shanghai using 95th percentile (very wet days)\n",
    "masked_cube = present_precip_shanghai.copy()\n",
    "masked_cube.data = np.ma.masked_less(\n",
    "    present_precip_shanghai.data, present_precip_shanghai_pc95.data\n",
    ")\n",
    "\n",
    "# Now calculating the total sum to extreme rainfall\n",
    "total_extreme_precipitation = masked_cube.collapsed([\"time\"], iris.analysis.SUM)\n",
    "\n",
    "# also the sum on all days\n",
    "total_precip = present_precip_shanghai.collapsed([\"time\"], iris.analysis.SUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of rainfall on very high rainfall days\n",
    "extreme_present_pct = (total_extreme_precipitation / total_precip) * 100.0\n",
    "extreme_present_pct.rename(\"Fraction of precipitation from very heavy rain\")\n",
    "extreme_present_pct.units = \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally check the result by doing a plot\n",
    "extreme_present_pct = add_bounds(\n",
    "    extreme_present_pct, [\"grid_latitude\", \"grid_longitude\"]\n",
    ")\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.suptitle(\"Heavy rainfall\", fontsize=16)\n",
    "qplt.pcolormesh(extreme_present_pct)\n",
    "plt.gca().coastlines()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Calculate what percentage of all of the precipitation in period 1851-1880 fell on days when there was heavy rain i.e. => 95th Percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first extract the air_temperature at 1.5m cubes from the cubelist\n",
    "precip = cubelist.extract_strict(\"precipitation_flux\")\n",
    "# convert units to mm/day (equivalent to 'kg m-2 day-1')\n",
    "precip.convert_units(\"kg m-2 day-1\")\n",
    "# To avoid warnings when collapsing coordinates and also when plotting, add bounds to all coordinates\n",
    "precip = add_bounds(precip, [\"time\", \"grid_latitude\", \"grid_longitude\"])\n",
    "\n",
    "# define time constraint and extract 1851-1900 period (the baseline)\n",
    "start_time = 1851\n",
    "end_time = 1880\n",
    "\n",
    "# define the time constraint\n",
    "time_constraint = iris.Constraint(\n",
    "    time=lambda cell: start_time <= cell.point.year <= end_time\n",
    ")\n",
    "\n",
    "# applying the pressure, maximum temperature and time constraints getting a single cube\n",
    "past_precip = precip.extract(time_constraint)\n",
    "\n",
    "# extract data for the the Shanghai region using extract_rot_cube() function\n",
    "past_precip_shanghai = extract_rot_cube(past_precip, min_lat, min_lon, max_lat, max_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_precip_shanghai_wet = past_precip_shanghai.copy()\n",
    "past_precip_shanghai_wet.data = np.ma.masked_less(past_precip_shanghai_wet.data, 1.0)\n",
    "\n",
    "# Calculating percentile\n",
    "past_precip_shanghai_pc95 = past_precip_shanghai_wet.collapsed(\n",
    "    \"time\", iris.analysis.PERCENTILE, percent=95.0\n",
    ")\n",
    "past_precip_shanghai_pc95.rename(\"Past R95p of daily precipitation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of days of the rainfall on days when the precip > 95th percentile\n",
    "masked_cube = past_precip_shanghai.copy()\n",
    "masked_cube.data = np.ma.masked_less(\n",
    "    past_precip_shanghai.data, past_precip_shanghai_pc95.data\n",
    ")\n",
    "\n",
    "# Now calculating the total sum to extreme rainfall\n",
    "total_extreme_precip_past = masked_cube.collapsed([\"time\"], iris.analysis.SUM)\n",
    "\n",
    "# also the sum on all days\n",
    "total_precip_past = past_precip_shanghai.collapsed([\"time\"], iris.analysis.SUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of rainfall on very high rainfall days\n",
    "extreme_past_pct = (total_extreme_precip_past / total_precip_past) * 100.0\n",
    "extreme_past_pct.rename(\"Fraction of precipitation from very heavy rain\")\n",
    "extreme_past_pct.units = \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Calculate the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the difference in rain on extreme wet days\n",
    "\n",
    "extreme_pct_difference = extreme_present_pct - extreme_past_pct\n",
    "extreme_pct_difference.rename(\"Difference in % of rain from extreme events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Plot the percentages and difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and finally plot the historic, recent and percentile difference plots next to each other\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "fig.suptitle(\n",
    "    \"95th percentile of precipitation (1851-1880) vs present (1981-2010)\", fontsize=16\n",
    ")\n",
    "ax1 = fig.add_subplot(1, 3, 1, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(extreme_past_pct)\n",
    "ax1.coastlines()\n",
    "ax1 = fig.add_subplot(1, 3, 2, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(extreme_present_pct)\n",
    "ax1.coastlines()\n",
    "ax1 = fig.add_subplot(1, 3, 3, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(extreme_pct_difference)\n",
    "ax1.coastlines()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Summary</b><br> \n",
    "    In this session we learned how:<br>\n",
    "    <ul>\n",
    "        <li>to calculate extreme values and percentages\n",
    "        <li>to calcuate basic extreme value indices  \n",
    "    </ul>\n",
    "\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cssp37",
   "language": "python",
   "name": "cssp37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

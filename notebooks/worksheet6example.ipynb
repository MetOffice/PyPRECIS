{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 6 example code\n",
    "\n",
    "## Example 1 Frequency of warm days (TX90P) in the future\n",
    "\n",
    "Calculate the baseline (1986-2005) 90th percentile of maximum temperature. Then calculate the frequency of warm days in the future (2041-2060) (extreme index TX90P). Do this for HadGEM2-ES and MPI-ESM-LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code preamble - these libraries will be used in this worksheet.\n",
    "# This code block needs to be re-run every time you restart this worksheet!\n",
    "%matplotlib inline \n",
    "import os\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "import iris.quickplot as qplt\n",
    "import iris.plot as iplt\n",
    "from iris.experimental.equalise_cubes import equalise_attributes\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from iris.analysis import Aggregator\n",
    "\n",
    "# Some helpful data locations\n",
    "DATADIR = 'data_v2'\n",
    "CHIRPSDIR = os.path.join(DATADIR, 'CHIRPS')\n",
    "CRUDIR = os.path.join(DATADIR, 'CRU')\n",
    "CLIMDIR = os.path.join(DATADIR, 'EAS-22', 'climatology/')\n",
    "MODELDIR = os.path.join(DATADIR, 'EAS-22/')\n",
    "GCMIDS = ['hadgem2-es', 'mpi-esm-lr']\n",
    "GCM_FULL = {'hadgem2-es':'MOHC-HadGEM2-ES' , 'mpi-esm-lr':'MPI-M-MPI-ESM-LR'}\n",
    "TIME_PERIODS = {'historical':'1986_2005', 'rcp85':'2041_2060'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First calculate the 90th percentile of tsmax in the baseline and future periods for both set of downscaled GCMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasmax_EAS-22_MOHC-HadGEM2-ES_historical_*GERICS-REMO2015*_*_day_*.nc\n"
     ]
    }
   ],
   "source": [
    "ndays = {}\n",
    "for gcmid in GCMIDS:\n",
    "    for period in TIME_PERIODS.keys():\n",
    "        filename = f'tasmax_EAS-22_{GCM_FULL[gcmid]}_{period}_*GERICS-REMO2015*_*_day_*.nc'\n",
    "        print(filename)\n",
    "        model_tasmax = iris.load(MODELDIR + filename)\n",
    "        # solve merge issues\n",
    "        equalise_attributes(model_tasmax)\n",
    "        model_tasmax = model_tasmax.concatenate_cube()\n",
    "\n",
    "        # store the number of days for this GCM in a dictionary\n",
    "        ndays[gcmid] = len(model_tasmax.coord('time').points)\n",
    "\n",
    "        # 90th percentile calculation\n",
    "        model_pc90 = model_tasmax.collapsed('time', iris.analysis.PERCENTILE, percent=90.0)\n",
    "        outfile = os.path.join(CLIMDIR, gcmid + '.day.' + TIME_PERIODS[period] + '.GERICS-REMO2015.tasmax.90pc.nc')\n",
    "        print(f'saving to file: {outfile}')\n",
    "        iris.save(model_pc90, outfile)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the frequency of warm days in the future (extreme index TX90P), i.e. the number of days which exceed the 90th percentile temperatures in the baseline.  Then calculate the numbers of days as a percentage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to extract our cube chunks\n",
    "def chunks(cube, x=100, y=100):\n",
    "    \"\"\"\n",
    "    Yield successive x-y sized chunks from cube,\n",
    "    works for 3D Time-Lat-Lon\n",
    "    \n",
    "    Args:\n",
    "    cube (Iris cube): input cube to be chunked\n",
    "    x: size of chunks in x direction\n",
    "    y: size of chunk in y direction\n",
    "    \"\"\"\n",
    "    coord_names = [coord.name() for coord in cube.coords()]\n",
    "    if 'grid_latitude' in coord_names and 'latitude' in coord_names:\n",
    "        cube.remove_coord('latitude')\n",
    "    if 'grid_longitude' in coord_names and 'longitude' in coord_names:\n",
    "        cube.remove_coord('longitude')\n",
    "    \n",
    "    for i in range(0, cube.coord(axis='x').shape[0], x):\n",
    "        for j in range(0, cube.coord(axis='y').shape[0], y):\n",
    "            yield cube[:, j:j + y, i:i + x]\n",
    "\n",
    "    \n",
    "def chunks_2d(cube, x=100, y=100):\n",
    "    coord_names = [coord.name() for coord in cube.coords()]\n",
    "    if 'grid_latitude' in coord_names and 'latitude' in coord_names:\n",
    "        cube.remove_coord('latitude')\n",
    "    if 'grid_longitude' in coord_names and 'longitude' in coord_names:\n",
    "        cube.remove_coord('longitude')\n",
    "    \n",
    "    for i in range(0, cube.coord(axis='x').shape[0], x):\n",
    "        for j in range(0, cube.coord(axis='y').shape[0], y):\n",
    "            yield cube[j:j + y, i:i + x]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving numbers of warm days in the future from hadgem2-es\n",
      "Saving numbers of warm days in the future from mpi-esm-lr\n"
     ]
    }
   ],
   "source": [
    "for gcmid in GCMIDS:\n",
    "    \n",
    "    # load data for future \n",
    "    filename = f'tasmax_EAS-22_{GCM_FULL[gcmid]}_rcp85_*GERICS-REMO2015*_*_day_*.nc'\n",
    "    future_tasmax = iris.load(MODELDIR + filename)\n",
    "\n",
    "    # solve merge issues\n",
    "    equalise_attributes(future_tasmax)\n",
    "    future_tasmax = future_tasmax.concatenate_cube()  \n",
    "    ndays = len(future_tasmax.coord('time').points)\n",
    "    \n",
    "    # and 90th percentile in historical period\n",
    "    infile = os.path.join(CLIMDIR, gcmid +  '.day.' + TIME_PERIODS['historical'] + '.GERICS-REMO2015.tasmax.90pc.nc')\n",
    "    hist_90pc = iris.load_cube(infile)\n",
    "    \n",
    "    nwarmdays_future = iris.cube.CubeList()\n",
    "    \n",
    "    \n",
    "    # need to do next operation chunking data, also chunk 90th percentile \n",
    "    for chunk_ft_tasmax, chunk_hist_90pc in zip(chunks(future_tasmax), chunks_2d(hist_90pc)):\n",
    "\n",
    "        # Use np.where to identify all cells where daily temperatures \n",
    "        # in the future exceed the 90th percentile\n",
    "        temp_gt_chunk = np.where(chunk_ft_tasmax.data >= chunk_hist_90pc.data, 1, 0)\n",
    "              \n",
    "        # use the 90th percentile cube as a template to copy warm days data into \n",
    "        nwarmdays_future_chunk = chunk_hist_90pc.copy()\n",
    "        nwarmdays_future_chunk.data = np.ma.sum(temp_gt_chunk.data, axis=0)\n",
    "        nwarmdays_future.append(nwarmdays_future_chunk)\n",
    "\n",
    "        \n",
    "    nwarmdays_future = nwarmdays_future.concatenate_cube()\n",
    "\n",
    "    # the sum above removes the mask - reinstate it with \n",
    "    nwarmdays_future.data.mask = hist_90pc.data.mask\n",
    "    nwarmdays_future.units = '1'\n",
    "    nwarmdays_future.rename('days > 90th %ile of baseline ')\n",
    "      \n",
    "    print (\"Saving numbers of warm days in the future from \" + gcmid)\n",
    "    outfile = os.path.join(CLIMDIR, gcmid +  '.day.' + TIME_PERIODS['historical'] + '.GERICS-REMO2015.tasmax.nwarmdays.nc')\n",
    "    #iris.save(nwarmdays_future, path_clim + job + 'a.TX90P.nc')\n",
    "    \n",
    "    # calculate percentage of days (see below)\n",
    "    nwarm_pc = nwarmdays_future/ndays*100.\n",
    "    nwarm_pc.units = '%'\n",
    "    nwarm_pc.rename('percentage of days T > 90th %ile of baseline ')\n",
    "    \n",
    "    # save percentage\n",
    "    outfile = os.path.join(CLIMDIR, gcmid +  '.day.' + TIME_PERIODS['historical'] + '.GERICS-REMO2015.tasmax.nwarmpc.nc')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the numbers of warm days in the future and the percentage of warm days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, job in enumerate(runids):\n",
    "    nwarmdays = iris.load_cube(path_clim + job + 'a.TX90P.nc')\n",
    "    nwd_pcent = iris.analysis.maths.divide(iris.analysis.maths.multiply(nwarmdays, 100), ndays[i])\n",
    "    iris.save(nwd_pcent, job + 'a.TX90P.per.nc')\n",
    "\n",
    "    plotnum = 1 + 2*i\n",
    "    plt.subplot(2, 2, plotnum)\n",
    "    qplt.pcolormesh(nwarmdays, vmin=0, vmax=10000)\n",
    "    plt.title(job + ': Number of warm days')\n",
    "    plt.subplot(2, 2, plotnum+1)\n",
    "    qplt.pcolormesh(nwd_pcent, vmin=0, vmax=100)\n",
    "    plt.title(job + ': Percentage of warm days')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2. Percentage of total precipitation which falls on very wet days\n",
    "\n",
    "Calculate the percentage of total precipitation which falls on very wet days in the future over Thailand\n",
    "(where a very wet day is one on which daily rainfall exceeds the 95th percentile of the baseline).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates of a box around Thailand\n",
    "malay_lons = np.array([98.0, 98.0, 105.0, 105.0])\n",
    "malay_lats = np.array([10.0, 21.0,  10.0,  21.0])\n",
    "\n",
    "# Load a cube on the rotated grid\n",
    "infile = os.path.join(CLIMDIR, gcmid +  '.day.' + TIME_PERIODS['historical'] + '.GERICS-REMO2015.tasmax.90pc.nc')\n",
    "hist_90pc = iris.load_cube(infile)\n",
    "\n",
    "rotg = iris.load_cube(path_clim + 'cahpaa.wetday.pcent.baseline.nc')\n",
    "rcs = rotg.coord('grid_latitude').coord_system\n",
    "\n",
    "# Get the rotated pole coordinates\n",
    "pole_lat = rcs.grid_north_pole_latitude\n",
    "pole_lon = rcs.grid_north_pole_longitude\n",
    "\n",
    "# Convert the coordinates of a box around Malaysia from real coordinates to rotated polar coordinates\n",
    "grid_lons, grid_lats = iris.analysis.cartography.rotate_pole(malay_lons, malay_lats, pole_lon, pole_lat)\n",
    "\n",
    "# Find the max / min of the lons / lats on the rotated grid.  They will be used to extract the data around Malaysia\n",
    "# N.B. The conversion to float is needed, as numpy data are of type float64 by default. If the coordinate limits\n",
    "# are passed as float64, they are interpreted as a list of two floats and the program will stop with an error:\n",
    "# ValueError: setting an array element with a sequence.\n",
    "lon_0 = float(min(grid_lons))\n",
    "lon_1 = float(max(grid_lons))\n",
    "lat_0 = float(min(grid_lats))\n",
    "lat_1 = float(max(grid_lats))\n",
    "\n",
    "# Set up constraints on the rotated grid for Malaysia\n",
    "lon_con = iris.Constraint(grid_longitude = lambda x: lon_0 <= x <= lon_1)\n",
    "lat_con = iris.Constraint(grid_latitude = lambda cell: lat_0 <= cell <= lat_1)\n",
    "\n",
    "for i, job in enumerate(runids):\n",
    "    data_path = 'daily/' + job + '/05216/'\n",
    "    file_f = job + 'a.pa.2150.05216.rr8.mmday.nc'\n",
    "#   precip = iris.load_cube(data_path + file_f, lon_con).intersection(grid_latitude = (-14.767, -5,623))\n",
    "    precip = iris.load_cube(data_path + file_f, lat_con & lon_con)\n",
    "    precip_pc95 = iris.load_cube(path_clim + 'cahpaa.pc95.05216.future.mmday.nc', lat_con & lon_con)\n",
    "    \n",
    "# Use broadcasting to identify all cells in precip where p95 is exceeded\n",
    "    pre_gt_pc95 = np.where(precip.data > precip_pc95.data, precip.data, 0.0)\n",
    "    pre_p95 = np.sum(pre_gt_pc95, axis=0)\n",
    "    pre_tot = precip.collapsed('time', iris.analysis.SUM)\n",
    "    pre_tot.data = np.divide(pre_p95, pre_tot.data, out=np.zeros_like(pre_tot.data), where = pre_tot.data != 0)\n",
    "    pre_tot = iris.analysis.maths.multiply(pre_tot, 100)\n",
    "    file_out = job + 'a.R95pTOT.future.nc'\n",
    "    iris.save(pre_tot, path_clim + file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the percentages of heavy rainfall in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runids = ['cahpa', 'cahpb']\n",
    "path_clim = 'daily/climatology/'\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, job in enumerate(runids):\n",
    "    filename = job + 'a.R95pTOT.future.nc'\n",
    "    pcent_heavy_rain = iris.load_cube(path_clim + filename)\n",
    "    plotnum = 1 + i\n",
    "    plt.subplot(2, 1, plotnum)\n",
    "    qplt.pcolormesh(pcent_heavy_rain, vmin=0, vmax=100)\n",
    "    plt.title(job + ': Percentage of heavy rain over Malaysia in the future')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

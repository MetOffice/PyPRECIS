{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 2: Using the Python Iris library for analysis and visualisation\n",
    "\n",
    "In this worksheet, sample CORDEX output over Southeast Asia is compared with observations for validation purposes. Validating model results by comparing with observed data is an essential step - this is the measure by which we can assess the quality of the model and it informs appropriate uses of the data.\n",
    "\n",
    "\n",
    "Here, we validate CORDEX output driven by two different GCMs (HadGEM2-ES and MPI-ESM-LR) created with the REMO2015 Regional Climate Model. Using data from both experiments will give us two representations of present day climate and two possible climate scenarios. For more details on multimodel approaches, refer to the workshop lecture on climate model ensembles.\n",
    "\n",
    "The following exercises provide examples of how analysis can be undertaken as part of a model validation. The methods shown are not necessarily the only way to proceed and are intended to demonstrate the use of Iris in model validation, and provide a starting point for your own analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>By the end of this worksheet you should be able to:</b><br> \n",
    "- Apply basic statistical operations to Iris cubes. <br>\n",
    "- Plot information from Iris cubes.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "### [2.1: Inspecting the data](#2.1) \n",
    "### [2.2: Converting units](#2.2)\n",
    "### [2.3: Climatological mean calculation](#2.3)\n",
    "### [2.4: IRIS quick plotting and visualising data](#2.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble\n",
    "Run the code preamble below to import the necessary libraries for this worksheet.\n",
    "\n",
    "To run the code, click in the box below and press <kbd>Ctrl</kbd> + <kbd>Enter</kbd>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code preamble - these libraries will be used in this worksheet.\n",
    "# This code block needs to be re-run every time you restart this worksheet!\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.dates as mdates\n",
    "import calendar\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "import iris.quickplot as qplt\n",
    "from iris.experimental.equalise_cubes import equalise_attributes\n",
    "from iris.time import PartialDateTime\n",
    "import cartopy.crs as ccrs\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from utils import copy_s3_files, flush_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "# 2.1 Inspecting the data\n",
    "\n",
    "The datasets used here contain daily and monthly data from two REMO2015 runs carried out over Southeast Asia, one driven by HadGEM2-ES and the other driven by MPI-ESM-LR. The observations used for comparison are from the CHIRPS gridded observational data set (https://chc.ucsb.edu/data/chirps).\n",
    "\n",
    "Remember, in Iris, data are read into an object called a **cube**. A single cube describes only one variable; it is not possible for a cube to contain both temperature and rainfall, for example. A cube always has a name, a unit and an n-dimensional data array to represent the cube’s data. Additionally, the cube contains collections of coordinates.  Coordinate types can include spatial information (latitude, longitude, altitude), a time dimension, or other information, e.g., an ensemble number.\n",
    "\n",
    "<p><img src=\"img/multi_array_to_cube.png\" alt=\"Example Iris cube\" style=\"float: center; height: 300px;\"/></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__a) Load the NetCDF file for the HadGEM2-ES and MPI-ESM-LR model data and the CHIRPS rainfall observation data and print the cube output__\n",
    "\n",
    "A cube has coordinates (e.g. time, longitude, latitude, model levels) which can be accessed with Python commands. In the following exercise we find the latitude and longitude covered by the CHIRPS data. This can be done either by printing the latitude and longitude coordinates (`.points`), noting the first and last values in the array, or in the case of the CHIRPS data, printing the cube and looking through the attributes. A similar example can be found in the [Iris documentation](https://scitools.org.uk/iris/docs/v2.4.0/userguide/navigating_a_cube.html#accessing-coordinates-on-the-cube). \n",
    "\n",
    "Before running the code, take a look at it line-by-line to understand what steps are being taken. Then click in the box and press <kbd>ctrl</kbd> + <kbd>enter</kbd> to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first need to download APHRODITE data\n",
    "copy_s3_files('s3://ias-pyprecis/data/APHRODITE/*.nc', 'data/APHRODITE/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the names of the directories where the netCDF model files are stored\n",
    "DATADIR = 'data_v2/'\n",
    "\n",
    "# Load and concatenate the HadGEM2-ES model cube data\n",
    "infile = os.path.join(DATADIR, 'EAS-22/pr_EAS-22_MOHC-HadGEM2-ES_historical_r1i1p1_GERICS-REMO2015_v1_mon_*.nc')\n",
    "cubes = iris.load(infile)\n",
    "equalise_attributes(cubes)\n",
    "hadgem2 = cubes.concatenate_cube()\n",
    "\n",
    "# Load and concatenate the MPI-ESM-LR model cube data\n",
    "infile = os.path.join(DATADIR, 'EAS-22/pr_EAS-22_MPI-M-MPI-ESM-LR_historical_r1i1p1_GERICS-REMO2015_v1_mon_*.nc')\n",
    "cubes = iris.load(infile)\n",
    "equalise_attributes(cubes)\n",
    "mpiesm = cubes.concatenate_cube()\n",
    "\n",
    "# finally load the CHIRPS data and print the cube \n",
    "infile = os.path.join(DATADIR, 'CHIRPS', 'chirps-v2.0.monthly.global.1981_2018.nc')\n",
    "chirpsData = iris.load_cube(infile)\n",
    "print(chirpsData)\n",
    "\n",
    "# print the first and last latitude points\n",
    "print(chirpsData.coord('latitude').points[0], chirpsData.coord('latitude').points[-1])\n",
    "# print the first and last longitude points\n",
    "print(chirpsData.coord('longitude').points[0], chirpsData.coord('longitude').points[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question:</b> How many years of data does the CHIRPS dataset contain? What longitudes and latitudes are covered by the CHIRPS data?\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer:</b>*(Double click here to fill in the answers)*<br>\n",
    "\n",
    "Number of years:\n",
    "\n",
    "Latitude and longitude covered: \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b) Extract a subset of the data within a cube__\n",
    "\n",
    "Data extraction is an important function in Iris. The extraction of a subset of data is called **slicing**.  For example, it could be necessary to extract data over all latitude and longitude grid points on the first time step. For more information around subsetting cubes please read the [Iris documentation on slicing](https://scitools.org.uk/iris/docs/v2.4.0/userguide/subsetting_a_cube.html#cube-indexing).\n",
    "\n",
    "__Using the HadGEM2-ES data, the example below shows how to subset a cube for the first and last timesteps. This method will be used later for plotting data from a cube.__ \n",
    "\n",
    "Work through the example below line by line then click in the box and press <kbd>Ctrl</kbd> + <kbd>Enter</kbd> to run the code.\n",
    "\n",
    "First, print the HadGEM2-ES cube, containing all the time steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the print() command to display a summary of the HadGEM2-ES cube\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question:</b> What dimensions does this cube have? <br>\n",
    "    t = number of timesteps <br>\n",
    "    y = number of latitude steps <br>\n",
    "    x = number of longitude steps <br>\n",
    "    Write your answer in the form `[ t, y, x ]`\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer:</b> *(Double click here to fill in the answers)*<br> \n",
    "HadGEM2-ES dimensions: [ t, y, x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> When indexing a cube dimension, you either can specify a single coordinate, e.g. <code>0</code> is the first (zeroth) item, <code>-1</code> is the last item, or you can use <b><code>:</code></b> to include <b>all items</b>.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the cube's **first** timestep and check the associated `time` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the print() funiction with slicing notation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the cube's **last** timestep and check the associated `time` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the print() function with slicing notation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the analysis here, we will use data from 1986 to 2005 inclusive as used in the AR5 WG1 atlas. To do this we will use the same approach as in Worksheet 1 by using time constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_constraint = iris.Constraint(time=lambda cell: PartialDateTime(year=1986) \n",
    "                            <= cell.point <= PartialDateTime(year=2005))\n",
    "hadgem2 = hadgem2.extract(time_constraint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the same time constraint to the mpiesm data to restrict to the same period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpiesm = mpiesm.extract(time_constraint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2'></a>\n",
    "## 2.2 Converting units\n",
    "\n",
    "__c) Convert the precipitation units from kg/m2/s (equivalent to mm/s) to mm/day__\n",
    "\n",
    "To convert to mm/day, we could just multiply the raw data (in mm/s) by 86400 seconds, but a clearer way is to use the __`.convert_units()`__ method with the name of the units we want to convert the data into.\n",
    "\n",
    "Let's do this for the __HadGEM2-ES__ historical data first and break down the steps as follows:\n",
    "\n",
    "* Print the units and summary statistic about the data\n",
    "* Convert the unit and print the information again\n",
    "* Rename the `.units` value in the cube and save it as a new netCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hadgem2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the unit\n",
    "print('The current unit for data is: ' + hadgem2.units)\n",
    "# print the summary statistic (maximum monthly precipitation)\n",
    "maxpr = np.max(hadgem2.data)\n",
    "print('This is an example rainfall rate (kg m-2 s-1) prior to conversion: ' + maxpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert units to kg m-2 day-1 (same as multiplying by 86400 seconds)\n",
    "hadgem2.convert_units('kg m-2 day-1')\n",
    "# Print cube.units to view new units for precipitation\n",
    "print('The new rainfall units are: ' + hadgem2.units)\n",
    "maxpr = np.max(hadgem2.data)\n",
    "# print the summary statistic (maximum monthly precipitation) after the unit conversion\n",
    "print('This is the same rainfall rate but now in (kg m-2 day-1): ' + maxpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the new cube units for consistency, then save the converted cube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename cube units\n",
    "hadgem2.units = 'mm day-1'\n",
    "\n",
    "# Save the new cube as a new netCDF file\n",
    "HISTDIR = 'data_v2/EAS-22/historical'\n",
    "\n",
    "# Check to see if this directory exists, if not create it\n",
    "if not os.path.isdir(HISTDIR):\n",
    "    # Make directory\n",
    "    os.mkdir(HISTDIR)\n",
    "    # Set directory permissions \n",
    "    os.chmod(HISTDIR, 0o776)\n",
    "\n",
    "outfile = os.path.join(HISTDIR, 'hadgem2-es.mon.1986_2005.GERICS-REMO2015.pr.mmday-1.nc')\n",
    "iris.save(hadgem2, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following code block to repeat the same procedure for MPI-ESM-LR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the current MPI-ESM-LR cube units\n",
    "\n",
    "\n",
    "# convert units to kg m-2 day-1\n",
    "\n",
    "\n",
    "# Rename the units to mm day-1. Recall that 1 kg m-2 is equivalent to 1 mm of rain\n",
    "\n",
    "\n",
    "# Save the new cube as a new netCDF file using the `outfile` filename we've provided below!\n",
    "outfile = os.path.join(HISTDIR, 'mpi-esm-lr.mon.1986_2005.GERICS-REMO2015.pr.mmday-1.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3'></a>\n",
    "## 2.3 Climatological seasonal mean calculation\n",
    "\n",
    "__d) Calculate the 1986-2005 seasonal mean precipitation__ field for October-December (OND) from both the HadGEM2-ES and MPI-ESM-LR driven runs.\n",
    "\n",
    "Work through the example below line by line then click in the box and press <kbd>ctrl</kbd> + <kbd>enter</kbd> to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directory for the climatology\n",
    "CLIMDIR = 'data_v2/EAS-22/climatology'\n",
    "\n",
    "# Check to see if this directory exists, if not create it\n",
    "if not os.path.isdir(CLIMDIR):\n",
    "    # Make directory\n",
    "    os.mkdir(CLIMDIR)\n",
    "    # Set directory permissions \n",
    "    os.chmod(CLIMDIR, 0o776)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Loop through two model runs\n",
    "for gcmid in ['hadgem2-es', 'mpi-esm-lr']:\n",
    "    infile = os.path.join(HISTDIR, gcmid + '.mon.1986_2005.GERICS-REMO2015.pr.mmday-1.nc')\n",
    "\n",
    "    # Load the data\n",
    "    data = iris.load_cube(infile)\n",
    "\n",
    "    # In order to calculate OND mean, we use the command below to add a season membership coordinate.\n",
    "    # The seasons can be any sequence of months, identified by the first letters of the names of the months.\n",
    "    # Here, we define two seasons, jfmamjjas (the months we are not interested in) and ond (October, November and\n",
    "    # December); the months we do want.\n",
    "    iris.coord_categorisation.add_season(data, 'time', name='seasons', seasons=('jfmamjjas','ond'))\n",
    "\n",
    "    # This command extracts data for the OND season using a constraint\n",
    "    data_ond = data.extract(iris.Constraint(seasons='ond'))\n",
    "\n",
    "    # The cube 'data_ond' contains data from October-December for all years. \n",
    "    # The command below calculates the mean over all years.\n",
    "    seasonal_mean = data_ond.collapsed('time', iris.analysis.MEAN)\n",
    "    \n",
    "    # Save the OND seasonal mean as a netCDF\n",
    "    outfile = os.path.join(CLIMDIR, gcmid + '.OND.mean.1986_2005.pr.mmday-1.nc')\n",
    "    iris.save(seasonal_mean, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question:</b> What dimensions does this cube have now? <br>\n",
    "    t = number of timesteps <br>\n",
    "    y = number of latitude steps <br>\n",
    "    x = number of longitude steps <br>\n",
    "    Write your answer in the form `[ t, y, x ]` <br>\n",
    "    Compare your answer to the answer you found in <strong> (b)</strong>. Which dimensions have changed?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer:</b> *(Double click here to fill in the answers)*<br>\n",
    "Seasonal mean dimensions: [ t, y, x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__e) Calculate the 1986-2005 seasonal mean for OND from the CHIRPS observation data__\n",
    "\n",
    "CHIRPS is a daily high resolution (0.05 degree) data set for 1981 to almost the present day. See https://chc.ucsb.edu/data/chirps for more information.\n",
    "\n",
    "Follow step d) and complete the code yourself.  The file name to load is: `chirps-v2.0.monthly.global.1981_2018.nc`. We've given you the infile and outfile names to make sure you load and save it in the right place for later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we first need to download APHRODITE data\n",
    "copy_s3_files('s3://ias-pyprecis/data/climatology/*.nc', 'data/climatology/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory names where data is read from and stored to\n",
    "infile = os.path.join(DATADIR, 'CHIRPS', 'chirps-v2.0.monthly.global.1981_2018.nc')\n",
    "\n",
    "# Load the CHIRPS data, only for the period 1986-2005 \n",
    "chirps = iris.load_cube(infile, constraint=time_constraint)\n",
    "\n",
    "# convert the units to mm day^-1 \n",
    "chirps.convert_units('mm day-1')\n",
    "\n",
    "# In order to calculate OND mean, we need to a add season membership coordinate\n",
    "iris.coord_categorisation.add_season(chirps, 'time', name='seasons', seasons=('jfmamjjas','ond'))\n",
    "\n",
    "# Then constrain the cube just for the OND season\n",
    "chirps_ond = chirps.extract(iris.Constraint(seasons='ond'))\n",
    "\n",
    "# Now calculate the climatological mean for this season\n",
    "seasonal_mean = chirps_ond.collapsed('time', iris.analysis.MEAN)\n",
    "\n",
    "# save the seasonal mean cube as a NetCDF file\n",
    "outfile = os.path.join(CLIMDIR, 'chirps.OND.mean.1986_2005.pr.mmday-1.nc')\n",
    "iris.save(seasonal_mean, outfile)\n",
    "\n",
    "# print the CHIRPS seasonal mean cube\n",
    "print(seasonal_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question:</b> How would you calculate the standard deviation of mean rainfall?  How about annual maximum rainfall?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer:</b> Write the line of code required to calculate CHIRPS's (a) standard deviation and (b) annual maximum rainfall in the code block below. <br>\n",
    "<b>Hint</b>: How could you adapt <code>chirps_ond.aggregated_by(['seasons'], iris.analysis.MEAN)</code> from above? You can refer to the [Iris documentation](https://scitools.org.uk/iris/docs/v2.4.0/iris/iris/analysis.html) if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From chirps, calculate: \n",
    "# (a) chirps_std \n",
    "\n",
    "\n",
    "# (b) chirps_max\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4'></a>\n",
    "## 2.4 IRIS quick plotting and visualising data\n",
    "\n",
    "Now we will plot the output to take a first look at what climatological winter precipitation (1986-2005 OND seasonal mean) looks like for each dataset. This section provides an initial introduction to visualising data quickly using iris, for further reading and instructions please visit: https://scitools.org.uk/iris/docs/v2.4.0/userguide/plotting_a_cube.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f) Plot and compare** the climatological winter preciptation over South East Asia for three datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question:</b> Work through the code block below line by line. Think about what you expect the plot setup to look like: <br> \n",
    "\n",
    "* Which lines of code specify the layout of sub-plots?<br>\n",
    "* Will the plots have a common colour scale or separate ones?<br>\n",
    "* What are the maximum and minimum precipitation values that will be displayed? <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about your answers, then click in the box and press <kbd>ctrl</kbd> + <kbd>enter</kbd> to run the code and create the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hadgem2-es model data\n",
    "infile = os.path.join(CLIMDIR, 'hadgem2-es.OND.mean.1986_2005.pr.mmday-1.nc')\n",
    "hadgem_cube = iris.load_cube(infile)\n",
    "\n",
    "# load mpi-esm model data\n",
    "infile = os.path.join(CLIMDIR, 'mpi-esm-lr.OND.mean.1986_2005.pr.mmday-1.nc')\n",
    "mpi_cube = iris.load_cube(infile)\n",
    "\n",
    "# load CHIRPS data\n",
    "infile = os.path.join(CLIMDIR, 'chirps.OND.mean.1986_2005.pr.mmday-1.nc')\n",
    "obs_cube   = iris.load_cube(infile)\n",
    "\n",
    "# Do some plotting!\n",
    "# Create a figure of the size 12x10 inches\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(1, 3, 1)           # Create a new subplot for the model data; 1 row x 3 columns, 1st plot\n",
    "levels = range(0, 22, 2)       # Define the contour levels for all plots\n",
    "\n",
    "# Note this is where cube slicing is needed as you can only plot 2-coordinate\n",
    "# dimensions with qplt.contourf, so here we have selected time[0] as there is only\n",
    "# one timestep (the baseline 1986-2005 mean)\n",
    "qplt.contourf(hadgem_cube, levels=levels, cmap=cm.RdBu, extend='max')\n",
    "                               \n",
    "\n",
    "plt.title('HadGEM2-ES model')  # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "\n",
    "plt.subplot(1, 3, 2)           # Create a new subplot for the model data; 1 row x 3 columns, 2nd plot\n",
    "qplt.contourf(mpi_cube, levels=levels, cmap=cm.RdBu, extend='max')\n",
    "\n",
    "plt.title('MPI-ESM-LR model')  # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "\n",
    "plt.subplot(1, 3, 3)           # Create a new subplot for the observed data 1 row x 3 columns, 3rd plot\n",
    "                               # This plot will be centred and below the two model plots\n",
    "qplt.contourf(obs_cube, levels=levels, cmap=cm.RdBu, extend='max')\n",
    "\n",
    "plt.title('CHIRPS obs')        # plots a title for the plot\n",
    "ax = plt.gca()                 # gca function that returns the current axes\n",
    "ax.coastlines()                # adds coastlines defined by the axes of the plot\n",
    "ax.set_extent((65.0, 155.0, 0.0, 40.0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question:</b> \n",
    "    <br>What are the differences between the following plots for HadGEM2-ES, MPI-ESM and CHIRPS? Note the colour bars. \n",
    "    <br>Where are the largest daily rainfall rates distributed?\n",
    "    <br>Why do you think this is happening?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer:</b> *(Double click here to fill in the answers)*<br>\n",
    "\n",
    "<b>What differences do you see between the three plots?</b>\n",
    "\n",
    "\n",
    "<b>Location of greatest rainfall</b>\n",
    "<br> *HadGEM2-ES*: \n",
    "<br> *MPI-ESM*: \n",
    "<br> *CHIRPS*:\n",
    "\n",
    "\n",
    "<b>What is happening and why?</b>\n",
    "\n",
    "\n",
    "<b>How could comparison be made easier?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>This completes worksheet 2.</b> <br>You have covered converting units, created seasonal means and visualised your results.<br>\n",
    "In worksheet 3, you will start to consider more advanced analysis, extract regional means, look at annule cycles, work with ensemble data and produce difference plots.\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img src=\"img/MO_MASTER_black_mono_for_light_backg_RBG.png\" alt=\"python + iris logo\" style=\"float: center; height: 100px;\"/></p>\n",
    "<center>© Crown Copyright 2022, Met Office</center>"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.6.10 ('pyprecis-environment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "30fc2c9368d5cc76c4fad6f63328738b6cf0a0091c34cff8da6b063602b9d1b0"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

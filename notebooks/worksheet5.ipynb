{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 5: Thresholds and climate extremes\n",
    "The following exercises demonstrate analysis of moderate extremes in climate simulated in CORDEX. As with the other worksheets, these are just examples of some of the analysis that you might perform using packages such as Python and and the python Library IRIS.\n",
    "\n",
    "The basis of climate extremes analysis is a common set of standard extreme climate indices, defined by the World Climate Research Programme [Expert Team on Climate Change Detection and Indices (ETCCDI)](https://www.wcrp-climate.org/etccdi).\n",
    "\n",
    "There are 27 climate extremes indices, nicely summarised by the [Climdex](https://www.climdex.org/learn/indices/) website.  You can read more about them in the frame below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://www.climdex.org/learn/indices/', width=950, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this worksheet we'll be looking at wet days, a threshold measure giving the count of days when $\\mathrm{pr} \\geq 1 mm \\;day^{-1}$, and **R95p**, the 95th percentile of precipitation on wet days ($\\mathrm{pr} \\geq 1 mm \\;day^{-1}$) in the 1986-2005 period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>By the end of this worksheet you should be able to:</b><br> \n",
    "- Have an appreciation for working with daily model data <br>\n",
    "- Understand how to calculate some useful climate extremes statistics<br>\n",
    "- Be aware of some coding stratagies for dealing with large data sets<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "### [5.1: Frequency of Wet days](#5.1) \n",
    "### [5.2: Calculating percentiles](#5.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code preamble - these libraries will be used in this worksheet.\n",
    "# This code block needs to be re-run every time you restart this worksheet!\n",
    "%matplotlib inline \n",
    "import os\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "import iris.quickplot as qplt\n",
    "import iris.plot as iplt\n",
    "from iris.time import PartialDateTime\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dask\n",
    "dask.config.set(scheduler=dask.get)\n",
    "import dask.array as da\n",
    "from iris.analysis import Aggregator\n",
    "\n",
    "# Some helpful data locations\n",
    "DATADIR = 'data_v2'\n",
    "DOMAIN = 'EAS-22'\n",
    "CLIMDIR = os.path.join(DATADIR, DOMAIN, 'climatology')\n",
    "HISTDIR = os.path.join(DATADIR, DOMAIN, 'historical')\n",
    "FUTRDIR = os.path.join(DATADIR, DOMAIN, 'rcp85')\n",
    "CHIRPSDIR = os.path.join('data_v2', 'CHIRPS')\n",
    "GCMIDS = ['hadgem2-es', 'mpi-esm-lr']\n",
    "TIME_PERIODS = {'historical':'1986_2005', 'rcp85':'2041_2060'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question:</b> Thinking about climate extremes, what model <b>averaging period</b> should we be using for our data analysis? Why? <br>\n",
    "    How do we identify this model avergaing period in the model output <b>filenames</b>?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer:</b><br>\n",
    "*Type your answer here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5.1'></a>\n",
    "## 5.1 Frequency of wet days\n",
    "\n",
    "**a)** Start by finding the frequency of wet days using daily data for both _HadGEM2-ES_ and _MPI-ESM-LR_ driven runs.  Calculate the number of days in both the baseline and future periods which are wet days - **a wet day is defined as having precipitation >=1 mm/day**.  Then calculate the percentage of wet days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each day: is rainfall >= 1? True/False\n",
    "# Sum over all days to get number of wet days at each grid point\n",
    "# Do for both model simulations and time periods\n",
    "# Then calcuate the percentage of wet days.\n",
    "\n",
    "# Define a new aggregator to help count non-zero days\n",
    "# (This uses a dask array to reduce memory load)\n",
    "# To learn more about custom aggregators see\n",
    "# https://scitools.org.uk/iris/docs/v2.4.0/examples/General/custom_aggregation.html#general-custom-aggregation \n",
    "\n",
    "\n",
    "for gcmid in GCMIDS:\n",
    "    for period in TIME_PERIODS.keys():\n",
    "        # Get path to daily data\n",
    "        infile = os.path.join(DATADIR, DOMAIN, period, gcmid + '.day.' + TIME_PERIODS[period] + '.GERICS-REMO2015.pr.*.nc')\n",
    "        data = iris.load_cube(infile)\n",
    "        # count wet days \n",
    "        model_wetdays = data.collapsed('time', iris.analysis.COUNT,\n",
    "                                       function=lambda values: values > 1)\n",
    "        model_wetdays.rename(gcmid + ' number of wet days (>=1mm/day) ' + TIME_PERIODS[period])\n",
    "        # Save the file\n",
    "        outfile = os.path.join(CLIMDIR, gcmid + '.day.' + TIME_PERIODS[period] + '.GERICS-REMO2015.wetday.nc')\n",
    "        iris.save(model_wetdays, outfile)\n",
    "        print('Saved: ' + outfile)\n",
    "        \n",
    "        # Find wet days as a percentage of total days\n",
    "        total_days = len(data.coord('time').points)  \n",
    "        model_pcent_wetdays = (model_wetdays / total_days) * 100\n",
    "        # Add metadata\n",
    "        model_pcent_wetdays.rename(gcmid + ' percentage of wet days (>=1mm/day) ' + TIME_PERIODS[period])\n",
    "        model_pcent_wetdays.units = '%'\n",
    "\n",
    "        # Save the file\n",
    "        outfile = os.path.join(CLIMDIR, gcmid + '.day.' + TIME_PERIODS[period] + '.GERICS-REMO2015.wetday.pcent.nc')\n",
    "        iris.save(model_pcent_wetdays, outfile)\n",
    "        print('Saved: ' + outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**b) Calculate numbers of wet days and percentage of wet days from the _CHIRPS_ observations**. \n",
    "\n",
    "Climate Hazards Group InfraRed Precipitation with Station data ([CHIRPS](https://chc.ucsb.edu/data/chirps)) is a 35+ year quasi-global rainfall data set. Spanning 50°S-50°N (and all longitudes) and ranging from 1981 to near-present, CHIRPS incorporates climatology, 0.05° resolution satellite imagery, and in-situ station data to create gridded rainfall time series for trend analysis and seasonal drought monitoring. \n",
    "\n",
    "We'll use CHIRPS as our observational data from which to compare our CORDEX model data.\n",
    "\n",
    "**Fill in the missing code** to calculate the observed wet days: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CHIRPS daily precipitation data, but only period of interest\n",
    "historical_time_constraint = iris.Constraint(time=lambda cell: PartialDateTime(year=1986) \n",
    "                            <= cell.point <= PartialDateTime(year=2005))\n",
    "\n",
    "infile = os.path.join(CHIRPSDIR, 'chirps-v2.0_pr_day_1981-2018_p25.nc')\n",
    "\n",
    "# Find number of wet days\n",
    "\n",
    "# Save wet days cube\n",
    "outfile = os.path.join(CLIMDIR, 'chirps.wetday.nc')\n",
    "\n",
    "# Find number of days in dataset (number_chirps_days)\n",
    "\n",
    "# Find wet days as percent of all chirps days \n",
    "\n",
    "# Save \n",
    "outfile = os.path.join(CLIMDIR, 'chirps.wetday.pcent.nc')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question:</b> Are there any additional considerations that have to be made with daily data? <br>\n",
    "    From a coding perspective, how does working with daily data compare to working with monthly data?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer</b><br>\n",
    "*Type your answer here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** **Plot** the modelled and observed **numbers of wet days** from 1986-2005. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot modelled and observed numbers of wet days for a common baseline period.\n",
    "# Create a figure of the size desired\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "fig.suptitle('Number of wet days (1986-2005)', fontsize=16)\n",
    "\n",
    "# Set common limits for each subplot\n",
    "cbar_lims=(0,number_chirps_days)\n",
    "easia_domain = [70,160,10,50]\n",
    "\n",
    "# Load and plot the models' wet day count\n",
    "for n, gcmid in enumerate(GCMIDS):\n",
    "    infile = os.path.join(CLIMDIR, gcmid + '.day.1986_2005.GERICS-REMO2015.wetday.nc')\n",
    "    nwetdays = iris.load_cube(infile)\n",
    "    ax1 = fig.add_subplot(1, 3, n+1, projection=ccrs.PlateCarree())\n",
    "    qplt.pcolormesh(nwetdays, vmin=cbar_lims[0], vmax=cbar_lims[1])\n",
    "    plt.title(gcmid)\n",
    "    ax1.coastlines()             # adds coastlines defined by the axes of the plot\n",
    "    ax1.set_extent(easia_domain, crs=ccrs.PlateCarree())\n",
    "\n",
    "# Load and plot CHIRPS wet day count\n",
    "infile = os.path.join(CLIMDIR, 'chirps.wetday.nc')\n",
    "obs_nwetdays = iris.load_cube(infile)\n",
    "fig.add_subplot(1, 3, 3, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(obs_nwetdays, vmin=cbar_lims[0], vmax=cbar_lims[1])\n",
    "plt.title('Observations (CHIRPS)')\n",
    "ax = plt.gca()              # gca function that returns the current axes\n",
    "ax.coastlines()\n",
    "ax.set_extent(easia_domain, crs=ccrs.PlateCarree())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question:</b> Which of the following steps are required in order to <b>calculate the model bias</b> (the difference between CORDEX model output and observed data)? <br>\n",
    "    \n",
    "* Regrid data onto a common grid, to the finer (higher) resolution <br>\n",
    "* Regrid data onto a common grid, to the coarser (lower) resolution <br>\n",
    "* Convert CODREX data to a regular lat-lon grid if the simulation used a rotated pole <br>\n",
    "* Ensure the units are comparable (e.g not comparing K with C)  <br>\n",
    "    \n",
    "Which of these steps are required when __comparing output for different time periods from the same model simulation__ (e.g. _future - baseline_ difference calculations)? \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer</b><br>\n",
    "Steps required to calculate the model bias: <br>\n",
    "* *type your answer here...*<br>\n",
    "\n",
    "Steps required when comparing output from the same simulation: <br>\n",
    "* *type your answer here...*<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Calculate the **difference in modelled future and baseline** wet day frequency and also the **difference in modelled baseline and observation** wet day frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load percentage of wet days data for the CHIRPS observations\n",
    "infile = os.path.join(CLIMDIR, 'chirps.wetday.pcent.nc')\n",
    "obs = iris.load_cube(infile)\n",
    "# Add coordinate system information to facilitate regridding later\n",
    "wgs84_cs = iris.coord_systems.GeogCS(6371229.0) \n",
    "obs.coord('latitude').coord_system = wgs84_cs \n",
    "obs.coord('longitude').coord_system = wgs84_cs\n",
    "\n",
    "# constrain the observations to a smaller domain \n",
    "obs_sub = obs.intersection(longitude=(70, 160), latitude=(10, 50))\n",
    "\n",
    "\n",
    "# The observed rainfall data have been created using surface rain gauges, and so are only available\n",
    "# over land points.  Define a mask to remove sea points. The mask is True for masked points.\n",
    "mask = np.where(obs.data > 0.0, False, True)\n",
    "\n",
    "# Redefine the obs data array as a masked array.\n",
    "obs.data = np.ma.array(obs.data, mask=mask)\n",
    "\n",
    "# Define regridding method\n",
    "scheme = iris.analysis.Linear(extrapolation_mode='mask')\n",
    "\n",
    "for gcmid in GCMIDS:\n",
    "    infile = os.path.join(CLIMDIR, gcmid + '.day.' + TIME_PERIODS['historical'] + '.GERICS-REMO2015.wetday.pcent.nc')\n",
    "    model_baseline = iris.load_cube(infile)\n",
    "    infile = os.path.join(CLIMDIR, gcmid + '.day.' + TIME_PERIODS['rcp85'] + '.GERICS-REMO2015.wetday.pcent.nc')\n",
    "    model_future = iris.load_cube(infile)\n",
    "    # In order to compare the modelled and observed numbers of wet days,\n",
    "    # the model data needs to be regridded to the CHIRPS grid\n",
    "    model_baseline_rg = model_baseline.regrid(obs_sub, scheme)\n",
    "    model_future_rg = model_future.regrid(obs_sub, scheme)\n",
    "\n",
    "    # Find the difference between futue and baseline models\n",
    "    diff_model = model_future_rg - model_baseline_rg\n",
    "    diff_model.rename(gcmid +' change in number of wet days (>=1mm/day) 2041-2060 vs 1986-2005')\n",
    "    # Save the file\n",
    "    outfile = os.path.join(CLIMDIR, gcmid + '.GERICS-REMO2015.wetday.pcent.diff.nc')\n",
    "    iris.save(diff_model, outfile)\n",
    "    print('Saved ' + outfile)\n",
    "\n",
    "    # Subtract the observed percentages of wet days from the modelled percentages\n",
    "    diff_mod_obs = model_baseline_rg - obs_sub\n",
    "    diff_mod_obs.rename(gcmid + ' number of wet days (>=1mm/day) bias compared to CHIRPS')\n",
    "    # Save the file\n",
    "    outfile = os.path.join(CLIMDIR, gcmid + '.GERICS-REMO2015.wetday.pcent.bias.nc')\n",
    "    iris.save(diff_mod_obs, outfile)\n",
    "    print('Saved ' + outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note</b>: A cube can be easily constrained to a given domain using the <code>cube.intersection</code> method. More information on this (and other) Iris cube functionality can be found in the <b><a href=\"https://scitools.org.uk/iris/docs/v2.4.0/iris/iris/cube.html?highlight=intersection#iris.cube.Cube.intersection\">Iris Documentation</a></b> online.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** **Plot the percentage change and model bias for wet day frequency**.  \n",
    "\n",
    "**First**, run the code block below to produce a series of plots showing the model bias and future precipitation change for _cahpa_ and _cahpb_ simulations. <br>\n",
    "\n",
    "As the model domain is smaller than the observations domain, you will see that the data is plotted on a domain which is larger than necessary. \n",
    "\n",
    "**Next, read the Iris documentation** to learn how to use the `cube.intersection` method, then **add the necessary code** below, to constrain the plots to the model domain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure of the size 12x12 inches\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "\n",
    "# Load the model's future percentage change in wet days (future - baseline)\n",
    "for n, gcmid in enumerate(GCMIDS):\n",
    "    infile = os.path.join(CLIMDIR, gcmid + '.GERICS-REMO2015.wetday.pcent.diff.nc')\n",
    "    pcent_change = iris.load_cube(infile)\n",
    "    \n",
    "    # Add in a line of code to constrain the model domain to these coordinates: \n",
    "    # longitude=(70, 160)\n",
    "    # latitude=(10, 50)\n",
    "    pcent_change_subset = \n",
    "    \n",
    "    # plot percentage changes on first row\n",
    "    plt.subplot(2, 2, n+1)\n",
    "    qplt.pcolormesh(pcent_change_subset, \n",
    "                    vmax=10, vmin=-10, cmap='BrBG')\n",
    "    plt.title(gcmid + ' rcp85-historical \\n precipitation change (%)')\n",
    "    ax = plt.gca()\n",
    "    ax.coastlines()\n",
    "\n",
    "    \n",
    "# Load the percentage bias (differences in precipitation between the models and obs)\n",
    "for n, gcmid in enumerate(GCMIDS):\n",
    "    infile = os.path.join(CLIMDIR, gcmid + '.GERICS-REMO2015.wetday.pcent.bias.nc')\n",
    "    pcent_bias = iris.load_cube(infile)\n",
    "    \n",
    "    # Add in a line of code to constrain the model domain to these lat-lon coordinates: \n",
    "    # longitude=(70, 160)\n",
    "    # latitude=(10, 50)\n",
    "    pcent_bias_subset = \n",
    "    \n",
    "    # plot bias on the second row\n",
    "    plt.subplot(2, 2, n+3)\n",
    "    qplt.pcolormesh(pcent_bias_subset, \n",
    "                    vmax=20, vmin=-20, cmap='BrBG')\n",
    "    plt.title(gcmid + ' model-observations \\n precipitation difference (%)')\n",
    "    ax = plt.gca()\n",
    "    ax.coastlines()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question:</b><br>\n",
    "\n",
    "*  Which simulation (<i>HadGEM2-ES</i> or <i>MPI-ESM-LR</i>) has better agreement with observations for wet day frequency? <br>\n",
    "* What is the magnitude and location of any notable wet or dry biases for each simulation during the baseline period? <br>\n",
    "* Summarise the projected change in wet day frequency over South-East Asia for both simulations. <br>\n",
    "* Given any wet/dry biases in each simulation's baseline period, what adjustments might we make to our summary of projected change from <i>HadGEM2-ES</i> or <i>MPI-ESM-LR</i>? \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers:**\n",
    "\n",
    "Which simulation  has better agreement with observations?\n",
    "    \n",
    "* \n",
    "\n",
    "    \n",
    "Magnitude and location of any notable wet or dry biases:\n",
    "\n",
    "* HadGEM2-ES driven run: \n",
    "* MPI-ESM-LR driven run: \n",
    "\n",
    "Summarise the projected change in wet day frequency:\n",
    "\n",
    "* HadGEM2-ES driven run: \n",
    "* MPI-ESM-LR driven run: \n",
    "\n",
    "Adjustments in light of model bias:\n",
    "\n",
    "* HadGEM2-ES driven run: \n",
    "* MPI-ESM-LR driven run: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5.2'></a>\n",
    "## 5.2. Calculating percentiles\n",
    "\n",
    "**f)** Calculate in mm/day the baseline (1986-2005) and future (2041-2060) **95th percentile of precipitation**. Do this for HadGEM2-ES, MPI-ESM-LE driven runs and also for CHIRPS  baseline.\n",
    "\n",
    "This introduces some new processing challenges: **the size of the daily future data set is (probably) too large to load into memory**.  Sometimes Iris can handle this for us (see [Iris and Lazy Data](https://scitools.org.uk/iris/docs/v2.4.0/userguide/real_and_lazy_data.html)), but in this case we need to manually **'chunk' the data to load and process smaller sections**.  This way Iris only loads a section of the data at a time and keeps within the memory limits imposed by this computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the number of chunks for the lat and lon dimensions\n",
    "# This will give us 3 x 3 = 9 cubes\n",
    "steps = (3, 3)  \n",
    "\n",
    "# Define a helper function to extract our cube chunks\n",
    "def chunks(cube, x, y):\n",
    "    \"\"\"Yield successive x-y sized chunks from cube\"\"\"\n",
    "    for i in range(0, cube.coord(axis='x').shape[0], x):\n",
    "        for j in range(0, cube.coord(axis='y').shape[0], y):\n",
    "            yield cube[:, j:j + y, i:i + x]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now process the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over job ID and time period\n",
    "for gcmid in GCMIDS:\n",
    "    for period in TIME_PERIODS.keys():\n",
    "        infile = os.path.join(DATADIR, DOMAIN, period, gcmid + '.day.' + TIME_PERIODS[period] + '.GERICS-REMO2015.pr.mmday-1.nc')\n",
    "        model_precip = iris.load_cube(infile)\n",
    "        # if cube has both latitude (2d true latitude) and grid_latitude, then\n",
    "        # coord(axis='y') does not work, so remove unused 'latitude' and 'longitude'\n",
    "        model_precip.remove_coord('latitude')\n",
    "        model_precip.remove_coord('longitude')\n",
    "        \n",
    "        # Calculate lat-lon chunks in terms of their index\n",
    "        lat_chunk = int(model_precip.coord(axis='y').shape[0] / steps[0])\n",
    "        lon_chunk = int(model_precip.coord(axis='x').shape[0] / steps[1])\n",
    "        # Make list of cubes\n",
    "        subcubes = list(chunks(model_precip, lon_chunk, lat_chunk))\n",
    "        # Loop through subcubes\n",
    "        model_pc95 = iris.cube.CubeList()\n",
    "        for cube in subcubes:\n",
    "            model_pc95.append(cube.collapsed('time', iris.analysis.PERCENTILE, percent=95.))\n",
    "        # Concatenate the cube list back into one cube\n",
    "        model_pc95 = model_pc95.concatenate_cube()\n",
    "        # Give cube a helpful name\n",
    "        model_pc95.rename('R95p of ' + gcmid + ' daily rainfall ' + TIME_PERIODS[period])\n",
    "        # Save output\n",
    "        outfile = os.path.join(CLIMDIR, gcmid + '.day.pc95.' + TIME_PERIODS[period] + '.GERICS-REMO2015.pr.mmday-1.nc')\n",
    "        iris.save(model_pc95, outfile)\n",
    "        print('Saved: ' + outfile)\n",
    "        # Tidy up memory\n",
    "        del model_precip, model_pc95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question:</b> Why can we only 'chunk' in the lat-lon dimensions?  Why can't we 'chunk' the time dimension?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer</b><br>\n",
    "<i>Type your answer here...</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for the CHIRPS data. First we take a subset of the CHIRPS data to make the code run quicker - constraining the data in time to the same period as the RCM data above and in space to a similar area to the EAS-22 domain (62-185 degrees longitude, -2 to 50 degree latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_time_constraint = iris.Constraint(time=lambda cell: PartialDateTime(year=1986) \n",
    "                            <= cell.point <= PartialDateTime(year=2005))\n",
    "# now load CHIRPS daily data\n",
    "infile = os.path.join(CHIRPSDIR, 'chirps-v2.0_pr_day_1981-2018_p25.nc')\n",
    "obs_precip = iris.load_cube(infile, historical_time_constraint)\n",
    "obs_precip = obs_precip.intersection(longitude=(62, 185), latitude=(-2, 50))\n",
    "\n",
    "\n",
    "# save this to disk \n",
    "subsetfile = os.path.join(CHIRPSDIR, 'chirps-v2.0_pr_day_1986-2005_p25_eastasia.nc')\n",
    "iris.save(obs_precip, subsetfile)\n",
    "\n",
    "# save memory\n",
    "del obs_precip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the percentile calculation for the CHIRPS data\n",
    "\n",
    "#  load subset of CHRIRPS in \n",
    "obs_precip = iris.load_cube(subsetfile)\n",
    "\n",
    "# Calculate lat-lon chunks in terms of their index\n",
    "lat_chunk = int(obs_precip.coord(axis='y').shape[0] / steps[0])\n",
    "lon_chunk = int(obs_precip.coord(axis='x').shape[0] / steps[1])\n",
    "\n",
    "# Make list of cubes\n",
    "subcubes = list(chunks(obs_precip, lon_chunk, lat_chunk))\n",
    "# Loop through subcubes\n",
    "obs_pc95 = iris.cube.CubeList()\n",
    "for cube in subcubes:\n",
    "    cube.data = np.ma.filled(cube.data, np.nan)\n",
    "    obs_pc95.append(cube.collapsed('time', iris.analysis.PERCENTILE, percent=95.))\n",
    "    print('Done ' + len(obs_pc95) + ' chunks')\n",
    "\n",
    "# Concatenate the cube list back into one cube\n",
    "obs_pc95 = obs_pc95.concatenate_cube()\n",
    "\n",
    "# Redefine the data array of pc95 as a masked array. \n",
    "obs_pc95.data = np.ma.masked_where(np.isnan(obs_pc95.data), obs_pc95.data)\n",
    "outfile = os.path.join(CLIMDIR, 'chirps.pc95.1986_2005.mmday-1.nc')\n",
    "iris.save(obs_pc95, outfile)\n",
    "print('Saved: ' + outfile)\n",
    "\n",
    "# Tidy up memory\n",
    "del obs_precip, obs_pc95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**g)** **Calculate the change in extreme precipitation** _(the difference between the future and baseline 95th percentiles of precipitation)_ **and the associated model bias** _(the difference between the baseline and CHIRPS 95th percentiles of precipitation)._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define WGS84 coordinate system\n",
    "wgs84 = iris.coord_systems.GeogCS(semi_major_axis=6378137.0, inverse_flattening=298.257223563)\n",
    "\n",
    "# Load CHIRPS data\n",
    "infile = os.path.join(CLIMDIR, 'chirps.pc95.1986_2005.mmday-1.nc')\n",
    "obs_cube = iris.load_cube(infile)\n",
    "obs_cube.coord('latitude').coord_system = wgs84 \n",
    "obs_cube.coord('longitude').coord_system = wgs84\n",
    "\n",
    "# constrain the observations to a smaller domain \n",
    "obs_cube = obs_cube.intersection(longitude=(70, 160), latitude=(10, 50))\n",
    "\n",
    "\n",
    "# Define regridding method\n",
    "scheme = iris.analysis.Linear(extrapolation_mode='mask')\n",
    "\n",
    "for gcmid in GCMIDS:\n",
    "    # First, calculate the difference between the modelled future and baseline 95th percentiles\n",
    "    infile = os.path.join(CLIMDIR, gcmid + '.day.pc95.1986_2005.GERICS-REMO2015.pr.mmday-1.nc')\n",
    "    print(infile)\n",
    "    model_base = iris.load_cube(infile)\n",
    "    infile = os.path.join(CLIMDIR, gcmid + '.day.pc95.2041_2060.GERICS-REMO2015.pr.mmday-1.nc')\n",
    "    model_fut = iris.load_cube(infile)\n",
    "    diff = iris.analysis.maths.subtract(model_fut, model_base)\n",
    "    diff.rename(gcmid + ' change in R95p (rcp85 - historical)')\n",
    "    outfile = os.path.join(CLIMDIR, gcmid + '.day.pc95.diff.GERICS-REMO2015.pr.mmday-1.nc')\n",
    "    iris.save(diff, outfile)\n",
    "    print('Saved: ' + outfile)\n",
    "\n",
    "    # Next, calculate the differences between the modelled baseline and observed 95th percentiles\n",
    "    # Remember, to compare the model and observations, the model data need to be regridded.\n",
    "    model_base_rg = model_base.regrid(obs_cube, scheme)\n",
    "    bias = obs_cube.copy()\n",
    "    bias.data = model_base_rg.data - obs_cube.data\n",
    "    bias.rename(gcmid + ' bias in R95p (model - obs)')\n",
    "    outfile = os.path.join(CLIMDIR, gcmid + '.day.pc95.bias.GERICS-REMO2015.pr.mmday-1.nc')\n",
    "    iris.save(bias, outfile)\n",
    "    print('Saved: ' + outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**h)** **Plot the differences in the 95th percentiles** between the models and observations, and the future changes in the 95th percentiles of precipitation from both models.\n",
    "\n",
    "**Complete the code block to plot the figures...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note</b>: You will probably find it useful to consult the matpltlib documentation to help you produce your plots.  In this case, take a look at the <code>plt.subplot()</code> docs to help you arrange your plots:<b> <a href=\"https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplot.html\"> plt.subplot()</a></b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HINT: The filenames have the following pattern: gcmid + '.day.pc95.bias.pr.mmday-1.nc'\n",
    "# Create a figure of the size 12x12 inches\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for n, gcmid in enumerate(GCMIDS):\n",
    "    # HINT: Use the `n` variable to help arrange you plots using: plt.subplot()\n",
    "    # Use the matplotlib documention to help you! \n",
    "\n",
    "    # Load and plot the model bias (model - obs)\n",
    "\n",
    "    # Load and plot the percentage change in precipitation between future and baseline\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question:</b><br>\n",
    "\n",
    "* Where do we see the greatest changes in extreme precipitation for each simulation? <br>\n",
    "* Comment on each model's ability to reprent observed extremes in precipitation at the 95th percentile. <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Greatest changes:\n",
    "\n",
    "* HadGEM2-ES driven run: \n",
    "* MPI-ESM-LR driven run: \n",
    "\n",
    "Abilty to represent observed extremes:\n",
    "\n",
    "* HadGEM2-ES driven run: \n",
    "* MPI-ESM-LR driven run: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>This completes worksheet 5.</b> <br>You have calculated and compared climate indices for future and baseline rainfall. You have also learned an effective method for working with large quantities of daily data. <br>\n",
    "In the final worksheet you will combine all the techniques learned to this point, through writing your own code to post-process and analyse CORDEX simulations of extreme temperature over East Asia. \n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img src=\"img/MO_MASTER_black_mono_for_light_backg_RBG.png\" alt=\"python + iris logo\" style=\"float: center; height: 100px;\"/></p>\n",
    "<center>© Crown Copyright 2022, Met Office</center>"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3.6.10 ('pyprecis-environment')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "30fc2c9368d5cc76c4fad6f63328738b6cf0a0091c34cff8da6b063602b9d1b0"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

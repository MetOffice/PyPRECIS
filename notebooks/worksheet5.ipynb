{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 5: Thresholds and climate extremes\n",
    "The following exercises demonstrate analysis of moderate extremes in climate simulated using PRECIS. As with the other worksheets, these are just examples of some of the analysis that you might perform using packages such as Python and and the python Library IRIS.\n",
    "\n",
    "The basis of climate extremes analysis is a common set of standard extreme climate indices, defined by the World Climate Research Programme [Expert Team on Climate Change Detection and Indices (ETCCDI)](https://www.wcrp-climate.org/etccdi).\n",
    "\n",
    "There are 27 climate extremes indices, nicely summarised by the [Climdex](https://www.climdex.org/learn/indices/) website.  You can read more about them in the frame below..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://www.climdex.org/learn/indices/', width=950, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this worksheet we'll be looking at wet days, a threshold measure giving the count of days when $\\mathrm{pr} \\geq 1 mm \\;day^{-1}$, and **R95p**, the 95th percentile of precipitation on wet days ($\\mathrm{pr} \\geq 1 mm \\;day^{-1}$) in the 1961-1990 period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>By the end of this worksheet you should be able to:</b><br> \n",
    "- Have an appreciation for working with daily model data <br>\n",
    "- Understand how to calculate some useful climate extremes statistics<br>\n",
    "- Be aware of some coding stratagies for dealing with large data sets<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "### [5.1: Frequency of Wet days](#5.1) \n",
    "### [5.2: Calculating percentiles](#5.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code preamble - these libraries will be used in this worksheet.\n",
    "# This code block needs to be re-run every time you restart this worksheet!\n",
    "%matplotlib inline \n",
    "import os\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "import iris.quickplot as qplt\n",
    "import iris.plot as iplt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dask\n",
    "dask.config.set(scheduler=dask.get)\n",
    "import dask.array as da\n",
    "from iris.analysis import Aggregator\n",
    "\n",
    "# Some helpful data locations\n",
    "DATADIR = '/project/precis/worksheets/data'\n",
    "CLIMDIR = os.path.join(DATADIR, 'climatology')\n",
    "HISTDIR = os.path.join(DATADIR, 'historical')\n",
    "FUTRDIR = os.path.join(DATADIR, 'future')\n",
    "APHRODIR = os.path.join(DATADIR, 'APHRODITE')\n",
    "JOBIDS = ['cahpa', 'cahpb']\n",
    "TIME_PERIODS = {'historical':'1961_1990', 'future':'2021_2050'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question:</b> Thinking about climate extremes, what model <b>averaging period</b> should we be using for our data analysis? Why? <br>\n",
    "    How do we identify this model avergaing period in the model output <b>filenames</b>?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer:</b><br>\n",
    "*Type your answer here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5.1'></a>\n",
    "## 5.1 Frequency of wet days\n",
    "\n",
    "**a)** Start by finding the frequency of wet days using daily data for both _cahpa_ and _cahpb_.  Calculate the number of days in both the baseline and future periods which are wet days - **a wet day is defined as having precipitation >=1 mm/day**.  Then calculate the percentage of wet days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each day: is rainfall >= 1? True/False\n",
    "# Sum over all days to get number of wet days at each grid point\n",
    "# Do for both model simulations and time periods\n",
    "# Then calcuate the percentage of wet days.\n",
    "\n",
    "# Define a new aggregator to help count non-zero days\n",
    "# (This uses a dask array to reduce memory load)\n",
    "count_nonzero = Aggregator('count', None,\n",
    "                           units_func=lambda units: 1,\n",
    "                           lazy_func=da.count_nonzero)\n",
    "\n",
    "for runid in JOBIDS:\n",
    "    for period in TIME_PERIODS.keys():\n",
    "        # Get path to daily data\n",
    "        infile = os.path.join(DATADIR, period, runid + '.day.' + TIME_PERIODS[period] + '.pr.*.nc')\n",
    "        data = iris.load_cube(infile)\n",
    "        # Select only wet days using our custom aggregator\n",
    "        model_wetdays = data.collapsed('time', count_nonzero)\n",
    "        model_wetdays.rename('{} number of wet days (>=1mm/day) {}'.format(runid, TIME_PERIODS[period]))\n",
    "        # Save the file\n",
    "        outfile = os.path.join(CLIMDIR, runid + '.day.' + TIME_PERIODS[period] + '.wetday.nc')\n",
    "        iris.save(model_wetdays, outfile)\n",
    "        print('Saved: {}'.format(outfile))\n",
    "        \n",
    "        # Find wet days as a percentage of total days\n",
    "        total_days = len(data.coord('time').points)  # Note that this is a 360 day calendar!\n",
    "        model_pcent_wetdays = (model_wetdays / total_days) * 100\n",
    "        # Add metadata\n",
    "        model_pcent_wetdays.rename('{} percentage of wet days (>=1mm/day) {}'.format(runid, TIME_PERIODS[period]))\n",
    "        model_pcent_wetdays.units = '%'\n",
    "        # Save the file\n",
    "        outfile = os.path.join(CLIMDIR, runid + '.day.' + TIME_PERIODS[period] + '.wetday.pcent.nc')\n",
    "        iris.save(model_pcent_wetdays, outfile)\n",
    "        print('Saved: {}'.format(outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**b) Calculate numbers of wet days and percentage of wet days from the _APHRODITE_ observations**. \n",
    "\n",
    "[APHRODITE](http://www.chikyu.ac.jp/precip/english/) (_Asian Precipitation - Highly-Resolved Observational Data Integration Towards Evaluation_) is a daily gridded dataset of precipitation and temperature from (1951 onward). It is continental-scale and contains a dense network of daily rain-gauge data for Asia including the Himalayas, South and Southeast Asia and mountainous areas in the Middle East.  \n",
    "\n",
    "We have extracted APHRODITE data for the period 1961 to 1990. APHRODITE uses a Greogorian 365.25-day calendar (ie. includes leap years), so this data set has 10957 days.\n",
    "\n",
    "We'll use APHRODITE as our observational data from which to compare our PRECIS model data.\n",
    "\n",
    "**Fill in the missing code** to calculate the observed wet days: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load APHRODITE daily precipitation data:\n",
    "infile = os.path.join(APHRODIR, 'aphro.day.1961_1990.nc')\n",
    "obs = iris.load_cube(infile, 'daily precipitation analysis interpolated onto 0.25deg grids [mm/day]')\n",
    "\n",
    "# Find number of wet days\n",
    "\n",
    "\n",
    "# Save wet days cube\n",
    "outfile = os.path.join(CLIMDIR, 'aphro.wetday.nc')\n",
    "\n",
    "\n",
    "# Find number of days in dataset\n",
    "\n",
    "\n",
    "# Find wet days as percent of all aphro days \n",
    "\n",
    "\n",
    "# Save \n",
    "outfile = os.path.join(CLIMDIR, 'aphro.wetday.pcent.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question:</b> Are there any additional considerations that have to be made with daily data? <br>\n",
    "    From a coding perspective, how does working with daily data compare to working with monthly data?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer</b><br>\n",
    "*Type your answer here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** **Plot** the modelled and observed **numbers of wet days** from 1961-1990. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot modelled and observed numbers of wet days for a common baseline period.\n",
    "# Create a figure of the size 12x12 inches for plots\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "fig.suptitle('Number of wet days (1961-1990)', fontsize=16)\n",
    "\n",
    "# Set common limits for each subplot\n",
    "cbar_lims=(0,number_aphro_days)\n",
    "seasia_domain = [80,150,-15,40]\n",
    "\n",
    "# Load and plot the models' wet day count\n",
    "for n, runid in enumerate(JOBIDS):\n",
    "    infile = os.path.join(CLIMDIR, runid + '.day.1961_1990.wetday.nc')\n",
    "    nwetdays = iris.load_cube(infile)\n",
    "    ax1 = fig.add_subplot(1, 3, n+1, projection=ccrs.PlateCarree())\n",
    "    qplt.pcolormesh(nwetdays, vmin=cbar_lims[0], vmax=cbar_lims[1])\n",
    "    plt.title(runid)\n",
    "    ax1.coastlines()             # adds coastlines defined by the axes of the plot\n",
    "    ax1.set_extent(seasia_domain)\n",
    "\n",
    "# Load and plot APHRODITE wet day count\n",
    "infile = os.path.join(CLIMDIR, 'aphro.wetday.nc')\n",
    "obs_nwetdays = iris.load_cube(infile)\n",
    "fig.add_subplot(1, 3, 3, projection=ccrs.PlateCarree())\n",
    "qplt.pcolormesh(obs_nwetdays, vmin=cbar_lims[0], vmax=cbar_lims[1])\n",
    "plt.title('Observations (APHRODITE)')\n",
    "ax = plt.gca()              # gca function that returns the current axes\n",
    "ax.coastlines()\n",
    "ax.set_extent(seasia_domain)\n",
    "plt.tight_layout()          # automatically adjusts subplot(s) to fit in to the figure area\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question:</b> Which of the following steps are required in order to <b>calculate the model bias</b> (the difference between PRECIS model output and observed data)? <br>\n",
    "    \n",
    "* Regrid data onto a common grid, to the finer (higher) resolution <br>\n",
    "* Regrid data onto a common grid, to the coarser (lower) resolution <br>\n",
    "* Convert PRECIS output to a regular lat-lon grid if the simulation used a rotated pole <br>\n",
    "* Ensure the units are comparable (e.g not comparing K with C)  <br>\n",
    "    \n",
    "Which of these steps are required when __comparing output for different time periods from the same model simulation__ (e.g. _future - baseline_ difference calculations)? \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer</b><br>\n",
    "Steps required to calculate the model bias: <br>\n",
    "* *type your answer here...*<br>\n",
    "\n",
    "Steps required when comparing output from the same simulation: <br>\n",
    "* *type your answer here...*<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Calculate the **difference in modelled future and baseline** wet day frequency and also the **difference in modelled baseline and observation** wet day frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load percentage of wet days data for the APHRODITE observations\n",
    "infile = os.path.join(CLIMDIR, 'aphro.wetday.pcent.nc')\n",
    "obs = iris.load_cube(infile)\n",
    "# Add coordinate system information to facilitate regridding later\n",
    "wgs84_cs = iris.coord_systems.GeogCS(6371229.0) \n",
    "obs.coord('latitude').coord_system = wgs84_cs \n",
    "obs.coord('longitude').coord_system = wgs84_cs\n",
    "\n",
    "# The observed rainfall data have been created using surface rain gauges, and so are only available\n",
    "# over land points.  Define a mask to remove sea points. The mask is True for masked points.\n",
    "mask = np.where(obs.data > 0.0, False, True)\n",
    "\n",
    "# Redefine the obs data array as a masked array.\n",
    "obs.data = np.ma.array(obs.data, mask=mask)\n",
    "\n",
    "# Define regridding method\n",
    "scheme = iris.analysis.Linear(extrapolation_mode='mask')\n",
    "\n",
    "for runid in JOBIDS:\n",
    "    infile = os.path.join(CLIMDIR, runid + '.day.' + TIME_PERIODS['historical'] + '.wetday.pcent.nc')\n",
    "    model_baseline = iris.load_cube(infile)\n",
    "    infile = os.path.join(CLIMDIR, runid + '.day.' + TIME_PERIODS['future'] + '.wetday.pcent.nc')\n",
    "    model_future = iris.load_cube(infile)\n",
    "    # In order to compare the modelled and observed numbers of wet days,\n",
    "    # the model data needs to be regridded to the APHRODITE grid\n",
    "    model_baseline_rg = model_baseline.regrid(obs, scheme)\n",
    "    model_future_rg = model_future.regrid(obs, scheme)\n",
    "\n",
    "    # Find the difference between futue and baseline models\n",
    "    diff_model = model_future_rg - model_baseline_rg\n",
    "    diff_model.rename('{} change in number of wet days (>=1mm/day) 2021-2050 vs 1961-1990 ')\n",
    "    # Save the file\n",
    "    outfile = os.path.join(CLIMDIR, runid + '.wetday.pcent.diff.nc')\n",
    "    iris.save(diff_model, outfile)\n",
    "    print('Saved {}'.format(outfile))\n",
    "\n",
    "    # Subtract the observed percentages of wet days from the modelled percentages\n",
    "    diff_mod_obs = model_baseline_rg - obs\n",
    "    diff_mod_obs.rename('{} number of wet days (>=1mm/day) bias compared to Aphrodite'.format(runid))\n",
    "    # Save the file\n",
    "    outfile = os.path.join(CLIMDIR, runid + '.wetday.pcent.bias.nc')\n",
    "    iris.save(diff_mod_obs, outfile)\n",
    "    print('Saved {}'.format(outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note</b>: A cube can be easily constrained to a given domain using the <code>cube.intersection</code> method. More information on this (and other) Iris cube functionality can be found in the <b><a href=\"https://scitools.org.uk/iris/docs/latest/iris/iris/cube.html?highlight=intersection#iris.cube.Cube.intersection\">Iris Documentation</a></b> online.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** **Plot the percentage change and model bias for wet day frequency**.  \n",
    "\n",
    "**First**, run the code block below to produce a series of plots showing the model bias and future precipitation change for _cahpa_ and _cahpb_ simulations. <br>\n",
    "\n",
    "As the model domain is smaller than the observations domain, you will see that the data is plotted on a domain which is larger than necessary. \n",
    "\n",
    "**Next, read the Iris documentation** to learn how to use the `cube.intersection` method, then **add the necessary code** below, to constrain the plots to the model domain.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure of the size 12x12 inches\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "\n",
    "# Load the model's future percentage change in wet days (future - baseline)\n",
    "for n, runid in enumerate(JOBIDS):\n",
    "    infile = os.path.join(CLIMDIR, runid + '.wetday.pcent.diff.nc')\n",
    "    pcent_change = iris.load_cube(infile)\n",
    "    \n",
    "    # Add in a line of code to constrain the model domain to these coordinates: \n",
    "    # longitude=(90, 137)\n",
    "    # latitude=(-20, 32)\n",
    "    pcent_change_subset = \n",
    "    \n",
    "    # plot percentage changes on first row\n",
    "    plt.subplot(2, 2, n+1)\n",
    "    qplt.pcolormesh(pcent_change_subset, \n",
    "                    vmax=10, vmin=-10, cmap='BrBG')\n",
    "    plt.title(runid + ' future-historical precipitation change (%)')\n",
    "    ax = plt.gca()\n",
    "    ax.coastlines()\n",
    "\n",
    "    \n",
    "# Load the percentage bias (differences in precipitation between the models and obs)\n",
    "for n, runid in enumerate(JOBIDS):\n",
    "    infile = os.path.join(CLIMDIR, runid + '.wetday.pcent.bias.nc')\n",
    "    pcent_bias = iris.load_cube(infile)\n",
    "    \n",
    "    # Add in a line of code to constrain the model domain to these lat-lon coordinates: \n",
    "    # longitude=(90, 137)\n",
    "    # latitude=(-20, 32)\n",
    "    pcent_bias_subset = \n",
    "    \n",
    "    # plot bias on the second row\n",
    "    plt.subplot(2, 2, n+3)\n",
    "    qplt.pcolormesh(pcent_bias_subset, \n",
    "                    vmax=20, vmin=-20, cmap='BrBG')\n",
    "    plt.title(runid + ' model-observations precipitation difference (%)')\n",
    "    ax = plt.gca()\n",
    "    ax.coastlines()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question:</b><br>\n",
    "\n",
    "*  Which simulation (<i>cahpa</i> or <i>cahpb</i>) has better agreement with observations for wet day frequency? <br>\n",
    "* What is the magnitude and location of any notable wet or dry biases for each simulation during the baseline period? <br>\n",
    "* Summarise the projected change in wet day frequency over South-East Asia for both simulations. <br>\n",
    "* Given any wet/dry biases in each simulation's baseline period, what adjustments might we make to our summary of projected change from <i>cahpa</i> or <i>cahpb</i>? \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers:**\n",
    "\n",
    "Which simulation  has better agreement with observations?\n",
    "    \n",
    "* \n",
    "\n",
    "    \n",
    "Magnitude and location of any notable wet or dry biases:\n",
    "\n",
    "* cahpa: \n",
    "* cahpb: \n",
    "\n",
    "Summarise the projected change in wet day frequency:\n",
    "\n",
    "* cahpa:\n",
    "* cahpb:\n",
    "\n",
    "Adjustments in light of model bias:\n",
    "\n",
    "* cahpa:\n",
    "* cahpb:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5.2'></a>\n",
    "## 5.2. Calculating percentiles\n",
    "\n",
    "**f)** Calculate in mm/day the baseline (1961-1990) and future (2021-2050) **95th percentile of precipitation**. Do this for cahpa, cahpb and also for APHRODITE baseline.\n",
    "\n",
    "This introduces some new processing challenges: **the size of the daily future data set is (probably) too large to load into memory**.  Sometimes Iris can handle this for us (see [Iris and Lazy Data](https://scitools.org.uk/iris/docs/latest/userguide/real_and_lazy_data.html)), but in this case we need to manually **'chunk' the data to load and process smaller sections**.  This way Iris only loads a section of the data at a time and keeps within the memory limits imposed by this computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the number of chunks for the lat and lon dimensions\n",
    "# This will give us 3 x 3 = 9 cubes\n",
    "steps = (3, 3)  \n",
    "\n",
    "# Define a helper function to extract our cube chunks\n",
    "def chunks(cube, x, y):\n",
    "    \"\"\"Yield successive x-y sized chunks from cube\"\"\"\n",
    "    for i in range(0, cube.coord(axis='x').shape[0], x):\n",
    "        for j in range(0, cube.coord(axis='y').shape[0], y):\n",
    "            yield cube[:, i:i + x, j:j + y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now process the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over job ID and time period\n",
    "for runid in JOBIDS:\n",
    "    for period in TIME_PERIODS.keys():\n",
    "        infile = os.path.join(DATADIR, period, runid + '.day.' + TIME_PERIODS[period] + '.pr.rr.mmday-1.nc')\n",
    "        model_precip = iris.load_cube(infile)\n",
    "        # Calculate lat-lon chunks in terms of their index\n",
    "        lat_chunk = int(model_precip.coord(axis='y').shape[0] / steps[0])\n",
    "        lon_chunk = int(model_precip.coord(axis='x').shape[0] / steps[1])\n",
    "        # Make list of cubes\n",
    "        subcubes = list(chunks(model_precip, lon_chunk, lat_chunk))\n",
    "        # Loop through subcubes\n",
    "        model_pc95 = iris.cube.CubeList()\n",
    "        for cube in subcubes:\n",
    "            model_pc95.append(cube.collapsed('time', iris.analysis.PERCENTILE, percent=95.))\n",
    "        # Concatenate the cube list back into one cube\n",
    "        model_pc95 = model_pc95.concatenate_cube()\n",
    "        # Give cube a helpful name\n",
    "        model_pc95.rename('R95p of {} daily rainfall {}'.format(runid, TIME_PERIODS[period]))\n",
    "        # Save output\n",
    "        outfile = os.path.join(CLIMDIR, runid + '.day.pc95.' + TIME_PERIODS[period] + '.pr.rr.mmday-1.nc')\n",
    "        iris.save(model_pc95, outfile)\n",
    "        print('Saved: {}'.format(outfile))\n",
    "        # Tidy up memory\n",
    "        del model_precip, model_pc95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question:</b> Why can we only 'chunk' in the lat-lon dimensions?  Why can't we 'chunk' the time dimension?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Answer</b><br>\n",
    "<i>Type your answer here...</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for the APHRODITE data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for the APHRODITE data\n",
    "# Define a mask to remove the sea points, as there are no observations over the sea.\n",
    "infile = os.path.join(CLIMDIR, 'aphro.wetday.nc')\n",
    "obs_wetday_no = iris.load_cube(infile)\n",
    "mask = np.where(obs_wetday_no.data > 0.0, False, True)\n",
    "\n",
    "infile = os.path.join(APHRODIR, 'aphro.day.1961_1990.nc')\n",
    "obs_precip = iris.load_cube(infile, 'daily precipitation analysis interpolated onto 0.25deg grids [mm/day]')\n",
    "# Calculate lat-lon chunks in terms of their index\n",
    "lat_chunk = int(obs_precip.coord(axis='y').shape[0] / steps[0])\n",
    "lon_chunk = int(obs_precip.coord(axis='x').shape[0] / steps[1])\n",
    "# Make list of cubes\n",
    "subcubes = list(chunks(obs_precip, lon_chunk, lat_chunk))\n",
    "# Loop through subcubes\n",
    "obs_pc95 = iris.cube.CubeList()\n",
    "for cube in subcubes:\n",
    "    obs_pc95.append(cube.collapsed('time', iris.analysis.PERCENTILE, percent=95.))\n",
    "# Concatenate the cube list back into one cube\n",
    "obs_pc95 = obs_pc95.concatenate_cube()\n",
    "# Redefine the data array of pc95 as a masked array.\n",
    "obs_pc95.data = np.ma.array(obs_pc95.data, mask=mask)\n",
    "outfile = os.path.join(CLIMDIR, 'aphro.pc95.1961_1990.mmday-1.nc')\n",
    "iris.save(obs_pc95, outfile)\n",
    "print('Saved: {}'.format(outfile))\n",
    "# Tidy up memory\n",
    "del obs_precip, obs_pc95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**g)** **Calculate the change in extreme precipitation** _(the difference between the future and baseline 95th percentiles of precipitation)_ **and the associated model bias** _(the difference between the baseline and APHRODITE 95th percentiles of precipitation)._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define WGS84 coordinate system\n",
    "wgs84 = iris.coord_systems.GeogCS(semi_major_axis=6378137.0, inverse_flattening=298.257223563)\n",
    "\n",
    "# Load aphrodite data\n",
    "infile = os.path.join(CLIMDIR, 'aphro.pc95.1961_1990.mmday-1.nc')\n",
    "obs_cube = iris.load_cube(infile)\n",
    "obs_cube.coord('latitude').coord_system = wgs84 \n",
    "obs_cube.coord('longitude').coord_system = wgs84\n",
    "\n",
    "# Define regridding method\n",
    "scheme = iris.analysis.Linear(extrapolation_mode='mask')\n",
    "\n",
    "for runid in JOBIDS:\n",
    "    # First, calculate the difference between the modelled future and baseline 95th percentiles\n",
    "    infile = os.path.join(CLIMDIR, runid + '.day.pc95.1961_1990.pr.rr.mmday-1.nc')\n",
    "    model_base = iris.load_cube(infile)\n",
    "    infile = os.path.join(CLIMDIR, runid + '.day.pc95.2021_2050.pr.rr.mmday-1.nc')\n",
    "    model_fut = iris.load_cube(infile)\n",
    "    diff = iris.analysis.maths.subtract(model_fut, model_base)\n",
    "    diff.rename('{} change in R95p (future - historical)'.format(runid))\n",
    "    outfile = os.path.join(CLIMDIR, runid + '.day.pc95.diff.pr.mmday-1.nc')\n",
    "    iris.save(diff, outfile)\n",
    "    print('Saved: {}'.format(outfile))\n",
    "\n",
    "    # Next, calculate the differences between the modelled baseline and observed 95th percentiles\n",
    "    # Remember, to compare the model and observations, the model data need to be regridded.\n",
    "    model_base_rg = model_base.regrid(obs_cube, scheme)\n",
    "    bias = obs_cube.copy()\n",
    "    bias.data = model_base_rg.data - obs_cube.data\n",
    "    bias.rename('{} bias in R95p (model - obs)'.format(runid))\n",
    "    outfile = os.path.join(CLIMDIR, runid + '.day.pc95.bias.pr.mmday-1.nc')\n",
    "    iris.save(bias, outfile)\n",
    "    print('Saved: {}'.format(outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**h)** **Plot the differences in the 95th percentiles** between the models and observations, and the future changes in the 95th percentiles of precipitation from both models.\n",
    "\n",
    "**Complete the code block to plot the figures...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note</b>: You will probably find it useful to consult the matpltlib documentation to help you produce your plots.  In this case, take a look at the <code>plt.subplot()</code> docs to help you arrange your plots:<b> <a href=\"https://matplotlib.org/api/_as_gen/matplotlib.pyplot.subplot.html?highlight=subplot#matplotlib.pyplot.subplot\"> plt.subplot()</a></b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# HINT: The filenames have the following pattern: runid + '.day.pc95.bias.pr.mmday-1.nc'\n",
    "# Create a figure of the size 12x12 inches\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for n, runid in enumerate(JOBIDS):\n",
    "    # HINT: Use the `n` variable to help arrange you plots using: plt.subplot()\n",
    "    # Use the matplotlib documention to help you! \n",
    "    # Load and plot the model bias (model - obs)\n",
    "\n",
    "\n",
    "    # Load and plot the percentage change in precipitation between future and baseline\n",
    "            \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "    <b>Question:</b><br>\n",
    "\n",
    "* Where do we see the greatest changes in extreme precipitation for each simulation? <br>\n",
    "* Comment on each model's ability to reprent observed extremes in precipitation at the 95th percentile. <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Greatest changes:\n",
    "\n",
    "* cahpa:\n",
    "* cahpb: \n",
    "\n",
    "Abilty to represent observed extremes:\n",
    "\n",
    "* cahpa:\n",
    "* cahpb:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>This completes worksheet 5.</b> <br>You have calculated and compared climate indices for future and baseline rainfall. You have also learned an effective method for working with large quantities of daily data. <br>\n",
    "In the final worksheet you will combine all the techniques learned to this point, through writing your own code to post-process and analyse PRECIS simulations of extreme temperature over South East Asia. \n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>© Crown Copyright 2019, Met Office</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

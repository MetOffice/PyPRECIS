{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 6 example code\n",
    "\n",
    "## Example 1 Frequency of warm days (TX90P) in the future\n",
    "\n",
    "Calculate the baseline (1986-2005) 90th percentile of maximum temperature. Then calculate the frequency of warm days in the future (2041-2060). Do this for HadGEM2-ES and MPI-ESM-LR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code preamble - these libraries will be used in this worksheet.\n",
    "# This code block needs to be re-run every time you restart this worksheet!\n",
    "%matplotlib inline \n",
    "import os\n",
    "import iris\n",
    "import iris.coord_categorisation\n",
    "import iris.quickplot as qplt\n",
    "import iris.plot as iplt\n",
    "from iris.util import equalise_attributes\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from iris.analysis import Aggregator\n",
    "\n",
    "# Some helpful data locations\n",
    "DATADIR = 'data_v2'\n",
    "CHIRPSDIR = os.path.join(DATADIR, 'CHIRPS')\n",
    "CRUDIR = os.path.join(DATADIR, 'CRU')\n",
    "CLIMDIR = os.path.join(DATADIR, 'EAS-22', 'climatology/')\n",
    "MODELDIR = os.path.join(DATADIR, 'EAS-22/')\n",
    "GCMIDS = ['hadgem2-es', 'mpi-esm-lr']\n",
    "GCM_FULL = {'hadgem2-es':'MOHC-HadGEM2-ES' , 'mpi-esm-lr':'MPI-M-MPI-ESM-LR'}\n",
    "TIME_PERIODS = {'historical':'1986_2005', 'rcp85':'2041_2060'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First calculate the 90th percentile of tsmax in the baseline and future periods for both set of downscaled GCMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a helper function to extract our cube chunks\n",
    "def chunks(cube, x=200, y=200):\n",
    "    \"\"\"\n",
    "    Yield successive x-y sized chunks from cube,\n",
    "    works for 3D Time-Lat-Lon\n",
    "    \n",
    "    Args:\n",
    "    cube (Iris cube): input cube to be chunked\n",
    "    x: size of chunks in x direction\n",
    "    y: size of chunk in y direction\n",
    "    \"\"\"\n",
    "    coord_names = [coord.name() for coord in cube.coords()]\n",
    "    if 'grid_latitude' in coord_names and 'latitude' in coord_names:\n",
    "        cube.remove_coord('latitude')\n",
    "    if 'grid_longitude' in coord_names and 'longitude' in coord_names:\n",
    "        cube.remove_coord('longitude')\n",
    "    \n",
    "    for i in range(0, cube.coord(axis='x').shape[0], x):\n",
    "        for j in range(0, cube.coord(axis='y').shape[0], y):\n",
    "            yield cube[:, j:j + y, i:i + x]\n",
    "\n",
    "    \n",
    "def chunks_2d(cube, x=200, y=200):\n",
    "    coord_names = [coord.name() for coord in cube.coords()]\n",
    "    if 'grid_latitude' in coord_names and 'latitude' in coord_names:\n",
    "        cube.remove_coord('latitude')\n",
    "    if 'grid_longitude' in coord_names and 'longitude' in coord_names:\n",
    "        cube.remove_coord('longitude')\n",
    "    \n",
    "    for i in range(0, cube.coord(axis='x').shape[0], x):\n",
    "        for j in range(0, cube.coord(axis='y').shape[0], y):\n",
    "            yield cube[j:j + y, i:i + x]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gcmid in GCMIDS:\n",
    "    for period in TIME_PERIODS.keys():\n",
    "        filename = f'tasmax_EAS-22_{GCM_FULL[gcmid]}_{period}_*GERICS-REMO2015*_*_day_*.nc'\n",
    "        model_tasmax = iris.load(MODELDIR + filename)\n",
    "        # solve merge issues\n",
    "        equalise_attributes(model_tasmax)\n",
    "        model_tasmax = model_tasmax.concatenate_cube()\n",
    "\n",
    "        # 90th percentile calculation\n",
    "        model_pc90 = iris.cube.CubeList()\n",
    "        for model_data in chunks(model_tasmax):\n",
    "            model_pc90_chk = model_data.collapsed('time', iris.analysis.PERCENTILE, percent=90.0)\n",
    "            model_pc90.append(model_pc90_chk)\n",
    "        model_pc90 =model_pc90.concatenate_cube()\n",
    "\n",
    "        # save to file\n",
    "        outfile = os.path.join(CLIMDIR, gcmid + '.day.' + TIME_PERIODS[period] + '.GERICS-REMO2015.tasmax.90pc.nc')\n",
    "        print(f'saving to file: {outfile}')\n",
    "        iris.save(model_pc90, outfile)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the frequency of warm days in the future (extreme index TX90P), i.e. the number of days which exceed the 90th percentile temperatures in the baseline.  Then calculate the numbers of days as a percentage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gcmid in GCMIDS:\n",
    "    \n",
    "    # load daily data for future \n",
    "    filename = f'tasmax_EAS-22_{GCM_FULL[gcmid]}_rcp85_*GERICS-REMO2015*_*_day_*.nc'\n",
    "    future_tasmax = iris.load(MODELDIR + filename)\n",
    "\n",
    "    # solve merge issues\n",
    "    equalise_attributes(future_tasmax)\n",
    "    future_tasmax = future_tasmax.concatenate_cube()  \n",
    "    ndays = len(future_tasmax.coord('time').points)\n",
    "    \n",
    "    infile = os.path.join(CLIMDIR, gcmid +  '.day.' + TIME_PERIODS['historical'] + '.GERICS-REMO2015.tasmax.90pc.nc')\n",
    "    print(infile)\n",
    "    hist_90pc = iris.load_cube(infile)\n",
    "    \n",
    "    \n",
    "    # need to do next operation chunking data, also chunk 90th percentile \n",
    "    nwarmdays_future = iris.cube.CubeList()  \n",
    "    for chunk_ft_tasmax, chunk_hist_90pc in zip(chunks(future_tasmax), chunks_2d(hist_90pc)):\n",
    "\n",
    "        # Use np.where to identify all cells where daily temperatures \n",
    "        # in the future exceed the 90th percentile\n",
    "        assert(chunk_ft_tasmax.coord('grid_longitude') == chunk_hist_90pc.coord('grid_longitude'))\n",
    "        assert(chunk_ft_tasmax.coord('grid_latitude') == chunk_hist_90pc.coord('grid_latitude'))\n",
    "        temp_gt_chunk = np.where(chunk_ft_tasmax.data >= chunk_hist_90pc.data, 1, 0)\n",
    "              \n",
    "        # use the 90th percentile cube as a template to copy warm days data into \n",
    "        nwarmdays_future_chunk = chunk_hist_90pc.copy()\n",
    "        nwarmdays_future_chunk.data = np.ma.sum(temp_gt_chunk.data, axis=0)\n",
    "        nwarmdays_future.append(nwarmdays_future_chunk)\n",
    "        \n",
    "    nwarmdays_future = nwarmdays_future.concatenate_cube()\n",
    "\n",
    "    # the sum above removes the mask - reinstate it with \n",
    "    nwarmdays_future.data.mask = hist_90pc.data.mask\n",
    "    nwarmdays_future.units = '1'\n",
    "    nwarmdays_future.rename('days > 90th %ile of baseline ')\n",
    "      \n",
    "    print (\"Saving numbers of warm days in the future from \" + gcmid)\n",
    "    outfile = os.path.join(CLIMDIR, gcmid +  '.day.' + TIME_PERIODS['historical'] + '.GERICS-REMO2015.tasmax.nwarmdays.nc')\n",
    "    iris.save(nwarmdays_future, outfile)\n",
    "    \n",
    "    # calculate percentage of days (see below)\n",
    "    nwarm_pc = nwarmdays_future/ndays*100.\n",
    "    nwarm_pc.units = '%'\n",
    "    nwarm_pc.rename('percentage of days T > 90th %ile of baseline ')\n",
    "    \n",
    "    # save percentage\n",
    "    print (\"Saving precentage of warm days in the future from \" + gcmid)\n",
    "    outfile = os.path.join(CLIMDIR, gcmid +  '.day.' + TIME_PERIODS['historical'] + '.GERICS-REMO2015.tasmax.nwarmpc.nc')    \n",
    "    iris.save(nwarm_pc, outfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the numbers of warm days in the future and the percentage of warm days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, gcmid in enumerate(GCMIDS):\n",
    "    \n",
    "    infile = os.path.join(CLIMDIR, gcmid +  '.day.' + TIME_PERIODS['historical'] + '.GERICS-REMO2015.tasmax.nwarmdays.nc')\n",
    "    nwarmdays = iris.load_cube(infile)\n",
    "    infile = os.path.join(CLIMDIR, gcmid +  '.day.' + TIME_PERIODS['historical'] + '.GERICS-REMO2015.tasmax.nwarmpc.nc')    \n",
    "    nwd_pcent = iris.load_cube(infile)\n",
    "\n",
    "    plotnum = 1 + 2*i\n",
    "    plt.subplot(2, 2, plotnum)\n",
    "    qplt.pcolormesh(nwarmdays, vmin=0, vmax=10000)\n",
    "    plt.title(gcmid + ': Number of warm days')\n",
    "    plt.gca().coastlines()\n",
    "    plt.subplot(2, 2, plotnum+1)\n",
    "    qplt.pcolormesh(nwd_pcent, vmin=0, vmax=30)\n",
    "    plt.title(gcmid + ': Percentage of warm days')\n",
    "    plt.gca().coastlines()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2. Percentage of total precipitation which falls on very wet days\n",
    "\n",
    "Calculate the percentage of total precipitation which falls on very wet days in the future over Thailand\n",
    "(where a very wet day is one on which daily rainfall exceeds the 95th percentile of the baseline).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First find the 95th percentile of rainfall during baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gcmid in GCMIDS:\n",
    "    filename = f'pr_EAS-22_{GCM_FULL[gcmid]}_historical_*GERICS-REMO2015*_*_day_*.nc'\n",
    "    model_pr = iris.load(MODELDIR + filename)\n",
    "    # solve merge issues\n",
    "    equalise_attributes(model_pr)\n",
    "    model_pr = model_pr.concatenate_cube()\n",
    "\n",
    "    # 95th percentile calculation\n",
    "    model_pc95 = iris.cube.CubeList()\n",
    "    for model_data in chunks(model_pr):\n",
    "        model_pc95_chk = model_data.collapsed('time', iris.analysis.PERCENTILE, percent=95.0)\n",
    "        model_pc95.append(model_pc95_chk)\n",
    "    model_pc95 = model_pc95.concatenate_cube()\n",
    "\n",
    "    # save to file\n",
    "    outfile = os.path.join(CLIMDIR, gcmid + '.day.' + TIME_PERIODS['historical'] + '.GERICS-REMO2015.pr.95pc.nc')\n",
    "    print(f'saving to file: {outfile}')\n",
    "    iris.save(model_pc95, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates of a box around Thailand\n",
    "thai_lons = np.array([98.0, 98.0, 105.0, 105.0])\n",
    "thai_lats = np.array([10.0, 21.0,  10.0,  21.0])\n",
    "\n",
    "# Load a cube on the rotated grid\n",
    "gcmid = 'hadgem2-es'\n",
    "infile = os.path.join(CLIMDIR, gcmid +  '.day.' + TIME_PERIODS['historical'] + '.GERICS-REMO2015.pr.95pc.nc')\n",
    "rotg = iris.load_cube(infile)\n",
    "rcs = rotg.coord('grid_latitude').coord_system\n",
    "\n",
    "# Get the rotated pole coordinates\n",
    "pole_lat = rcs.grid_north_pole_latitude\n",
    "pole_lon = rcs.grid_north_pole_longitude\n",
    "\n",
    "# Convert the coordinates of a box around Thailand from real coordinates to rotated polar coordinates\n",
    "grid_lons, grid_lats = iris.analysis.cartography.rotate_pole(thai_lons, thai_lats, pole_lon, pole_lat)\n",
    "\n",
    "# Find the max / min of the lons / lats on the rotated grid.  They will be used to extract the data around Malaysia\n",
    "# N.B. The conversion to float is needed, as numpy data are of type float64 by default. If the coordinate limits\n",
    "# are passed as float64, they are interpreted as a list of two floats and the program will stop with an error:\n",
    "# ValueError: setting an array element with a sequence.\n",
    "lon_0 = float(min(grid_lons))\n",
    "lon_1 = float(max(grid_lons))\n",
    "lat_0 = float(min(grid_lats))\n",
    "lat_1 = float(max(grid_lats))\n",
    "\n",
    "# Set up constraints on the rotated grid for Thailand\n",
    "lon_con = iris.Constraint(grid_longitude = lambda cell: lon_0 <= cell <= lon_1)\n",
    "lat_con = iris.Constraint(grid_latitude = lambda cell: lat_0 <= cell <= lat_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop over GCMs\n",
    "for i, gcmid in enumerate(GCMIDS):\n",
    "    # load the RCP 8.5 daily precip data\n",
    "    file_f =  f'pr_EAS-22_{GCM_FULL[gcmid]}*_rcp85_*_GERICS-REMO2015*_*_day_*.nc'\n",
    "#   precip = iris.load_cube(data_path + file_f, lon_con).intersection(grid_latitude = (-14.767, -5,623))\n",
    "    precip = iris.load(MODELDIR + file_f, lat_con & lon_con)\n",
    "    # solve merge issues\n",
    "    equalise_attributes(precip)\n",
    "    precip = precip.concatenate_cube()\n",
    "   \n",
    "    \n",
    "    # load the historical 95th percentile\n",
    "    file_f = os.path.join(CLIMDIR, gcmid + '.day.' + TIME_PERIODS['historical'] + '.GERICS-REMO2015.pr.95pc.nc')\n",
    "    precip_pc95 = iris.load_cube(file_f, lat_con & lon_con)\n",
    "    \n",
    "# Use broadcasting to identify all cells in precip where p95 is exceeded\n",
    "    pre_gt_pc95 = np.where(precip.data > precip_pc95.data, precip.data, 0.0)\n",
    "    pre_p95 = np.sum(pre_gt_pc95, axis=0)\n",
    "    pre_tot = precip.collapsed('time', iris.analysis.SUM)\n",
    "    pre_tot.data = np.divide(pre_p95, pre_tot.data, out=np.zeros_like(pre_tot.data), where = pre_tot.data != 0)\n",
    "    pre_tot = iris.analysis.maths.multiply(pre_tot, 100)\n",
    "    file_out = gcmid + '.R95pTOT.future.GERICS-REMO2015.nc'\n",
    "    iris.save(pre_tot, CLIMDIR + file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the percentages of heavy rainfall in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for i, gcmid in enumerate(GCMIDS):\n",
    "    filename = gcmid + '.R95pTOT.future.GERICS-REMO2015.nc'\n",
    "    pcent_heavy_rain = iris.load_cube(CLIMDIR + filename)\n",
    "    plotnum = 1 + i\n",
    "    plt.subplot(1, 2, plotnum)\n",
    "    qplt.pcolormesh(pcent_heavy_rain, vmin=0, vmax=100)\n",
    "    plt.title(gcmid + ': Percentage of heavy rain \\n over Thailand in the future')\n",
    "    plt.gca().coastlines()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img src=\"img/MO_MASTER_black_mono_for_light_backg_RBG.png\" alt=\"Met Office Logo\" style=\"float: center; height: 100px;\"/></p>\n",
    "<center>© Crown Copyright, Met Office. All rights reserved.</center>\n",
    "<center>This file is part of PyPrecis and is released under the BSD 3-Clause license.</center>\n",
    "<center>See LICENSE in the root of the repository for full licensing details.</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
